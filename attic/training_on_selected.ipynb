{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Using this notebook, we train on a subset of classes (phenotypes). For example, we leave out the mitochondrial phenotype.\n",
    "\n",
    "**Naming the experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_desc = 'chong_no_batch_only_EndoErMito'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data\n",
    "\n",
    "Downloading the data if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3.2G\r\n",
      "-rw-r--r-- 1 root root 153M Jan  7  2017 Chong_test_set.hdf5\r\n",
      "-rw-r--r-- 1 root root 738M Jan  7  2017 Chong_train_set.hdf5\r\n",
      "-rw-r--r-- 1 root root 152M Jan  7  2017 Chong_valid_set.hdf5\r\n",
      "-rw-r--r-- 1 root root  740 Jan  8  2017 README.TXT\r\n",
      "-rw-r--r-- 1 root root  46M Jan  8  2017 Schuldiner_test_set.hdf5\r\n",
      "-rw-r--r-- 1 root root 405M Jan  8  2017 Schuldiner_train_set.hdf5\r\n",
      "-rw-r--r-- 1 root root 172M Jan  8  2017 wt2017_test_set.hdf5\r\n",
      "-rw-r--r-- 1 root root 1.5G Jan  8  2017 wt2017_train_set.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "#Taken from https://github.com/okraus/DeepLoc/blob/master/download_datasets.sh\n",
    "import os\n",
    "if not (os.path.exists('datasets/Chong_train_set.hdf5')):\n",
    "    !curl http://spidey.ccbr.utoronto.ca/~okraus/DeepLoc_full_datasets.zip --output DeepLoc_full_datasets.zip\n",
    "    !unzip DeepLoc_full_datasets.zip\n",
    "    !rm DeepLoc_full_datasets.zip\n",
    "!ls -lh datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 16 07:45:09 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P40           Off  | 00000000:89:00.0 Off |                    0 |\r\n",
      "| N/A   35C    P0    46W / 250W |      0MiB / 22919MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1.6.0', '2.1.5', '1.14.1', '2.7.1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Flatten, Activation\n",
    "from keras.layers import Lambda, Dropout, BatchNormalization, Convolution2D, MaxPooling2D\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.contrib.keras.python.keras.layers.merge import Concatenate\n",
    "# from tensorflow.contrib.keras.python.keras.layers import Lambda, RepeatVector\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time\n",
    "%matplotlib inline\n",
    "tf.__version__,keras.__version__, np.__version__, h5py.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Index1', 'Info1', 'data1', 'label_names']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({(0, b'ACTIN'): 738,\n",
       "         (1, b'BUDNECK'): 535,\n",
       "         (2, b'BUDTIP'): 336,\n",
       "         (3, b'CELLPERIPHERY'): 423,\n",
       "         (4, b'CYTOPLASM'): 1500,\n",
       "         (5, b'ENDOSOME'): 1500,\n",
       "         (6, b'ER'): 1500,\n",
       "         (7, b'GOLGI'): 1500,\n",
       "         (8, b'MITOCHONDRIA'): 1500,\n",
       "         (9, b'NUCLEARPERIPHERY'): 1500,\n",
       "         (10, b'NUCLEI'): 1500,\n",
       "         (11, b'NUCLEOLUS'): 1500,\n",
       "         (12, b'PEROXISOME'): 988,\n",
       "         (13, b'SPINDLE'): 185,\n",
       "         (14, b'SPINDLEPOLE'): 1500,\n",
       "         (15, b'VACUOLARMEMBRANE'): 1500,\n",
       "         (16, b'VACUOLE'): 1500,\n",
       "         (17, b'DEAD'): 749,\n",
       "         (18, b'GHOST'): 1428})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn1 = 'datasets/Chong_train_set.hdf5'\n",
    "d1 = h5py.File(fn1)\n",
    "print(list(d1.keys()))\n",
    "l = [d for d in zip(np.argmax(d1['Index1'],axis=1), d1['label_names'])]\n",
    "from collections import Counter\n",
    "Counter(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatBatch2Tensor(batchData,imSize,channels):\n",
    "    splitByChannel = [batchData[:,(chan*imSize**2):((chan+1)*imSize**2)].reshape((-1,imSize,imSize,1)) \\\n",
    "                      for chan in range(channels)]\n",
    "    tensorBatchData = np.concatenate(splitByChannel,3)\n",
    "    return tensorBatchData\n",
    "\n",
    "def load_kraus():\n",
    "       \n",
    "    #fn1 = 'datasets/wt2017_train_set.hdf5'\n",
    "    #fn2 = 'datasets/wt2017_test_set.hdf5'\n",
    "    \n",
    "    fn1 = 'datasets/Chong_train_set.hdf5'\n",
    "    fn2 = 'datasets/Chong_test_set.hdf5'\n",
    "    fn3 = 'datasets/Chong_valid_set.hdf5'\n",
    "    d1 = h5py.File(fn1)\n",
    "    d2 = h5py.File(fn2)\n",
    "    d3 = h5py.File(fn3)\n",
    "    \n",
    "    X_train = flatBatch2Tensor(d1['data1'][:], 64, 2)\n",
    "    X_test = flatBatch2Tensor(d2['data1'][:], 64, 2)\n",
    "    X_valid = flatBatch2Tensor(d3['data1'][:], 64, 2)\n",
    "    y_train = d1['Index1'][:]\n",
    "    y_test = d2['Index1'][:]\n",
    "    y_valid = d3['Index1'][:]\n",
    "    \n",
    "    # We bring the data into the range [0,1] and clamp it due to heavy outliers\n",
    "    X_train = np.clip(X_train,0,100)/100\n",
    "    X_test = np.clip(X_test,0,100)/100\n",
    "    X_valid = np.clip(X_valid,0,100)/100\n",
    "    \n",
    "    # For sparse labels\n",
    "    #y_train = np.ndarray.astype(np.argmax(d1['Index1'],axis=1),'int32')\n",
    "    #y_test = np.ndarray.astype(np.argmax(d2['Index1'],axis=1),'int32')\n",
    "        \n",
    "    print(\"X_train type {} dtype {} shape {}\".format(type(X_train), X_train.dtype,np.shape(X_train)))\n",
    "    print(\"X_train min {}, max {} mean {}\".format(np.min(X_train), np.max(X_train), np.mean(X_train)))\n",
    "    print(\"Y_train shape {} Y_test shape{} Y_validation shape{} \".format(np.shape(y_train), np.shape(y_test), np.shape(y_valid)))\n",
    "    return X_train, y_train, X_test, y_test, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type <class 'numpy.ndarray'> dtype float32 shape (21882, 64, 64, 2)\n",
      "X_train min 0.0, max 1.0 mean 0.17277522385120392\n",
      "Y_train shape (21882, 19) Y_test shape(4516, 19) Y_validation shape(4491, 19) \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "X_train, Y_train, X_test, Y_test, X_valid, Y_valid = load_kraus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, (4491, 19))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.argmax(Y_train, axis=1)) + 1, Y_valid.shape #19 number of classes - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing cells in the training and validation set\n",
    "\n",
    "We remove the e.g. mitochondrial cells from the training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes (original) 19    from 0 to 18\n"
     ]
    }
   ],
   "source": [
    "y_train = np.argmax(Y_train,axis=1)\n",
    "y_valid = np.argmax(Y_valid,axis=1)\n",
    "y_test = np.argmax(Y_test,axis=1)\n",
    "\n",
    "y_max = np.max(y_train) #0,...\n",
    "num_class_org = y_max + 1\n",
    "print('Number of classes (original)', num_class_org, '   from', 0, 'to', y_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a list of classes which shall be used in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For myto\n",
    "if True:\n",
    "    myto_idx = 8\n",
    "    keep_idx = list(np.linspace(start=0,stop=y_max,num=y_max+1, dtype='int32'))\n",
    "    keep_idx.remove(myto_idx)\n",
    "    keep_idx.remove(4) #4 For Cyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For EndoErMito\n",
    "#keep_idx = list((5,6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_idx = list(range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes (after cutting) 10 to keep from org [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(keep_idx)\n",
    "print(\"Number of classes (after cutting)\" , num_classes, \"to keep from org\", keep_idx)\n",
    "\n",
    "all_to_limited = dict()\n",
    "limited_to_all = dict()\n",
    "c = 0\n",
    "for i in range(num_class_org):\n",
    "    all_to_limited[i] = c\n",
    "    limited_to_all[c] = i\n",
    "    if (keep_idx.count(i) > 0):\n",
    "        c += 1\n",
    "#all_to_limited\n",
    "#limited_to_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11032, 64, 64, 2), (2392, 64, 64, 2), 10, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_training = [keep_idx.count(y) > 0 for y in y_train]\n",
    "X_train_keep = X_train[keep_training]\n",
    "y_train_keep = [all_to_limited[y] for y in y_train if keep_idx.count(y) > 0] \n",
    "\n",
    "keep_valid = [keep_idx.count(y) > 0 for y in y_valid]\n",
    "X_valid_keep = X_valid[keep_valid]\n",
    "y_valid_keep = [all_to_limited[y] for y in y_valid if keep_idx.count(y) > 0] \n",
    "\n",
    "X_train_keep.shape, X_valid_keep.shape, len(np.unique(y_train_keep)), len(np.unique(y_valid_keep))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5644ba5a58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAABrCAYAAADHLkZuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztvXusZdld5/dZaz/P+77r3r63urqru7rbbWMb0hiwARk8mWFINIQZCYYoQAQTwh8o8weRgpAiRRkhoUmUhEwmmngUxEzCaIYJkAcMNMQBBmNg3G7b7bb7Uf2o6rr1uu/z3me/Vv5Yj73PrbLrVlVz23juT7o69+yzz95rr7N+6/f7fX8voZTijM7ojCqS7/UAzuiMvt7ojCnO6IyO0RlTnNEZHaMzpjijMzpGZ0xxRmd0jM6Y4ozO6Bg9FFMIIb5PCPGaEOINIcTPvVuDOiNNZ/P73pB4UD+FEMIDXgf+XWAb+CzwI0qpr7x7w/u3l87m972jh5EUHwHeUEq9pZRKgX8O/MC7M6wz4mx+3zPyH+K7m8C12vtt4Nu+1hdC2VAN2dJvhNCvSoHnQVFUJwqBKkr9rxTusCqVfq8AKe3B6lqlAoH5vHZ9e7/j/9e/B9V37f/i7tdQpUJ4Xu1kqvPuJnjrYxFC38+TYJ6xfs4g39tTSq1yn/Mb+k0VRwtzx0Sp9Hg9qf93Y7zLnJRKj+H4MVWCkPrV91G+h7DjrmkZypNz95wfiIBS/05z59Wvkef6PsfHcPw6x+/reyAEIi/mz7XnyGrfHyS37Nx+TXoYpjgRCSF+CvgpgFi2+Qh/Ba/dohiNAZCN2CwwTeVshmy3wDdDy3P9muUQ+JSjsf48M8cbMeVRH+H7qDxH+D4ijqrPzXfceI5/XrsvgIyiO56hnM1QWY6MY/1dMx5lGFm0W6jRuHq1zxPUprd+P3Pcjkv4vv5OI+b5W//z1XvNqXuW+tyGPb792Z9CDqaU3Ya+fujjDxLK2CfvRPjDGd5OHxWH+gJhAHuH0G3r/9MMBiNEqD9XcTh3vNxaJV1uEO5P9VwNpu46YjBGpSl025TdxtxnpBkiSVFxSL7SQaY53k7fPYdKU0QY6u+vLFLG/vzncQiDEUwTOL9BGfvIZP73c/fo6k1XDPTc2vekGc+//vdPNLcPwxTXgfO191vm2BwppT4JfBKgK5eVt9QD30eYRajy3C1m+wpUzAB6QTViyPOKIRqxO0+2zURQW9B3+bx+PVUUlNNEfy/wke0WKplBI0bZxWoWt/sM3KuIIyfd7PlME8dw5WyGrDGFKgrUsbG4/835opjb7e45v/W57TU2lExyRJIiByMAPLPQZLdNaBapikNEkur/w0AzhGGEbGsZVjr4e0N9gzDQCzDNYGUROZgSQrUgByP9fezia0Ga4e30KdZ61XPae6WZvnYYzDNmGqIwgjrN9P3sM/YH0Ef/no0Y0kzr/OYckaT6XrGvn3svdWPCnhcG3A89DFN8FrgkhHgc/WP9beA//FpfEJ5EJTNUPnY7sioKRLtFedTHW1pEjSdaGtQ/jyOYJk6KFKMx0u7ScWSumevvBL5mmpqksFIG9KIWcYRsNR1TuOOeN7fTO0kQ6J3cjSXL56SPky72XswzkvA8/f1cf+/4BiA8724S6r7mV3mSvBvrHzQ1Oz1AbaesSwHA7e4iDFHdFsH2vv6eWbBiMEam1fllt6EZwi5aIxWsRKrvzk5S1MhKsLldvra4VbdFGes5kWYhl2s95GDqJA2gpZt9bozECoNKwoWBZsLa9e+HHpgplFK5EOJngOcBD/hlpdSXH/R6ZzRPZ/P73tFD2RRKqX8F/KsTn1+Ud6gQArTa4ftapwx8mM2qXdrq/4GPNCqRt9hzO3J9x3Z0TJdXRYEwx0QcaYMxTfV1qKSHG4+5hv3fShERR+5+9Z29nM2Q0TGJVbMhrKpWH3fdjnLjPWbn3M/8iixHprlWd+y4Yt/tsgDYnbRbUyfTEKw6ZXZqu5NblcepUXaHr+3CMsnd8WKth9zeBVrkKx09T2lOGern8wdJNS53/0xLEGOHyK+i7qhui7wba3ukLjVq45k7VpcQ9ykt/sIN7ToJKfTiN4sMcAtCUC2+ORugpvpg1Z1GPGekAnMGcF2NIfARxhiXUUQxGjsGcePy/coOsGpbbYxOnUpm7hpEkWNcb2mR4uAQGUUIz5u7jv2+125RHPa1KmYN65pKV7/PA1Gp7lAzrG4+p7/Xv2IWp8NyjL7uVJjtXX2823bHZZJXnx+7FkC5pcEda5eU3QYyzZ2KA9xxDZnkesGbz/Nu7BhIJrkz1v09zTB1NasMfX392nnW6LY0xywnoFNlCksqz6sFUFv0bqFkOaLVBND2A2gUaTZDLvS08Xxcj7fGqm92eHtNa2waRvNWlzVzHWMcQBvGZjziOHJkmEuNxk5iWUZUaeqY046BwEcZMME+s9du6ePJbP7+tWs98JxGgV6A1HT3wVQbwyuLsHfobAdLVu+3aJFIUq2jm8/zixvVgqsZwM4QPsZkc/ZGjQHq9oxFtI6jR1bKgZEox3Z3kaQO3SIMqrGvdDRjHJNi1qYQg7GTdCelU2cKa3Q6dAgc0qSKAowxq1LN6d7aKmoyqRZQns9LmhpTyRpDqVJj6fZ1TuLYhWnHZI7Zz6zKpcy4rDp0XHWqv3cSooYo1Q1plRs1Du6AhN2z+A/+c4i8cAvbq++S3TakGfnFDX0LA9ECGrEx6k+6uYCcFRXyVKdjcGf9eN14zrsxZdTCH1Zza3fw/OIGZeRVsLD5fem2naplpYMYjN29rHQqjhnpVhLY77h5MN+tnrFH3omQs2N+jK9Bpy8pzKIrjzQO7RAjQ3OLHSgPDh3yYxfjHbuqtRvszl2W8/4NcJCniGv3qfkLpIF8RRiisnxelbFw8DHp4iDXrMY8vq8lUSMGa+/Yc4/5KkRTS0PVH7j/H5SsU8yiSVDp4U4VSc047a5q9fc0I3zxDUSvqyFbgyL5lhnSlOKoz3HlrqghQ8VaD5nmdyxSMAvbfJZ3Y6SFbw3V7Q477q+5s6eZU4mcGmYkkopD8m48d3re8qB1ctX09JnC98GvGVpm1xZxhLDSwy4qQBg7opwmWv04ZowCTq1So7GDb+s7v3P4GRJhSJnMnCEt2y13TzWeVCqcZYxpgmg1KQfDuxrSjgIfISXKMNEdzw2Vod1sagwetGSLAspOE9458UzOkfPodttzTnW78wfbY1Qckm4uEO4aZrUGNMC5lTmDG4A0cwvfs6pXzRCW27uUW6uUK53KSdiNKSNvbmc+vujrRnvejck7gXYI1lSv+vlwjJHNOfZ4GfuVPwXm7p93AtK2R9YSnJROnSms99mSwOzax+wCadzzyixQb7FXoUTmPNBGsoyiSgWzRqu9QeBrOwScoa6yHLm0CL5Z9MlML6TcqFjHFrAqCkhTRLvldv85Y9oa8oFB0Gpqk6M8v4ORRK+r//E9iO7PGLyDTAjEHJ6fZuRmwSrzmT+cuZ3UHyR4O33ttCN2C7uu71sPuHXG5auVepS/b4u85SEzRRnN78R5xyzatGT0aINwVBAe2M8ipFn0ZeQhU63i1j3xdanm/B93Awzqzj7r2wglk3P63CIUZC3I74MpzvIpzuiMjtHpSgohXJiGjX3y2q1qp7VwaJ5rNQb0zt2IXQjFHX6CGvrkDNjGvE4p6lIHEN0O5AVqoFUL0WzqgLVpUu3eYejUG9ntoMpSX8eoWlZdA5BSamlU85DPxUZZFS6KNKpmfTIriwBOVSi6DyEtTACcU3EwkqEWsmG9v6UxbLXq1Jo7p+6Jdsb3IHFIVmjGDBAOpvjdBoMn9fWyliAYK4rwzl15uuQzOO/jpRCMFeFIz00R6d9mtqR3+cbNxNkedm60l/6r+B1qUsP6MbK2R7Kox5C3BGUAyUot+PIedLpMUSqHHHlGx7cGsF1U8m52Qw1CvSMcom5kW31dygp1ynPntHIIlFWxrEEaBVWAbJ5DHEFeVAyS53oMva4+z6pq9tUwsA1Zscwx5zsBbT+NJ4heF9FsUPp6QWSLMUpC1nmIn0PKO8I4XEAfVYAccCfCVHfOWawfCHfHlcEbBqTv25qzFfpPLjFbsIygF2ARQhkISjOM6FCRtfR7mQIoZosSmepnD8YKmYGXKjyjhtUNZauWzcHGx/wO1knpDyDZ7DBek05dyhvmnPsIfzpdppBybtFYEp5XHbOLvIZCqaJAWR9FLQbKfu6u0+s6nV5YQ7ce69Prgu+hwgAxSZxNIYoSfA/hNzTDWKPVfK7S1PlNwPg+yrKyVcy9hJFoDjww56uiQLZb+nvmenQXSTZ04FoZCKZLHs29uxjvJyTlSfKLG3MYv7UnxGA8xyCOrEQZjJEYpMoE7AEuurZcbpAs+sSHObOlgLSlF7SXKoIxFCGkC/ppkxVBGSr8iX4/XbPHS2QmkJlmDrvwigxjBBvmCkKSRUFgeLh12/hGrJe927orZJuvdCgjj2TRpwwqSZW3FNlKjtf/ekWfyrKKQLVhFbXIUIsiiTpyk+VafbG4duDfYQhZRlNpCp0WyvMQ1ps7mWq1J47Mgs+hGaOaNRWrKKqcjpbeWsR4WhnioI3nPNevcQSTaSURDMO4MBXfB2p+EAMkKF/DsKrbYnau7X686ZKHkjBZeYifQyltnNZUC39vqEO1zU5ah2ChYhqSFDEYE1iD1nxfphnhYEq6uUCyKMhaATKDmWWAVfAngrSnKIOS8EiSt/S386Z+tTu0PxHEu4JkVZGslqhQS3JvLJEZ+GPNMBYisd/L2h7lY13iWxPSzQ5Z26NxswYzG0953gkoA+HUJvv9MlBEvYTOxoy3TziVp8sUnnROLoxgqIdF1PXyen6DDaHA9++O4OS5RlfCEIpS/6jWOddp6WOe1Ave82CWarRnphlNFCXMMrcLgXZ6iYlZ9M2Glh6+j4qMOhKGVQKLZRhL5hnmckbiSDNnnpOtNClDyfickUQeKMlddfGTksiL+VwJqhCLdLmB7ESE14/mQiD8vaE5p/qOdaSBRpD8YcZsKSAYw/CCYLqZ07iul03eVMw2jJQMC5JVUBOfaNdzTFH0CkRYIIOS/mpIZ2NI2m8gjoyfIdALN1soSJ9NkVcbxHvCLer4yI5Fb6LRgYFdbZiHgYCTRZ8iFE5S2XFFvYS13ohHO4e8eMK5PF2msMlWddugEWtpEfhzqpGVIA76DPwqrLuep2AkiFherCRBq4EyOz6YUOI4QCRmF7Xwp1XRZhmqGWsoMKpUDMcARr2643Gs3TKZIMJQq0fGz1GOxjqkBJxTEN+nWF+k9CSzXnU9L9G7r588RF3fWoaZXfQSIAyI3z7Qi91ICQuvWpXEQqGgdXhr9KYtyezpkLxld34FviJ91oAgN2LExEOuJpSZJGxkzFIPnhmx2NSb0t7NHmriI488CBSTScTy8ohhQ//+6dQGF+r5yBYK4j3f2STDTY8y9GhvezRvp4TXj6oQdkMW/s1aIHOYXsjxWvq37jRnNPyM1w7WTjyVp64+EfhV/BFUC73uFa45zoQ1yGvoFFB5gO0OnRcQRzr1cjx1TCGM5BBjrSKV3QZykqJ86XT+cqmDSDJkmuvzPTnPBOOplhLNWNseg7FmGMtAh9o7r8rShZh47VZla9QM+tKXpD2frFlJhawjUB735WC669wCDEaV885GvVJ5swHSZT034f6UvBM5Z14Z+/jDGf2Lep6zliDtwXQzRzRz2r0p+SSiGJvNYjVFTXx8vyAHZn3NJDMq1VSEBSr38ceCdEFRjAOGfsRs3/w+zZzl5RF71xYoM0lnY8go7Tn1Ktr1CPuCyZrEywLylt5owoMqzMMfZiQXA2fXABR9PedDv2A4iQjDk9trZ36KMzqjY/SehHmIMHRwpitYEPhVnm52TD9vxBV6Y9AlpzaFodvVy24TMU5Q3TZl0xjyZYmS0r2WoYecgMjLyqYgrFJLPQleTRoAqtVwyfouW81CtwDG7yEwsVomGtbFNkUBYjwl21wga/soD5JljbaARm/8qcKfPMS82qT+btupT8UbV3RAZbflPMPFWo/4uoFk0wwZ+iSbHfxhRroUUkTSSazJIwa5aWU0mzMiv2A4DljZ0JLx6aUdXtrZYNRvIINSq1IZlBOPck8ja3aBpQslZQBi4pGGAZ0NPYY09TkcNOlsDFloaO1hshrh+yZMY9xCpgIZaFUqGEszb1oSWAM7XRCUPiSr5ncykG8Y5kR+wfnuISfN0DpVplBKoUZjFOMKfTLIUXHYr4oYWGjTkoU5xxON9Bg/AmAQIU+rTXkJnoeKj0GPvkQhyToh3jQnX2ggJxk0TdplmmvGsNcsivnQi7xAeR5lM8JLMw3dQmXMWwN8qIsXuJATi5g1Y1S3Td7wmXU9ilDgJ/OGtXdnHN39z29NXQIdYQw4tMkyRx2hsowwPqfnbLqm0STAMcQHt66z3hgyyGKeXtrhnaF24L20szE/gIWU8ihEhSWZNdvGejRFzzgyjdE93NVM89TFm1zeXmOhkTDNAoYTzRBW3ckfSUiJ8ScCf2xQr0VBsqiXbnyonYUy03aPtW/aqzpPfTKJoDnj2qByOt6LTjfJSIg7omCtB9qrFQw47sewMKfodlCDoU5UMpCqRYgcquR5qNB3nlkVB85J5k3NPUtF0Q0J9ozTzZcoX4IvEQmaIQbjeXQK8CaJ3vXNe2US5B1KZSSZ9Zg7P4fvMTvXJln0SLuCMhCIQqEMUwRjRRG/O4xR90irOITbewi6ZFvLVTxR7fz41oTxhTZlYG0I5Zgi6ukBXRsscm2wyPnuIU+09/iexVcB+LUbzzHNAxYaCUfTmFG/oRfvru+gWX8skDmkmaAMFDLzyRYKvJ6e22kesLw8YqffZq03Yml5wmpj5Mb3mcsXUb2CoiVIe5L2OxJ/rIgP9fW9TJEsCuekk1cbcGFKmuqlvdidMJxE7v1J6JTDPLjD+2xRJ2DesWcRJt93YRokM80YzRhxYIzbbrtywqUZKgq1IW2khZISmZcUzVqUpicJDhMXXiGMkWrRKTFJnPENoDxPG9iTRDNdpMOrnXOuGVfOwKgFs2zOUFe+pGhotaQMBHkMfiIQRjApCTKDYPIQ6JNSLpHIHeoPtEOz26qcemHgPMYyzck7Ed6sRGaSZFVDmZYZ0mnAhx+/xt60TcPPuDZYZL0x5HOjxwD44OJ1Xjrc5Or+ImGYoya+g2Lta7ZQIJr6M3yF9Uo1DTp1Y7/HB7eugwke2Ju2eWe4yKMdXZxABiUl0F6dMplEJJMG594uKYyPJ21JvBT8KYwuzVCphwdO0pzvHrJ+bsibgxUun3AqTz/J6JhHe65yhw39rtsUuXZ6gQnfMAvQ7tL4HmVTM0KxoI/JyYzC/vBJTtYJkUWJSEuQgrIh74gGFeOkQp7Me/dZUVLGAdQcfqoZzxVwU1GAmJl0yabnxgVQ+pK8Ue3PZQBpgHFWgZ+Anyii/skTYY6T8r0K5bIh6YYhjj9rPQJ15+M9khWl0aELCVEjI881Q3/00lsA/M2tz/NC/zE+uvIWn9m7yDTXG863rV7hYNokzz3SaaB3/xuxlgRGbSKTMA6RmagYJPWIjM2wsNxnb9rmaBozmUR8cOs64yxid1qVqWn39M5f7sYQKA6fqjactKecl5yjkPPP3Gb71qKTDG8crLC+eZfEqa9B92QKIcR54J8C59Cehk8qpX5JCPFfAf8JYBJ5+XmTaP/VSVFBsWZB1WOdhOchmk3Kg0OkiTtSxgegR6t3a9WMtbpjSB6OKBfbiDTXxnS34SrulU0DHxqGkGmBPzVh1mUtSCwKwUgCzOJ2XvEwQB4MneFNFM5JAjemprZnCsMMWU+/WrUpjwWF4StvBtnRIdef/2fk4xGygPVHv83O+f3PLbWaTudW9P1NDSeXX23Os5As6NikZMUYqEchF7Z23GcTs/g/2rxMP2/ygcY2rMDlscb8byY9zncPmeV6kc9yj9GqhNRzYR7WCSczwFeo1INcMJwYkKIJS40Jj64dunu+eXuFxW6FOoz6DZaXRxyuehTjgEnNZPQn1tGnmWOnr5nJMnYY5nz6+uP3mro5OomkyIGfVUq9KIToAJ8TQvy++ey/V0r9tye+m1moqr7D2hwJ4xVW/cFcOqrT042UoChgliJym8LpoVoxIs0pmqFOOgk9lG8WflriTXXW1+SxLuGBwpvocyyJvNRM1oxhllaok5EaFIU+5hmmBO3zsAiXcQza9yqU5A2frG1LRIIo9AKZLSq8mUBJKGceq3/lB1gMNhHDKV/57f8BcCD/fc2tKEoIA4puw3l/w1e2XbyVNKmj6XIDf6iZPV0KDdKkCDfGrPVGXN1f5Nn1WwCMs4ir+4v8y/ZHaHszXp5ucXm8RjeopGjd2E5Tn631Q2586dxcmEfYFw55kqsJxTiYU28+1NM13m6nXXanbZ44t1fZFUuaUdYbQ37n2ge1NGplcKOS2k7iGkYMG5lzCk4mkTa8e3fWofpqdE8/hVLqplLqRfP/EHgFXef0jB6SgnaXxvoWAF4QE3fPgcUaz+g9o/uyKYQQjwHfDPw58DHgZ4QQPwa8gJYmh3f5TlXvVLRcBOxcPgXMxTzJejpnGOrPWk1d1GCWUS51kAODHAEq9MkWY4JhqmNiSoVIDToxSUmXm0BMeJQ5o9sbVMn9NtNLTBINv1rb4XjJmaKgWF9ETtI70iXzlTaUiul6TB4LZguCvFGhS2AkhtHYoj7IrDKsp5NDJgfXASz0cn9z63ed7RDtVCCEsvViVxYZPNkxaI0e+2hLUgYaIUqmASvrIz6x/hqfuvW0u8dPv/+P+eHOy1wrIq5ly/xQ7wV++eBjgFafoII9AbZvLUIAclX/nvFXmiSXElTqIcJC2wXNguFNHWP1hX6DvfU20yzgfPfQ2S0W9t3pt3l2/Rafvf2o822MrvZo7un9fHwhN0GFgrypUPsN8JUDC6yf4n7oxP0phBBt4I+AX1BK/YYQ4hywh16Xfw/YUEr9xNe6Ri9YVd/R+ht3LVYGX6XMi+8jmo2qDGJRoFq1MIIkI1vvUHqSMpT405y84RMMa/VIjSrlHyXkC7FmiLpNMkkrCNW+2qBBcFAv4MJErHEPkK00KQLJaDOkiKH/lMKb6NANAJkJogMIB4q8peHYrCWIjgxSU8548zf+IRcufi+vfO5/+xzw79333Mbr6jsu/Z254sTHgwPzTkQZSscUg8clyUrpfAgrG30+/shlxoX+Hd4crDDNAz6x/hofaGzzS29/gkc7h84I/uDidf7wxiXOdw95aXvTIUrWvgCtUvFqm/CDR5oRfMU3P32FcabvMc0DHu0c8lzvCv28yaduPc23rV7h/3njAwBcWD7kYNpkqTHh8vYaMigpxgFioq8f70rKUJE3lbYtFnToiYV8y0xqBCuTXP2xn/+cUuq5rzWPcEJJIYQIgF8HflUp9RsASqnbtc//MfBb97yQZcA6I9iSN5aOlagRoXGqhYGWFEUJ1gYAymZE3tBe4iKUiFwzhqNS4U0KkrWY0msSHCbau53X4oHyonLYQcUE1pln7AdRlsjB1MG90/Ndd5vpikeyLBg9XqAaBeVqiXdL//DBAURHClkoxFDnIYRDo3OXBVc/9StsrHyIR6KneOUh5tYl59QC/mw1D5nkLi9ismbmztc6/1MXb3J1X+/Mb45WeKK9B8DPXnier8w2eaH/GD1/wifWXwPgz648Bmim+LmnfpdP9Z+Fres0TeDd4aDpPNLpNEA+OaXjFwx9RWd1xLXBIo1Ab1o39nvc2O/xgn+eTnOmveSHmzy3pbsQWGP/YNrk0taOHmcLB+1ON0snKfwJ5FlI0dJMADpqtwDwTw5339OmEEII4H8FXlFK/Xe143V35g8CL9/rWqpUVZUOW3TYGt2NuKr6bVI/XRppZJAgz9OqzSxF5CUiL10KpyjAS0tKk94o00L/5ZqJwqMMb6orP6jQ18hTXkBekC+1EEWpfQ9ppg33SYKKgznvuMhLymaECn3K0NMZZoEgWfQYXJCMnijonB/wXe9/Hc+vkC3lgSyUhl0HJV5m/j/IufaH/4JOsMKFzY/V5/y+5xYhkGlOsL2vy08OpnNlYvJuTGaqWuQtyFtQhgrVLDiYNrmwfMi/f/5lmn4lYf/RjY/Tz6vkqp4/YVRELHYnLHYn/OGNSxwVTZ5q3mK9oVWbp5d2+PbHrjDrx8z6MWFDh4jsXVtgZaPvPNm3Xlzn1ovrLHYnPLJcld1/7WCNq/uLvDPUf00/4/L2GsNJ5PwhzeYMcqH/DMlMw7PxnqRx3UdN9J9IJfjKSZaT0EkkxceAHwW+JIT4gjn288CPCCE+jBbxV4D/9F4XEhbNqdVAslXDha0aaBN53Ag9hAntduRVPoC0GzjdPG9IwiOtPrl7pqVmDEyotC8dUuXn1lNtSrs0Y0SaIZJsvvBXUSAnM+0dj31kXjJbCpku6YmergqS9YIPf9Nb/OQjf8y/Hj7DN21d5wuHF/XjvuMR9Uu8aUHYTx06NrjxBjvXX6QdrfFv9v+BlaQ94O/f79wq36MM/bnaTHIwrap3Rx5pSzJdE0w2DMMupDDxHTz6K5/5TqLlKT/9/isAPNO4yatTzZ8v9B9jkgd89/JlfuGZ3wTgT8eX+IPDZ/jPNn6f1yfrXGrt8MX+JuuNISLUm91ab8TRVP92s1zbFXs3e7BQuGN7N3t0Vkf6eC7obAxpGOac5AGXDEw8zQMafsbNYcf5QWQmaF/VqbD+RMc/xXvKoYt5UyH37s8dd8+zlVKfplYxpkYnLqw8d73ReN52qBccMCSkdIyhPInqNpGDibMrVByQGh+APy4oGpK07eGlCuVLgmGGTE0+hi+dP6KMfbxJqsNAktyFcchBpqXRYKTv60lEmlEaZyCtmKIZokL9Q6Qtn8mK5/KAxxcKHn/fTXLlEYuMn176ND87/EFkUgtljgT+GGOkN/AGKcvyHH/tGd3fsWxGyOGE5y//N32l1I/e77yKotSlbOr9J2qlbibnQsJxife2QBrVYhj6iGbOc1vX2J22efpDO7ywfZ4X+o8BcKm1w5/vPsZKY8QT7T02o0M6MmHOlN/vAAAgAElEQVTB0yDH5fEakzzg73zxx/i7T/8B/+Sd7+DbVq/w7e03GVzSjDDJA3b6bUQzd1LCq0Gqw902US9heLNDtDzlua1r/MmXLznn27Prt5yz8Mcf/VN+7ca8SRDvCbxU53q4vOyWoHlDb5STR7QBbuHak9ApJxnptlj1speuIrhN45wm0GxW6FMUaD+C8WQXxtD1x/rz2UpE2pb4iULmCn+aa8PagkvGNyInWRXOYWyJsqNVAxmZAD6bjRdZbN+cZ5goM6pfshxQxDqpBUAFilaQ8kuP/R88HrR5JZXcnnTwzA/hjxXhUU64P4G8ILhxqPPETXMV4ghZFDoF9iHm1hYEq3fzUeiqHF6mXEK/dagFRx7xxpDdaZur+4s88fgez67f4rneFQBen6zzifXX6PkTOjLh1emGM8IBfmztT/inOx9jozPkl177Hr5z822ef+cZnucZxwCd1RHpNHBhHiIsKPohQabnpvlqwPBJgWjm5LnHawdrRL2EC8sV2LZifBavTjdoBTOgg8xs7rdu99LYUbR2CpIFHUU72jJRsn2Q6f3lqbwnZTMFtXRT28prmujXwNe1YxerTjhikmiJEQaIVEe5zpb0LuhNC1Sv6qOWtX2XgALgH00pm6EOGU8LHRFr1CaBUSMs0pQXmiF8qaWJUavKZoDytcMN0J7psIomba2NudjeIxZwMx/x64Pn2Dno0r5tfvi9HC8z9yoKHcOVzObURFHvf/eAlHciwlo4hy1WoJOIWgQjycHToVOfytXULV6AW9MOTT/j9cm6ez/IYnanbT668hY3kx7P9a44lcrSE13tbGt5Mz64dpNukPB7k2cAA9eio2VLk5TUecNn+KQepz/28cYSfzfCnwj23ydZXq4CAm3cFcBLh5tM80BLF2P65E1Fe1tXAklbks52Rtb2TOUQaO6UTNbkHPx9LzpLMjqjMzpGpxwla3iwEUOtTL1TlUxCkZASNTRh5AtdHaUK4HsU7YjJRkTp6V141pNE/RKZKURe4mUl3iR10iDvxsgkxzMSomyGKFkiJzMXliFnlWSxVPoSbJGyyMObFQhPl2S0EqOM9O6z0tZj/d8HH+L6bJFX++eQbzYIDOwaDjK8QaodjgbmVWU5X7XE96oCcA9I4fWjuSjYYFurT4QBclYwOReS9qBoGYAhKPEbGRud4Vy49rlQBxQOspiNuM+l1g4joza9PlnnqaYOA/nt3W9ib9rmA0s3AXj+nWdIU59Oc6YjX4EvfP4JVKjL25RHIQIYPplXhnKujeXZRk655+PfiDgMSmf8h2HOytKID/Wu81vXPsAs9+isjpj0tSbRviopQl1crTErydoaULA+IIAyhPI+ikKcsk1hVIRpUuVb361QMegqHFTBdjbqdLIRIQqQJhNZSUHWlMhC0byeUjQ05KpDtjTZoECZFpS+xEt1YpK1GZwz0JcaeTI2hP1e3vIoGtLdq4ghb0LR0Qv85mEXTz7CQavJpy8/iXcrorkniAbGF5Mr5KSqJ6XGEwc9689zXdyg1dRNDx+UTGPGYLvWDTZJUWFAGWk4VuY6Lxp0rsHezR4HzSbTPGCazSdnTfKAb2+/yVHRZFjGtD29kVn16ruXdTD2v96/xHcvX+bPrjzGE+f2uPzyFoerBspdSCHVGXlhXy/MeLcqTJA39HGZ+cxWC1pXfXK/cAF9z21d44Xt8zzR3qMRZBwOmhT90KFs0ZHSfp+D1BQwKGmNChffNd2I8ccK785976vS6dsUtkqf1adrUbO2SIEqS2d02gIE+UKDwlSLm3Vr3uhCZ161r2fMViLCQUbaCwn3Kx09XQi0nZGXeCaSVoUVKmXDxFUrdtKj6IZk7VrVEMMQwaRktGmOlyam/zDmrcN13s42aNzwiA8U7Rs5kbFtvNGsSnc1Yd31yuqWSR6GlO/pYmh7w6pah6mJlK62yFue1rdbIf4N/Yx7qd51v/XcO3z29qP83FO/y8vTLW6n2im5Efe5li3x11pf4RdufD+XWjt8Zu8if++ihmR/Ze+7uDXV4Rq/c+sDFOOA119/BLGQOnQpNrWg0gsz5G5IeCQpQ2sgm98wq/Ivkg9OKKcBYUMv6tcO1nh2/RY3kx5H01g75XzlDO2sBa3burWZP8T1wLBBkZ3XjvBmXVee8yR0+iVujvVpcMwwGlcLZZrocvaYXIZWTBF5pD2f6bJ0NUsBykL/P9rUkKP1USSPGGRpphd+1gsRLR8v03kV/qBKMipWu3Mtp7Je6DzkUKWNlgFkTZ3UMl1XhLtV3SZ/LIj6EB2VxIcFje0Ryjgf5WCCmkyh2ahSbevJVa1m1QLggedW6USiWpegstvA2+njxz6Tc7V6Ts1qQaapz5uDFb713Dv82egJbiY9l1m3nS7RkQn/YPd73TG4yK/sfRegw0AOpk3Od3UoBqCrcVztUa7qDSFZhfBqpMvcZILkUgJHIc2bem4mGyXNm5K8qYh2PdKmLpVj0SebyATaaG/3pgx32/RMxlB8pH/f8YU20UHmKqLb8p7JZofmlcHXcScjgc5nTmauF4Xw8rn+08Adu2bRDClDzQx5bMLPa4yfxwIvU+SxIG3NP5KSEA1LY4N4rrCvzEuHLtUpb/nItNSNPgyVtYSg2YKulxrtC6yzN96D1q0SL1U0dmY6/5tavoYNF6l1TwKqnndpOtes8kFIFKXLvU43FwBtY1hfRTgqmC7p61vMPr5Q2RH/5bn/l7/x0k9wvnvo/BDbLPFN8TV+sneL/+jKx3mud4WPrrzFb13TcUnfeu4dWkGHL7x9HpV6PHXxJjeHHVSzIDDSKOwblM7XiUz+5ZjpZs7EAFgyg/ETGV7fY7ZawMRnbb2CY59/5xk2OkPeOFihzCTDmx06b/iunGYRSacqyVkx11sPINzPmTzWpXllcOK5PH31yWbd1Vp6zfkujEdbNLXaVCy0UaEka0tmCxJZwKwN9fKKukCvDrRLu3qxWkguPlCMW7ZmrCLt+ARjRd5oEh0YWHdWkC4EJudB13Utgyq6dbKmsW8vgWRJ4M103FBo9P9woLPmrNNQptox6HK503RO+qmiqOrO1umr2VcnIRtXdntvLvZcJCn55gIy07p33hIsfkV/1s8W6HzLPtM84Idf+VFmuccT7T1+9ZZOdnqivce/PPwI/6OBYvt5k9tpl3/4/l8F4BevfT/fvXyZNw5WmEwiVhsjLm+vcf7RPa6xYn4fT5fTfKTAnwYMn9EMEO9Vu9ok0IxatCBannI0jdlJjZ+jOePq/iJ57qEmPq2rPo0dRXxLM26y3kSmOfH1Kt22LhXK0Mcf31+U7HtSIVB4XtXYJGY+X9s58EyPszQn86wqpcgbgryliPp1b7HWUaMDwXSj1CVRjMNmump0z15J6x2Jl2jGUVJQenZHCXT5Rk8zVN7QDq7hBf1pZDau0Za5Vhs6V5WTVvFRSXxzRL4QI0YmBD2ZVWhSI9bPZhq3WOa/IyjyISSF8j1tVJusO0Ab3mGIP5whk5zh1hKt64rxpkHuNjLKLy1z/mNv8JVb6zy7fouXDjeNgwza3oxff/tD/N2n/4DzwT7X5DJf7G/yi9e+H9A+hN+59QEWGgkLjYTPXL6IDEq2by3SelPP7fhCjv9knw8v7XFteZEIaDya6RBzcJl4s1XNEHnuEYY5HRNxezhostidcPjqEp2bumhBOC6dzSAzpf0zg+l8A0xL3cZc4/uT0Jmf4ozO6Bideil+W83DVR+v96PIcufVtvp3udDGmxWArwttdSE6EMyMw9ubabshGGrdVSaColWSd7VYCg48lA/hgYZSjzbBH5mS8MZOyFo69yFZUQRDQXJOS5u8a8WujojVmLq+XxlURl7Yz1Ghj3+UaCTL2hC20eRRf743eHBnL/F66f4HIVEqVH9AuXbe5WA3XrGxXdXO2bqdMV3TClbjakDYh89/+XHOX9xlvTHk31n9kjvXeq6tPwLgA0s3+eztRwEdzLeyNHKBeh9+/BrjLOLmsEP6LXpyn1o+5PL2GizhAv4AlzD05NIen3/tMRfF+sS5PS5vr7lMq3ZvSiPImO5pKWErtVubz0Yv2Pqy5RtXyL/lGYLtff3scNeeFl+LTtmmqPIp6k0WacQI02zxODwphxPKuEt0kDPrhDRvKZJlQWNPXyvtCERpy8TofGPvoHLzF7GJoG0pykjRuCmZbJWEB5K0a3soKMpYUbZzvEszzveG7I1ayMwkysgI8F2SfOedEuVBdKCZOdzXapKtCILvVdAruj7uHc0o6+qSaTdQDu6v6sT81CrKS+fxdvrIznyyllUrVv/4NsnjSzR29Jzsf0gxvaAZeKff5mU0E7w50CrYBxev87ce/yK//vaH+FuPf9EZ2E8vVcUN3hkucmO/xyPLfV5/a4PO6oifuPSn/Mb2N7tzLm3t8IW3z/Mff+RP+GJ/0zEYaBXs/KN73NjXu9zBtMny8sglKY2u9nTFwKYib0K8C96sdDZFvfIhe4fIhR5yb1h1T+02dKPKu7VC/ip0+iVubKj4sTRUqPB6Vx4TELNMQ42yQftmTrLo0bqpHAoVHemMqyIUpqS9IOtoCQKgPAEZzFYL/KFkbBZBspWRBCakvB8g1xI+9vhbRLKg5c94J17k9T1dtSItBUVTEfYFjV197/bNeaNYHgxRk4nuQSHlfJVDW1n9q1HgUxwczjXIfBAqQx8Zhw6OzLaWdbn90K/g2rR0AYHdNwSjCz7tq3D0vhZHYc7LBxuuIsbBtMnHH7nMk0t73E67zHKPT19/fC6Cdaff5oNb17k2WHTo0+uTdeflbnkzbiY9pusBoyLiifbeXLW+pcaEaR5Q9EMWzx8xfHFZZ9Gt1uLX3mgQ9gXRoaL3VjKHDObdGLoxwfa+LntU678BVfh8urkAr59sHk89SpYsv7ObUZ5Xi2iaoIzU0CPUqaHeSOro10XPJelYmnUlrVuFy41u7FaNRYKRVnX8oakSOJYgQQwl6jGtVqw9c0ggSx5tHPLNzasAfN674JgCwJsI14aqsZuZcBKTE2JrRC32YGdf55PXa1tZ9cl0dZWNeL5Z/ULvzrZl9zu1ZuGLJHWqQ7a1rBnhxVdJv+P9LtTDomqgkShteCuGu23Snj8XofrS4aYL9ntyaY8n2nsuUvbWtMNzW9fYiHXtpsvba/z4h/9sThqsNEYu9dReb6kx4Ymuzu4bZDEvbJ8HX7G/30aZYmz+i5VfJTzSEbCBgdO191pf0x/OTDZk6JAnr2ZU2x6A9Yb396LTR59Mecy5fnA19MkV9HIhEIXuER2F+EcJC0eJq6tkyZ+GZG1JOCrxE4GXlkQDzQR5rNWr8bpEeTqsQHnAN1Xi9NnF25yLBvzQwmfZLVocFS2+Mlhn3DcxRAe6jlF0pPQ9pgXeaFZF246nerymk5EyLQdcewErFQMfURSubbJtD1YeaWz3oRjDlfKsVDTb7cdbW0WacvvxYeBytDvbekfNWgF5U5AuFKRTXXcJ0CX2c4/L2RrLyyPOdw/5zVc/5GoyHQ6aPHFuz6WMtntTfuvaB/jWc+84RhhnEa1gxmpjxJ/vPsbf3Po854MD/vM/+mE9tlbGYnfiwjrYDYlf6pCbx/DN+o4OsrmWAbYXnjSoUxn6+HtDPNvK7LZmOowaZfPWT0KnW2C5LCl29/FWl+fafFkj00KUKpkhu3qnsBi/MM1YAPxajrZdmI23x5TNiGzR+AJMHkV8WFIGgu47illXMlkXqBKS6y3kml40bw2XWQrH/H/jZ/je1qt8KTnP1f4iYqSnJxgKuldKGruZrsZRqsp+sGQas9hqhvh+JQmovNYijhDGVilua93c63b1szfiB459smNJV1tOfbJ6tK0SaD348aFmVhs856XaT+C/ElcFAIC1b7nF9q1FwkbG00s77E61qvTSv3kCgG//6Ku8tLPB8OYj/PXnXmKQxbwzXOT3Lj/jUkwf7RyyEfdpezOe613hN7a/mWkWuKYqxTjg/NYh+/tt/BuRiYNSLL5u+lMcZOQtj9JEF9g+fI5BjL2UdwL8QcBsc0F/ZqFpo07NZVLeg063wLIndZP40ZjSqBdeHM01aLHM4ip2m1gplaaagTypC5aFJoxjMsE3aI+czLCeBxv7pKR03UeLMKB5Cybruo5ruaMZaNtbYLN1xNXJEntZh9+59j4ObvZoX9Xjio60uuZlJf6RUYuiUBdhxsRqhSHFwaEufT+ZaMauN58fDBHtFkJKStshtmsKHwS+dublD+G8M6X4w90xyabeUIJtU5LfdBaVJjDQqhJZu03rdqZbY5k2WpMNRfcNvQC3m+dQzYLO8og/+fIl/di9hOaTesH/yZcv8dTFm4yu9vjs7UdpBNr/8NFLb7kSNQCb0SH/6MvfxYXlQ46mMZFfuKYqopnz+dceI7rpE+/q/PHutVowZyhdsF+62iK8fkRY81rbKuohpgrirDANLY1dkc63AzsJnfkpzuiMjtFJS9xcAYboyiK5Uuo5IcQS8C+Ax9DJ9T90t4Jdd5DJyfasTWGbO5oAOQdV1uOgbEiI7XTq+0iq3AORZrqIWRTgHWmE2xU68CG6PWJ2rk28n5F1fGYLHvGOJGsbWLcZ8cdfeprWyoSX2WD2epfFq7i6TY39kvggxZvkWm2a1ZqbGyoHQ+RCTzdt8bw5qSfQEKzuzcFcSZ8/GvwavghAgTCeigeaW6Xcrmhjgazx6e30tQ/j0nnkrHBqVHSQIWcFzbSkCCMaBzllELiw7vY7ujD0fth2/oVZP2Zm/vd6qfZBoH0QUS9ha/2Qz3z2GcIN/ewrjRH/0xc/DjdiLk8DV6bGhq/L3ZB4T1L681ly4b4GQbydPtP3rbv31udgPdTFWo/StjoGLQ1jv2pcs9bTpX46J7fX7kd9+h6l1F7t/c8Bn1JK/aIQ4ufM+//ia15BCESrqVUJm6Nta8laxrAOvHqlccsg9eM2tNwa5FJqQ9d0NnI9IwyzRLdH5Ata/1z7Qkr/sdgVO84OA6Zrivxmj6xXsvSargJudW8X0zRJKz/EpBZKkFeImgMQpkkFO8Mdjecdswt4rvFXiXx97vP9X36guVWe1Aum23Lok108Kg6hu6F9GDXdOl1t4e8NdXxUawN/XCAzn8ioUtM1QdiH8mpE77L2a/gToQP30IXGwqsRsw3dpzoNAxrLGXI1IX9H3+fz/ceIegk5ugbT9d9/lDAD3+i5jR1FEep+E+13phRhk6zt4Q/N0lzr4Q8zV8XRPa95Dl072NeG9fkN3Z2pZkN4O32yrWWiNyvfyr3oYWyKHwA+bv7/J8Afci+mKFVlG9QiRucYAzQsa3H9OKqcXAaunYsRsoWZTdswp5fXq4IXJUwSfEBOfPAljYOC0rcx+QJR6OIH6paguVfgjwuCQ8NYpjUYs1Qzg4lhsk7GcjTWjWTyXMOtxwL9XLNLE+9kpYjwPFAg220ovHpA4H3PrTB2VRn7EGtUy9vpuzbI2UoHuvPRx3nLI0pS7c8YF5ShpHstdwF04TgwWWwato33dGUM2zI4WdUh38GejjZIj0JeTzdoXA1c0xb6Hnm/RXgkCa9K0h6svZgy3KoiWZdenWljOvJoHOSEBympycGXWUB8fegqH1qI1VGaafvh3IqDY1W35bIPfSoU7qR0UqZQwO8JIRTwvyilPgmcU0rdNJ/fQpfqv4Pm6p3KdlXvqea8U0XhjqvjTq565KgJGFSjsfu+kLJymNnB9geVnyOOKrXLk8hZSrnYJtqbkZsw88atnM41SRHojkZB3zgOjRRyaaS+p0NVqOVAYHp9DwbIVquCm21gI1BOEzzTs4/MZNlZcAH47N7/CUpxPnA1XO9/boMuKg7noEfVbWnjNM3cwrDoDVS1bO1neTdm9GjDhU54M4/WqODoYuACCZs3YOEt/fnRRb2wvRSGj0H3DUkwFhShYmJUMJkJZ0CDrsk0Phe4EJnGzYQy8nRod5oRhoFRjXQX1GB7H9UfIM9vVJKvzhjWWXd7DxluOE+2kyrpnaruveikTPGdSqnrQog14PeFEK/WP1RKKcMwd5BhoE+CriXrOhkd61OhigKV5wjfn6sLZWOEVKEbLapkps+zn5dlpavXvOUuQrXWg8L6E6TnIeLAFUEDYAIsxHj7elxyMqtah1nKC9eosqx55dVojGy1nLTTkq/6mi0irawfw0hGlcz41sb30VxYJ0n6vND/bYB2/ZYnntt4XREG1E8UgzGyG8/3yQ59hz6Voe8WkRiMKVdbhKPC+QCaVwYkmx1aOyWtqyMaB02mSzrfBCAwPoQygEc+nTHcCpCZzoRr7ZgErUCQLEL3bUXzdspsKcCblS4Trow8wutH5Csd/L2MvBtT1mBlgPz9jzvUTIYBXLuJsP1Ljs2JSFJIUiSGC02B6dn7tuCdu83inXQiplBKXTevO0KI3wQ+AtwWQmwopW6aMo/3VtpKXfep3r3IGtYWwqz7Kuqf26QkRmMNe1rI9phx7nIygppNUpYus010O7o5C1RNWTyJasUEt7SxZpnBxS9Z/d/aPY24yhSkZjhbH0VROOYFnJNuTq0ygEODCFWWRLLBOf9RRsVB64HmFgNJ7h2C6fKk4hCZ5lVAoMnKc6qF8YCrMEDFIeHumOjNsfaEA6QZ8fUhcZq5xKXGQSW5e29MSJdC/HFB3vLovaV/s3B37O6RLoV035jovIdZQXQAk3MhzdumD/ZwZsJPchiM8DHGtJl7dW6lak2GCfw7t0Jhw8RN7JM6v6Gh2GMtzAB8FnVRhxPSSToZtQCplBqa//8q8F8D/zfw48Avmtf/6553E0DgIwOfwjRkt7uo2+WN6lFOjZe3oRu1iLZWm1SeUx5UQIzsdnTcUE3tOp7BZvV3W6zZtfy1Rnsy0629JlPtgOsPqsUPVSlPY784RrRUC1EBKqO7FvRYjMbaR2MlTJ6TTTVSFvgxWZ6wl10HmD7I3Kq6DVVDXmyugS1qUHYbyBeNoH90s5IUZoct1npOUrgMPuMoa14ZzDkHtYoSMlsKaNxMnB0ANWO+7RGjVbUy8gh3x4SvbDvGteCA3N5146PbqIpED6aQZlqSfPltZLjhImKBihHSDJn6jsmdHWGa1Xj3kU9xEklxDvhNXWcZH/hnSqnfFUJ8Fvg1IcRPAleBHzrxXc8IgFQlfCH5AwAUJRv+Rfrp7gDNDGdz+x7RSWrJvgV86C7H94FP3O8NrVrk2QqAJjBORhEijlw/bW9Vi3BnVJud93jd2eLgsPIc10KxncFuAxDt/a0UqEXikufa9shzraPWMwAtHQMC5iSFCX93fgmLMh3vt1FD12jEtIIFPhb8oH6O0Riv0eKN9PMPPLdyMIWVRZRRNbQX2+yeJoJUDqYI01/b6eNpVoVa12wOOZiSr3QQgzF+zSNsfQJlt4E/Lmi9dBMVh/iDgGSzM6c+Lbx8yPDpBYJR4a4rwtDVBc5WOnpXX1lEDMZ4RnJYD3RuPpdpTv7+x3VV9bSKfZOpryXHYDqPTtXytIGv43wKxV3TLmW75YoZeKvL86pI/DUWPLhwa5f4X9Pr3W3tYu1WkZc27AK4kwFgPqS91ub4DrUJEwULDiiw43bBjWmq1UDM8x+DbVVRuM8figxyYzF6XVs2dxClVSlsCRy3iGpU199Bq0gqDjXD3d6j3HxqLsQiHEyZPbFGuDtGDMbEZkHWI3U7r2l9Pl1tESa5hoDNWILtfRfiDmbxpplTd6QZu0x138JirTdXnMDaSJaZ9Ll+bfyZ3giSkxd+OvV8ClXoBinOCK1BlRbOFL2urieLRZvGzggX7RaivoDtYpsmDvmBipnquRvWaeiOHWcEmDemjzNm/RnsPTHRrcZWqt+zXvHP2hFzbQYsGGDelrOThzcfJ+unAHQ7L8AzTGkby7sF8/IbepyPbpKbXAS3UNOsqlreHyBva/THHySIXpfGK7eYvk8XQ5NpyWwpIDowwX11ZjM7c7C97zzr/nCmdfxIQ8UAfqxD3stuQ8ccDUawssisVpHE38sc9Fp2Y9ftFbQ08/eyOSi23nrNMx7wbGv53UWf3k1yBnVtcdQ93GTzhjRU0sCGStTVofKoP68+mV1dNLWfwjJJsbuP12456Jd6+Lo1oG3wYTJDtP2qCLS9WZ0B66Eox/6fkyaWLEPY2lbBMebIcv0c9+dnqk2S0Au8nkvQH8C5FY1AJdVikY/qOkoiSV3xNJkaFCdNyS7qDLwAjFqkB2UlQvz2gX6klQ6NmxUzysGUdHMBOQjJV7RU9geJlljbu8huW99zOKtakFmpFvoabu22KWN/Di2y6pEdr70XAINR1VI6SZFpOJdpZxnyfuiUc7TFHPoyR41Y6+I1DN9SfacWMOfxdqqX5zmYszjs49XUGKYJshFXatDxhVfzktsJnmM2Mz4XwZvniLrNULdxDvvaXjru1Ta+i3I2g9lsvn94q6n9Hnfr+XdSMsXQVBy6HAJWFrUqstOnWOvhDxItLWyfD5grnqbikNIwCOByvscX2nReO9IoVE1fd+EkVj3bMzkPNfVJw8IZ5ZaxYy6/hReH8+0C4hB/gItnkmHg7iEGY2QYIKzn3YSlWNg4qKlNwfa+ZhyTZQg4tfHrNx211Kad3bWBqiDYsfwKS8f7WbgkpZpksd1WPbPQZG0B22tYsrka5WDo8h2Er9sD1EO864tWFYXOITdjc/6UY+mjKplVjjpTz8qNwX53QTPM3DPaMT5k3Sdt3MZzYQ1WFZLbu5pJ6lSDacvQp4xaLpMNgPMbyMGU6KBi1joc6nbhNMN/61BvJI9u6nPSecPW2QHvfxrSzIW3+2bRWuYQSVrFa9l7vnHFSTcrgepxUGIwxrdggZUKRoWU8ep8KPkJ6NQrBN6hy/u+rhJYC+GA2kI2/SzqzCPiaH5Bx5Henevfr9kUBD7CZPWp8UQv/Fqyj1OZrG/BqFJWGtkwDbLc2UJWlYMqD19VcEEAAASKSURBVORu57lzLWNbpKomiWyFwIelYHtf+xlq+jZoXd/b6aPQHmTnCNtadee4nbS2S9smMOHueM5Osbu0v5fNOwy3VhE7/bmd3iY3+Xs6fskyh43kdQxhYrSOxzapNHUMYe2Tuoe+klLD+fxs4weRiVYd85XOiXO0z/IpzuiMjtEpSwoBeV6pTjCvCtUC5agjObXQcuvxruv7NkoVaqEhtUaT9V2/7j+w8TMuB8KGtRv0yaJL1hMNJmTDGs3WxrBpp9Zu8bw77BFnLxlJNFcH6jjU+wCkAh3H5Cp3UOUeyMEUlaaUcY/wlW2XE84HnqzqJdXUIrvbSvOqvcYmdIRKqogk1buqMaBlGFRSyao/cTWeMvSR9nq1a9h7Oni4Zhhbn0Y9NGUujDzN8AfVd+xzzIWyDMZzAMS96NRtirpOD1SGsfVPuJFZxKlaTI5BarFNYMSdiU9SyWzecWYKOkONwQxZ2BfQKtR44kCAenEF932LWtUSiPQYazaNLYDmGFU780QYVnbEcV/LMcZ9EBJF6dAZh/xAZRjbsIowRD75GAB5DbosQ39+Mdvj3YZewAblybaWKyM6TcGoO/Z79hp2sVv/gTWArTOu7jdQceiOz0W/ouFkGx5SqVVxxcBGZXLfR6tsVcgJOtBx9+uVKdAL63jHHq/W384ZqFYnb8Q6Otbq7GZHdXCp9V8YRKoeYKhJM1Q5MzCwDT0/ZtDbe91RacRQPY+cfL6jqyoKB/eWo7G2X3x/LorW3ctBvjXbyj9WMfBBqOanmMsfMLusTP07KlpYG0QmOelygwDuWKxu8a0sovYOnTMQoIx7zqknel2KboOyq/0dylTTKC/pioW+666k7QLHfIMRpCk+OtbKQbE2i3CAi1+ShsGd/UCFWDl/iLGnmq/vu+e/n/xsAKHUXaOS/0JICLELjIG9e537l5hWeLjnu6CUWr3fL/1bMrfwcPN7ork9VaYAEEK8oJR67t5n/uWk9/L5vtHnFk7nGc/QpzM6o2N0xhRndEbH6L1gik++B/c8TXovn+8bfW7hFJ7x1G2KMzqjr3c6U5/O6IyO0akxhRDi+4QQrwkh3jAFvr4hSAhxRQjxJSHEF4QQL5hjS0KI3xdCXDavi/e6zkOO4Wxu30U6FaYQQnjAPwT+OvAs8CNCiGdP496nRN+jlPpwDSq0Ff4uAZ8y7/9C6Gxu3/25PS1J8RHgDaXUW0qpFPjn6Cp436j0A+jKfpjX/+Av8F5nc/su02kxxSZwrfZ+2xz7RiBbPfFzpmIfnLDC37tEZ3P7LtOpxz59A9IDV088o3vSezK3pyUprgPna++3zLG/9FSvngjMVU8EuJ8Kfw9IZ3P7LtNpMcVngUtCiMeFECHwt9FV8P5SkxCiJYTo2P/R1RNfpqrwByetnvjgdDa37zKdivqklMqFED8DPA94wC8rpb58Gvf+C6b3vHri2dy++3N75tE+ozM6Rmce7TM6o2N0xhRndEbH6IwpzuiMjtEZU5zRGR2jM6Y4ozM6RmdMcUZndIzOmOKMzugYnTHFGZ3RMfr/Aau4U7xGdCsjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5644b86358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X_train_keep[len(X_train_keep)-1,:,:,0])\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(X_train_keep[len(X_train_keep)-1,:,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building of Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    #zoom_range=[0.1,0.1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper functions\n",
    "def one_hot(Y, num_cl):\n",
    "    d = np.zeros((len(Y),num_cl), dtype='int8')\n",
    "    for row,col in enumerate(Y):\n",
    "        d[row, col] = 1\n",
    "    return d\n",
    "one_hot(np.array((1,0,1,1,2)), 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py:935: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (11032, 64, 64, 2) (2 channels).\n",
      "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_generator = datagen.flow(\n",
    "        x = X_train_keep,\n",
    "        y = one_hot(y_train_keep, num_classes),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (3,3),kernel_initializer='he_normal',padding='same',input_shape=(64,64,2)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Convolution2D(32, (3,3),kernel_initializer='he_normal',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Convolution2D(64, (3,3),kernel_initializer='he_normal',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Convolution2D(64, (3,3),kernel_initializer='he_normal',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())#macht einen vektor aus dem output\n",
    "model.add(Dropout(0.3))            \n",
    "model.add(Dense(200,kernel_initializer='he_normal'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        608       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               3277000   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,344,290\n",
      "Trainable params: 3,344,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((None, 64, 64, 2), (None, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.summary())\n",
    "model.input_shape, model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "def create_result_subdir(result_dir, run_desc):\n",
    "    ordinal = 0\n",
    "    for fname in glob.glob(os.path.join(result_dir, '*')):\n",
    "        try:\n",
    "            fbase = os.path.basename(fname)\n",
    "            ford = int(fbase[:fbase.find('-')])\n",
    "            ordinal = max(ordinal, ford + 1)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    result_subdir = os.path.join(result_dir, '%03d-%s' % (ordinal, run_desc))\n",
    "    if os.path.isdir(result_subdir):\n",
    "        return create_result_subdir(result_dir, run_desc) # Retry.\n",
    "    if not os.path.isdir(result_subdir):\n",
    "        os.makedirs(result_subdir)\n",
    "    return result_subdir, ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdir, ordinal = create_result_subdir('results_bayes', run_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results_bayes/015-chong_no_batch_only_EndoErMito'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_cb = keras.callbacks.TensorBoard(log_dir=resdir, histogram_freq=0, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint( \n",
    "    filepath =  resdir+\"/weights_Chong_data_epoch_{epoch:03d}-{val_loss:.2f}.hdf5\",\n",
    "    verbose = 1, \n",
    "    save_best_only = False,\n",
    "    period = 25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2392, 10), 10, 19, (11032, 10))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(y_valid_keep, num_classes).shape, num_classes, num_class_org,one_hot(y_train_keep, num_classes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 11s - loss: 2.0859 - acc: 0.2400 - val_loss: 1.7894 - val_acc: 0.3181\n",
      "Epoch 2/500\n",
      " - 9s - loss: 1.6730 - acc: 0.3744 - val_loss: 1.6588 - val_acc: 0.4214\n",
      "Epoch 3/500\n",
      " - 10s - loss: 1.5169 - acc: 0.4408 - val_loss: 1.4318 - val_acc: 0.5184\n",
      "Epoch 4/500\n",
      " - 9s - loss: 1.3043 - acc: 0.5245 - val_loss: 1.2369 - val_acc: 0.5727\n",
      "Epoch 5/500\n",
      " - 10s - loss: 1.1784 - acc: 0.5729 - val_loss: 1.0164 - val_acc: 0.6543\n",
      "Epoch 6/500\n",
      " - 9s - loss: 1.0389 - acc: 0.6242 - val_loss: 0.8699 - val_acc: 0.6961\n",
      "Epoch 7/500\n",
      " - 9s - loss: 0.9759 - acc: 0.6517 - val_loss: 0.8233 - val_acc: 0.7149\n",
      "Epoch 8/500\n",
      " - 9s - loss: 0.9299 - acc: 0.6634 - val_loss: 0.7652 - val_acc: 0.7287\n",
      "Epoch 9/500\n",
      " - 9s - loss: 0.8648 - acc: 0.6820 - val_loss: 0.6737 - val_acc: 0.7701\n",
      "Epoch 10/500\n",
      " - 10s - loss: 0.8325 - acc: 0.6986 - val_loss: 0.6727 - val_acc: 0.7625\n",
      "Epoch 11/500\n",
      " - 9s - loss: 0.7988 - acc: 0.7109 - val_loss: 0.6247 - val_acc: 0.7977\n",
      "Epoch 12/500\n",
      " - 9s - loss: 0.7643 - acc: 0.7213 - val_loss: 0.6119 - val_acc: 0.7797\n",
      "Epoch 13/500\n",
      " - 9s - loss: 0.7510 - acc: 0.7345 - val_loss: 0.6088 - val_acc: 0.7763\n",
      "Epoch 14/500\n",
      " - 9s - loss: 0.7058 - acc: 0.7498 - val_loss: 0.5956 - val_acc: 0.8002\n",
      "Epoch 15/500\n",
      " - 10s - loss: 0.6822 - acc: 0.7607 - val_loss: 0.5095 - val_acc: 0.8278\n",
      "Epoch 16/500\n",
      " - 9s - loss: 0.6667 - acc: 0.7596 - val_loss: 0.5233 - val_acc: 0.8219\n",
      "Epoch 17/500\n",
      " - 9s - loss: 0.6350 - acc: 0.7739 - val_loss: 0.5317 - val_acc: 0.8140\n",
      "Epoch 18/500\n",
      " - 9s - loss: 0.6374 - acc: 0.7755 - val_loss: 0.4942 - val_acc: 0.8265\n",
      "Epoch 19/500\n",
      " - 9s - loss: 0.6052 - acc: 0.7815 - val_loss: 0.4635 - val_acc: 0.8457\n",
      "Epoch 20/500\n",
      " - 9s - loss: 0.5855 - acc: 0.7929 - val_loss: 0.4328 - val_acc: 0.8533\n",
      "Epoch 21/500\n",
      " - 10s - loss: 0.5729 - acc: 0.7956 - val_loss: 0.4643 - val_acc: 0.8457\n",
      "Epoch 22/500\n",
      " - 9s - loss: 0.5559 - acc: 0.8027 - val_loss: 0.4442 - val_acc: 0.8503\n",
      "Epoch 23/500\n",
      " - 10s - loss: 0.5338 - acc: 0.8128 - val_loss: 0.4927 - val_acc: 0.8265\n",
      "Epoch 24/500\n",
      " - 10s - loss: 0.5440 - acc: 0.8079 - val_loss: 0.3939 - val_acc: 0.8650\n",
      "Epoch 25/500\n",
      " - 9s - loss: 0.5098 - acc: 0.8258 - val_loss: 0.3533 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00025: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_025-0.35.hdf5\n",
      "Epoch 26/500\n",
      " - 9s - loss: 0.5245 - acc: 0.8164 - val_loss: 0.3868 - val_acc: 0.8658\n",
      "Epoch 27/500\n",
      " - 9s - loss: 0.4995 - acc: 0.8234 - val_loss: 0.3492 - val_acc: 0.8800\n",
      "Epoch 28/500\n",
      " - 9s - loss: 0.4868 - acc: 0.8306 - val_loss: 0.3455 - val_acc: 0.8842\n",
      "Epoch 29/500\n",
      " - 10s - loss: 0.4818 - acc: 0.8348 - val_loss: 0.3470 - val_acc: 0.8909\n",
      "Epoch 30/500\n",
      " - 10s - loss: 0.4618 - acc: 0.8439 - val_loss: 0.3447 - val_acc: 0.8825\n",
      "Epoch 31/500\n",
      " - 10s - loss: 0.4419 - acc: 0.8491 - val_loss: 0.3428 - val_acc: 0.8901\n",
      "Epoch 32/500\n",
      " - 9s - loss: 0.4382 - acc: 0.8483 - val_loss: 0.3665 - val_acc: 0.8775\n",
      "Epoch 33/500\n",
      " - 10s - loss: 0.4494 - acc: 0.8487 - val_loss: 0.3287 - val_acc: 0.8921\n",
      "Epoch 34/500\n",
      " - 10s - loss: 0.4394 - acc: 0.8485 - val_loss: 0.3252 - val_acc: 0.9001\n",
      "Epoch 35/500\n",
      " - 9s - loss: 0.4269 - acc: 0.8549 - val_loss: 0.3740 - val_acc: 0.8616\n",
      "Epoch 36/500\n",
      " - 9s - loss: 0.4153 - acc: 0.8522 - val_loss: 0.3006 - val_acc: 0.8963\n",
      "Epoch 37/500\n",
      " - 10s - loss: 0.4130 - acc: 0.8593 - val_loss: 0.3124 - val_acc: 0.8967\n",
      "Epoch 38/500\n",
      " - 9s - loss: 0.4008 - acc: 0.8583 - val_loss: 0.3075 - val_acc: 0.8955\n",
      "Epoch 39/500\n",
      " - 10s - loss: 0.4189 - acc: 0.8556 - val_loss: 0.3472 - val_acc: 0.8804\n",
      " - 10s - loss: 0.3547 - acc: 0.8774 - val_loss: 0.2666 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00050: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_050-0.27.hdf5\n",
      "Epoch 51/500\n",
      " - 10s - loss: 0.3317 - acc: 0.8854 - val_loss: 0.2566 - val_acc: 0.9110\n",
      "Epoch 52/500\n",
      " - 9s - loss: 0.3490 - acc: 0.8766 - val_loss: 0.2916 - val_acc: 0.8951\n",
      "Epoch 53/500\n",
      " - 9s - loss: 0.3505 - acc: 0.8784 - val_loss: 0.2736 - val_acc: 0.9101\n",
      "Epoch 54/500\n",
      " - 10s - loss: 0.3346 - acc: 0.8884 - val_loss: 0.2764 - val_acc: 0.9068\n",
      "Epoch 55/500\n",
      " - 10s - loss: 0.3297 - acc: 0.8866 - val_loss: 0.2327 - val_acc: 0.9214\n",
      "Epoch 56/500\n",
      " - 9s - loss: 0.3285 - acc: 0.8879 - val_loss: 0.2672 - val_acc: 0.9055\n",
      "Epoch 57/500\n",
      " - 9s - loss: 0.3080 - acc: 0.8909 - val_loss: 0.3106 - val_acc: 0.8917\n",
      "Epoch 58/500\n",
      " - 9s - loss: 0.3213 - acc: 0.8890 - val_loss: 0.2542 - val_acc: 0.9176\n",
      "Epoch 59/500\n",
      " - 9s - loss: 0.3152 - acc: 0.8914 - val_loss: 0.2613 - val_acc: 0.9122\n",
      "Epoch 60/500\n",
      " - 10s - loss: 0.3341 - acc: 0.8833 - val_loss: 0.2275 - val_acc: 0.9227\n",
      "Epoch 61/500\n",
      " - 9s - loss: 0.3193 - acc: 0.8921 - val_loss: 0.2701 - val_acc: 0.9080\n",
      "Epoch 62/500\n",
      " - 9s - loss: 0.3028 - acc: 0.8924 - val_loss: 0.2546 - val_acc: 0.9164\n",
      "Epoch 63/500\n",
      " - 10s - loss: 0.2981 - acc: 0.8955 - val_loss: 0.2637 - val_acc: 0.9189\n",
      "Epoch 64/500\n",
      " - 9s - loss: 0.3107 - acc: 0.8911 - val_loss: 0.2672 - val_acc: 0.9110\n",
      "Epoch 65/500\n",
      " - 9s - loss: 0.3155 - acc: 0.8895 - val_loss: 0.2515 - val_acc: 0.9130\n",
      "Epoch 66/500\n",
      " - 9s - loss: 0.3002 - acc: 0.8967 - val_loss: 0.2495 - val_acc: 0.9164\n",
      "Epoch 67/500\n",
      " - 9s - loss: 0.3050 - acc: 0.8941 - val_loss: 0.2551 - val_acc: 0.9047\n",
      "Epoch 68/500\n",
      " - 10s - loss: 0.2976 - acc: 0.8960 - val_loss: 0.2712 - val_acc: 0.9084\n",
      "Epoch 69/500\n",
      " - 9s - loss: 0.2884 - acc: 0.8996 - val_loss: 0.2605 - val_acc: 0.9164\n",
      "Epoch 70/500\n",
      " - 9s - loss: 0.2924 - acc: 0.8996 - val_loss: 0.2822 - val_acc: 0.9043\n",
      "Epoch 71/500\n",
      " - 9s - loss: 0.2842 - acc: 0.8987 - val_loss: 0.2460 - val_acc: 0.9176\n",
      "Epoch 72/500\n",
      " - 9s - loss: 0.2850 - acc: 0.8996 - val_loss: 0.3172 - val_acc: 0.8917\n",
      "Epoch 73/500\n",
      " - 9s - loss: 0.2968 - acc: 0.9007 - val_loss: 0.2500 - val_acc: 0.9181\n",
      "Epoch 74/500\n",
      " - 9s - loss: 0.2864 - acc: 0.8991 - val_loss: 0.2811 - val_acc: 0.9009\n",
      "Epoch 75/500\n",
      " - 9s - loss: 0.2860 - acc: 0.9031 - val_loss: 0.2485 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00075: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_075-0.25.hdf5\n",
      "Epoch 76/500\n",
      " - 10s - loss: 0.2888 - acc: 0.8985 - val_loss: 0.2946 - val_acc: 0.9051\n",
      "Epoch 77/500\n",
      " - 9s - loss: 0.2881 - acc: 0.9012 - val_loss: 0.2677 - val_acc: 0.9064\n",
      "Epoch 78/500\n",
      " - 9s - loss: 0.2915 - acc: 0.9020 - val_loss: 0.3347 - val_acc: 0.8842\n",
      "Epoch 79/500\n",
      " - 9s - loss: 0.2853 - acc: 0.9022 - val_loss: 0.2654 - val_acc: 0.9059\n",
      "Epoch 80/500\n",
      " - 10s - loss: 0.2684 - acc: 0.9084 - val_loss: 0.2177 - val_acc: 0.9252\n",
      "Epoch 81/500\n",
      " - 9s - loss: 0.2787 - acc: 0.9025 - val_loss: 0.2169 - val_acc: 0.9235\n",
      "Epoch 82/500\n",
      " - 9s - loss: 0.2583 - acc: 0.9101 - val_loss: 0.2080 - val_acc: 0.9331\n",
      "Epoch 83/500\n",
      " - 9s - loss: 0.2752 - acc: 0.9083 - val_loss: 0.2497 - val_acc: 0.9176\n",
      "Epoch 84/500\n",
      " - 9s - loss: 0.2628 - acc: 0.9054 - val_loss: 0.2379 - val_acc: 0.9218\n",
      "Epoch 85/500\n",
      " - 9s - loss: 0.2580 - acc: 0.9101 - val_loss: 0.2664 - val_acc: 0.9064\n",
      "Epoch 86/500\n",
      " - 9s - loss: 0.2592 - acc: 0.9095 - val_loss: 0.2353 - val_acc: 0.9252\n",
      "Epoch 87/500\n",
      " - 9s - loss: 0.2569 - acc: 0.9120 - val_loss: 0.2296 - val_acc: 0.9185\n",
      "Epoch 88/500\n",
      " - 9s - loss: 0.2586 - acc: 0.9100 - val_loss: 0.2580 - val_acc: 0.9193\n",
      "Epoch 89/500\n",
      " - 10s - loss: 0.2677 - acc: 0.9085 - val_loss: 0.2536 - val_acc: 0.9130\n",
      "Epoch 90/500\n",
      " - 10s - loss: 0.2554 - acc: 0.9106 - val_loss: 0.2115 - val_acc: 0.9335\n",
      "Epoch 91/500\n",
      " - 10s - loss: 0.2523 - acc: 0.9109 - val_loss: 0.2144 - val_acc: 0.9327\n",
      "Epoch 92/500\n",
      " - 9s - loss: 0.2493 - acc: 0.9127 - val_loss: 0.2481 - val_acc: 0.9172\n",
      "Epoch 93/500\n",
      " - 10s - loss: 0.2513 - acc: 0.9139 - val_loss: 0.2416 - val_acc: 0.9235\n",
      "Epoch 94/500\n",
      " - 10s - loss: 0.2411 - acc: 0.9160 - val_loss: 0.2268 - val_acc: 0.9260\n",
      "Epoch 95/500\n",
      " - 10s - loss: 0.2436 - acc: 0.9168 - val_loss: 0.2460 - val_acc: 0.9214\n",
      "Epoch 96/500\n",
      " - 9s - loss: 0.2474 - acc: 0.9129 - val_loss: 0.3187 - val_acc: 0.8942\n",
      "Epoch 97/500\n",
      " - 10s - loss: 0.2572 - acc: 0.9131 - val_loss: 0.2495 - val_acc: 0.9151\n",
      "Epoch 98/500\n",
      " - 10s - loss: 0.2420 - acc: 0.9151 - val_loss: 0.2217 - val_acc: 0.9268\n",
      "Epoch 99/500\n",
      " - 9s - loss: 0.2396 - acc: 0.9153 - val_loss: 0.2382 - val_acc: 0.9218\n",
      "Epoch 100/500\n",
      " - 9s - loss: 0.2371 - acc: 0.9179 - val_loss: 0.2417 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00100: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_100-0.24.hdf5\n",
      "Epoch 101/500\n",
      " - 10s - loss: 0.2370 - acc: 0.9183 - val_loss: 0.2435 - val_acc: 0.9197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500\n",
      " - 9s - loss: 0.2509 - acc: 0.9118 - val_loss: 0.2264 - val_acc: 0.9243\n",
      "Epoch 103/500\n",
      " - 10s - loss: 0.2301 - acc: 0.9180 - val_loss: 0.2713 - val_acc: 0.9151\n",
      "Epoch 104/500\n",
      " - 9s - loss: 0.2352 - acc: 0.9187 - val_loss: 0.2255 - val_acc: 0.9247\n",
      "Epoch 105/500\n",
      " - 10s - loss: 0.2283 - acc: 0.9200 - val_loss: 0.2379 - val_acc: 0.9256\n",
      "Epoch 106/500\n",
      " - 9s - loss: 0.2407 - acc: 0.9153 - val_loss: 0.2474 - val_acc: 0.9231\n",
      "Epoch 107/500\n",
      " - 9s - loss: 0.2380 - acc: 0.9171 - val_loss: 0.2456 - val_acc: 0.9164\n",
      "Epoch 108/500\n",
      " - 9s - loss: 0.2382 - acc: 0.9145 - val_loss: 0.2344 - val_acc: 0.9243\n",
      "Epoch 109/500\n",
      " - 9s - loss: 0.2295 - acc: 0.9209 - val_loss: 0.2055 - val_acc: 0.9360\n",
      "Epoch 110/500\n",
      " - 9s - loss: 0.2430 - acc: 0.9133 - val_loss: 0.2021 - val_acc: 0.9356\n",
      "Epoch 111/500\n",
      " - 9s - loss: 0.2305 - acc: 0.9218 - val_loss: 0.2512 - val_acc: 0.9193\n",
      "Epoch 112/500\n",
      " - 10s - loss: 0.2262 - acc: 0.9237 - val_loss: 0.3209 - val_acc: 0.9030\n",
      "Epoch 113/500\n",
      " - 10s - loss: 0.2291 - acc: 0.9218 - val_loss: 0.1993 - val_acc: 0.9369\n",
      "Epoch 114/500\n",
      " - 9s - loss: 0.2379 - acc: 0.9180 - val_loss: 0.2758 - val_acc: 0.9076\n",
      "Epoch 115/500\n",
      " - 9s - loss: 0.2369 - acc: 0.9171 - val_loss: 0.2457 - val_acc: 0.9285\n",
      "Epoch 116/500\n",
      " - 9s - loss: 0.2340 - acc: 0.9160 - val_loss: 0.2152 - val_acc: 0.9335\n",
      "Epoch 117/500\n",
      " - 10s - loss: 0.2146 - acc: 0.9245 - val_loss: 0.2658 - val_acc: 0.9105\n",
      "Epoch 118/500\n",
      " - 9s - loss: 0.2293 - acc: 0.9166 - val_loss: 0.2381 - val_acc: 0.9218\n",
      "Epoch 119/500\n",
      " - 9s - loss: 0.2125 - acc: 0.9254 - val_loss: 0.2051 - val_acc: 0.9344\n",
      "Epoch 120/500\n",
      " - 9s - loss: 0.2242 - acc: 0.9213 - val_loss: 0.2397 - val_acc: 0.9273\n",
      "Epoch 121/500\n",
      " - 9s - loss: 0.2289 - acc: 0.9203 - val_loss: 0.2095 - val_acc: 0.9352\n",
      "Epoch 122/500\n",
      " - 9s - loss: 0.2185 - acc: 0.9229 - val_loss: 0.2115 - val_acc: 0.9394\n",
      "Epoch 123/500\n",
      " - 9s - loss: 0.2200 - acc: 0.9220 - val_loss: 0.2345 - val_acc: 0.9235\n",
      "Epoch 124/500\n",
      " - 9s - loss: 0.2180 - acc: 0.9254 - val_loss: 0.2542 - val_acc: 0.9222\n",
      "Epoch 125/500\n",
      " - 10s - loss: 0.2195 - acc: 0.9211 - val_loss: 0.2167 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00125: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_125-0.22.hdf5\n",
      "Epoch 126/500\n",
      " - 10s - loss: 0.2179 - acc: 0.9227 - val_loss: 0.2472 - val_acc: 0.9189\n",
      "Epoch 127/500\n",
      " - 10s - loss: 0.2183 - acc: 0.9251 - val_loss: 0.1845 - val_acc: 0.9469\n",
      "Epoch 128/500\n",
      " - 9s - loss: 0.2275 - acc: 0.9187 - val_loss: 0.2287 - val_acc: 0.9327\n",
      "Epoch 129/500\n",
      " - 9s - loss: 0.2143 - acc: 0.9242 - val_loss: 0.2165 - val_acc: 0.9298\n",
      "Epoch 130/500\n",
      " - 9s - loss: 0.2163 - acc: 0.9247 - val_loss: 0.2520 - val_acc: 0.9252\n",
      "Epoch 131/500\n",
      " - 9s - loss: 0.2052 - acc: 0.9279 - val_loss: 0.2561 - val_acc: 0.9222\n",
      "Epoch 132/500\n",
      " - 9s - loss: 0.2074 - acc: 0.9271 - val_loss: 0.2438 - val_acc: 0.9298\n",
      "Epoch 133/500\n",
      " - 10s - loss: 0.2106 - acc: 0.9276 - val_loss: 0.2426 - val_acc: 0.9218\n",
      "Epoch 134/500\n",
      " - 9s - loss: 0.2081 - acc: 0.9268 - val_loss: 0.2083 - val_acc: 0.9327\n",
      "Epoch 135/500\n",
      " - 10s - loss: 0.2042 - acc: 0.9281 - val_loss: 0.2017 - val_acc: 0.9406\n",
      "Epoch 136/500\n",
      " - 9s - loss: 0.2019 - acc: 0.9275 - val_loss: 0.2673 - val_acc: 0.9197\n",
      "Epoch 137/500\n",
      " - 10s - loss: 0.2132 - acc: 0.9281 - val_loss: 0.2492 - val_acc: 0.9193\n",
      "Epoch 138/500\n",
      " - 9s - loss: 0.1986 - acc: 0.9318 - val_loss: 0.2802 - val_acc: 0.9076\n",
      "Epoch 139/500\n",
      " - 10s - loss: 0.2090 - acc: 0.9281 - val_loss: 0.2540 - val_acc: 0.9189\n",
      "Epoch 140/500\n",
      " - 9s - loss: 0.2182 - acc: 0.9232 - val_loss: 0.2194 - val_acc: 0.9302\n",
      "Epoch 141/500\n",
      " - 9s - loss: 0.2092 - acc: 0.9270 - val_loss: 0.3471 - val_acc: 0.8951\n",
      "Epoch 142/500\n",
      " - 10s - loss: 0.2078 - acc: 0.9275 - val_loss: 0.2163 - val_acc: 0.9327\n",
      "Epoch 143/500\n",
      " - 10s - loss: 0.2151 - acc: 0.9274 - val_loss: 0.2798 - val_acc: 0.9126\n",
      "Epoch 144/500\n",
      " - 9s - loss: 0.2117 - acc: 0.9247 - val_loss: 0.2457 - val_acc: 0.9210\n",
      "Epoch 145/500\n",
      " - 9s - loss: 0.2092 - acc: 0.9263 - val_loss: 0.2933 - val_acc: 0.9130\n",
      "Epoch 146/500\n",
      " - 9s - loss: 0.1961 - acc: 0.9297 - val_loss: 0.2717 - val_acc: 0.9135\n",
      "Epoch 147/500\n",
      " - 10s - loss: 0.2088 - acc: 0.9265 - val_loss: 0.2781 - val_acc: 0.9151\n",
      "Epoch 148/500\n",
      " - 10s - loss: 0.2121 - acc: 0.9287 - val_loss: 0.2360 - val_acc: 0.9273\n",
      "Epoch 149/500\n",
      " - 9s - loss: 0.2070 - acc: 0.9260 - val_loss: 0.2525 - val_acc: 0.9202\n",
      "Epoch 150/500\n",
      " - 9s - loss: 0.1964 - acc: 0.9300 - val_loss: 0.2153 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00150: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_150-0.22.hdf5\n",
      "Epoch 151/500\n",
      " - 9s - loss: 0.2158 - acc: 0.9256 - val_loss: 0.2132 - val_acc: 0.9377\n",
      "Epoch 152/500\n",
      " - 9s - loss: 0.2046 - acc: 0.9296 - val_loss: 0.1966 - val_acc: 0.9448\n",
      "Epoch 153/500\n",
      " - 9s - loss: 0.1970 - acc: 0.9325 - val_loss: 0.2685 - val_acc: 0.9218\n",
      "Epoch 154/500\n",
      " - 9s - loss: 0.2065 - acc: 0.9303 - val_loss: 0.2571 - val_acc: 0.9243\n",
      "Epoch 155/500\n",
      " - 9s - loss: 0.2055 - acc: 0.9279 - val_loss: 0.2429 - val_acc: 0.9281\n",
      "Epoch 156/500\n",
      " - 10s - loss: 0.2001 - acc: 0.9282 - val_loss: 0.3042 - val_acc: 0.9135\n",
      "Epoch 157/500\n",
      " - 9s - loss: 0.2054 - acc: 0.9287 - val_loss: 0.2409 - val_acc: 0.9277\n",
      "Epoch 158/500\n",
      " - 9s - loss: 0.2032 - acc: 0.9303 - val_loss: 0.2533 - val_acc: 0.9235\n",
      "Epoch 159/500\n",
      " - 10s - loss: 0.1982 - acc: 0.9281 - val_loss: 0.2249 - val_acc: 0.9310\n",
      "Epoch 160/500\n",
      " - 9s - loss: 0.1926 - acc: 0.9327 - val_loss: 0.2130 - val_acc: 0.9344\n",
      "Epoch 161/500\n",
      " - 9s - loss: 0.1936 - acc: 0.9329 - val_loss: 0.2169 - val_acc: 0.9323\n",
      "Epoch 162/500\n",
      " - 10s - loss: 0.2016 - acc: 0.9303 - val_loss: 0.2019 - val_acc: 0.9385\n",
      "Epoch 163/500\n",
      " - 9s - loss: 0.1999 - acc: 0.9280 - val_loss: 0.2213 - val_acc: 0.9302\n",
      "Epoch 164/500\n",
      " - 9s - loss: 0.1939 - acc: 0.9339 - val_loss: 0.2244 - val_acc: 0.9331\n",
      "Epoch 165/500\n",
      " - 9s - loss: 0.1830 - acc: 0.9356 - val_loss: 0.2044 - val_acc: 0.9377\n",
      "Epoch 166/500\n",
      " - 10s - loss: 0.1909 - acc: 0.9326 - val_loss: 0.2601 - val_acc: 0.9218\n",
      "Epoch 167/500\n",
      " - 9s - loss: 0.2009 - acc: 0.9315 - val_loss: 0.2309 - val_acc: 0.9298\n",
      "Epoch 168/500\n",
      " - 10s - loss: 0.1848 - acc: 0.9323 - val_loss: 0.2666 - val_acc: 0.9214\n",
      "Epoch 169/500\n",
      " - 9s - loss: 0.1928 - acc: 0.9323 - val_loss: 0.2153 - val_acc: 0.9381\n",
      "Epoch 170/500\n",
      " - 10s - loss: 0.1927 - acc: 0.9313 - val_loss: 0.2482 - val_acc: 0.9227\n",
      "Epoch 171/500\n",
      " - 9s - loss: 0.1900 - acc: 0.9353 - val_loss: 0.2248 - val_acc: 0.9339\n",
      "Epoch 172/500\n",
      " - 10s - loss: 0.1937 - acc: 0.9310 - val_loss: 0.2195 - val_acc: 0.9344\n",
      "Epoch 173/500\n",
      " - 10s - loss: 0.1865 - acc: 0.9344 - val_loss: 0.2137 - val_acc: 0.9339\n",
      "Epoch 174/500\n",
      " - 10s - loss: 0.2032 - acc: 0.9301 - val_loss: 0.2442 - val_acc: 0.9293\n",
      "Epoch 175/500\n",
      " - 10s - loss: 0.1983 - acc: 0.9332 - val_loss: 0.2384 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00175: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_175-0.24.hdf5\n",
      "Epoch 176/500\n",
      " - 10s - loss: 0.1868 - acc: 0.9357 - val_loss: 0.2468 - val_acc: 0.9319\n",
      "Epoch 177/500\n",
      " - 9s - loss: 0.1852 - acc: 0.9339 - val_loss: 0.2054 - val_acc: 0.9402\n",
      "Epoch 178/500\n",
      " - 10s - loss: 0.1880 - acc: 0.9340 - val_loss: 0.2501 - val_acc: 0.9264\n",
      "Epoch 179/500\n",
      " - 9s - loss: 0.1876 - acc: 0.9345 - val_loss: 0.2472 - val_acc: 0.9264\n",
      "Epoch 180/500\n",
      " - 10s - loss: 0.1823 - acc: 0.9350 - val_loss: 0.2607 - val_acc: 0.9189\n",
      "Epoch 181/500\n",
      " - 10s - loss: 0.1982 - acc: 0.9322 - val_loss: 0.2805 - val_acc: 0.9156\n",
      "Epoch 182/500\n",
      " - 9s - loss: 0.2030 - acc: 0.9309 - val_loss: 0.2112 - val_acc: 0.9314\n",
      "Epoch 183/500\n",
      " - 9s - loss: 0.1813 - acc: 0.9346 - val_loss: 0.1975 - val_acc: 0.9373\n",
      "Epoch 184/500\n",
      " - 10s - loss: 0.1823 - acc: 0.9385 - val_loss: 0.2304 - val_acc: 0.9293\n",
      "Epoch 185/500\n",
      " - 9s - loss: 0.1777 - acc: 0.9381 - val_loss: 0.2048 - val_acc: 0.9369\n",
      "Epoch 186/500\n",
      " - 9s - loss: 0.1844 - acc: 0.9365 - val_loss: 0.3037 - val_acc: 0.9147\n",
      "Epoch 187/500\n",
      " - 9s - loss: 0.1797 - acc: 0.9361 - val_loss: 0.2021 - val_acc: 0.9394\n",
      "Epoch 188/500\n",
      " - 9s - loss: 0.1734 - acc: 0.9391 - val_loss: 0.2603 - val_acc: 0.9231\n",
      "Epoch 189/500\n",
      " - 10s - loss: 0.1895 - acc: 0.9354 - val_loss: 0.2619 - val_acc: 0.9264\n",
      "Epoch 190/500\n",
      " - 9s - loss: 0.1819 - acc: 0.9341 - val_loss: 0.2263 - val_acc: 0.9348\n",
      "Epoch 191/500\n",
      " - 9s - loss: 0.1820 - acc: 0.9383 - val_loss: 0.2332 - val_acc: 0.9293\n",
      "Epoch 192/500\n",
      " - 9s - loss: 0.1854 - acc: 0.9382 - val_loss: 0.1906 - val_acc: 0.9402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/500\n",
      " - 10s - loss: 0.1857 - acc: 0.9341 - val_loss: 0.2316 - val_acc: 0.9327\n",
      "Epoch 194/500\n",
      " - 9s - loss: 0.1798 - acc: 0.9365 - val_loss: 0.2291 - val_acc: 0.9344\n",
      "Epoch 195/500\n",
      " - 9s - loss: 0.1849 - acc: 0.9340 - val_loss: 0.2247 - val_acc: 0.9327\n",
      "Epoch 196/500\n",
      " - 9s - loss: 0.1856 - acc: 0.9337 - val_loss: 0.2380 - val_acc: 0.9319\n",
      "Epoch 197/500\n",
      " - 9s - loss: 0.1815 - acc: 0.9359 - val_loss: 0.2131 - val_acc: 0.9352\n",
      "Epoch 198/500\n",
      " - 9s - loss: 0.1904 - acc: 0.9349 - val_loss: 0.2440 - val_acc: 0.9289\n",
      "Epoch 199/500\n",
      " - 9s - loss: 0.1927 - acc: 0.9311 - val_loss: 0.2214 - val_acc: 0.9344\n",
      "Epoch 200/500\n",
      " - 9s - loss: 0.1842 - acc: 0.9329 - val_loss: 0.1961 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00200: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_200-0.20.hdf5\n",
      "Epoch 201/500\n",
      " - 9s - loss: 0.1780 - acc: 0.9367 - val_loss: 0.2296 - val_acc: 0.9344\n",
      "Epoch 202/500\n",
      " - 9s - loss: 0.1859 - acc: 0.9354 - val_loss: 0.2413 - val_acc: 0.9310\n",
      "Epoch 203/500\n",
      " - 9s - loss: 0.1782 - acc: 0.9366 - val_loss: 0.1907 - val_acc: 0.9431\n",
      "Epoch 204/500\n",
      " - 9s - loss: 0.1882 - acc: 0.9352 - val_loss: 0.1955 - val_acc: 0.9365\n",
      "Epoch 205/500\n",
      " - 9s - loss: 0.1759 - acc: 0.9374 - val_loss: 0.2013 - val_acc: 0.9360\n",
      "Epoch 206/500\n",
      " - 9s - loss: 0.1851 - acc: 0.9351 - val_loss: 0.1893 - val_acc: 0.9415\n",
      "Epoch 207/500\n",
      " - 9s - loss: 0.1789 - acc: 0.9389 - val_loss: 0.2286 - val_acc: 0.9327\n",
      "Epoch 208/500\n",
      " - 9s - loss: 0.1745 - acc: 0.9375 - val_loss: 0.2336 - val_acc: 0.9285\n",
      "Epoch 209/500\n",
      " - 9s - loss: 0.1738 - acc: 0.9387 - val_loss: 0.2088 - val_acc: 0.9390\n",
      "Epoch 210/500\n",
      " - 9s - loss: 0.1774 - acc: 0.9392 - val_loss: 0.2092 - val_acc: 0.9360\n",
      "Epoch 211/500\n",
      " - 9s - loss: 0.1745 - acc: 0.9389 - val_loss: 0.1886 - val_acc: 0.9381\n",
      "Epoch 212/500\n",
      " - 9s - loss: 0.1784 - acc: 0.9379 - val_loss: 0.2930 - val_acc: 0.9118\n",
      "Epoch 213/500\n",
      " - 9s - loss: 0.1756 - acc: 0.9386 - val_loss: 0.2157 - val_acc: 0.9365\n",
      "Epoch 214/500\n",
      " - 9s - loss: 0.1864 - acc: 0.9368 - val_loss: 0.2243 - val_acc: 0.9335\n",
      "Epoch 215/500\n",
      " - 9s - loss: 0.1765 - acc: 0.9340 - val_loss: 0.1935 - val_acc: 0.9440\n",
      "Epoch 216/500\n",
      " - 9s - loss: 0.1753 - acc: 0.9395 - val_loss: 0.2193 - val_acc: 0.9344\n",
      "Epoch 217/500\n",
      " - 9s - loss: 0.1632 - acc: 0.9436 - val_loss: 0.2599 - val_acc: 0.9273\n",
      "Epoch 218/500\n",
      " - 9s - loss: 0.1759 - acc: 0.9412 - val_loss: 0.2499 - val_acc: 0.9185\n",
      "Epoch 219/500\n",
      " - 9s - loss: 0.1752 - acc: 0.9401 - val_loss: 0.2567 - val_acc: 0.9235\n",
      "Epoch 220/500\n",
      " - 9s - loss: 0.1721 - acc: 0.9397 - val_loss: 0.2219 - val_acc: 0.9369\n",
      "Epoch 221/500\n",
      " - 9s - loss: 0.1698 - acc: 0.9399 - val_loss: 0.2183 - val_acc: 0.9335\n",
      "Epoch 222/500\n",
      " - 9s - loss: 0.1665 - acc: 0.9394 - val_loss: 0.2615 - val_acc: 0.9243\n",
      "Epoch 223/500\n",
      " - 9s - loss: 0.1794 - acc: 0.9373 - val_loss: 0.2397 - val_acc: 0.9302\n",
      "Epoch 224/500\n",
      " - 9s - loss: 0.1562 - acc: 0.9443 - val_loss: 0.2398 - val_acc: 0.9314\n",
      "Epoch 225/500\n",
      " - 9s - loss: 0.1650 - acc: 0.9442 - val_loss: 0.2492 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00225: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_225-0.25.hdf5\n",
      "Epoch 226/500\n",
      " - 9s - loss: 0.1777 - acc: 0.9360 - val_loss: 0.2549 - val_acc: 0.9273\n",
      "Epoch 227/500\n",
      " - 9s - loss: 0.1775 - acc: 0.9359 - val_loss: 0.2502 - val_acc: 0.9273\n",
      "Epoch 228/500\n",
      " - 9s - loss: 0.1852 - acc: 0.9372 - val_loss: 0.2542 - val_acc: 0.9227\n",
      "Epoch 229/500\n",
      " - 9s - loss: 0.1768 - acc: 0.9396 - val_loss: 0.3155 - val_acc: 0.9089\n",
      "Epoch 230/500\n",
      " - 9s - loss: 0.1778 - acc: 0.9385 - val_loss: 0.2408 - val_acc: 0.9268\n",
      "Epoch 231/500\n",
      " - 9s - loss: 0.1702 - acc: 0.9396 - val_loss: 0.2421 - val_acc: 0.9289\n",
      "Epoch 232/500\n",
      " - 9s - loss: 0.1630 - acc: 0.9431 - val_loss: 0.2515 - val_acc: 0.9264\n",
      "Epoch 233/500\n",
      " - 9s - loss: 0.1760 - acc: 0.9386 - val_loss: 0.2077 - val_acc: 0.9365\n",
      "Epoch 234/500\n",
      " - 9s - loss: 0.1746 - acc: 0.9388 - val_loss: 0.2180 - val_acc: 0.9411\n",
      "Epoch 235/500\n",
      " - 9s - loss: 0.1581 - acc: 0.9439 - val_loss: 0.2291 - val_acc: 0.9327\n",
      "Epoch 236/500\n",
      " - 9s - loss: 0.1553 - acc: 0.9451 - val_loss: 0.1731 - val_acc: 0.9498\n",
      "Epoch 237/500\n",
      " - 9s - loss: 0.1790 - acc: 0.9374 - val_loss: 0.1831 - val_acc: 0.9452\n",
      "Epoch 238/500\n",
      " - 9s - loss: 0.1607 - acc: 0.9441 - val_loss: 0.2821 - val_acc: 0.9160\n",
      "Epoch 239/500\n",
      " - 9s - loss: 0.1729 - acc: 0.9390 - val_loss: 0.2414 - val_acc: 0.9331\n",
      "Epoch 240/500\n",
      " - 9s - loss: 0.1677 - acc: 0.9379 - val_loss: 0.2149 - val_acc: 0.9381\n",
      "Epoch 241/500\n",
      " - 9s - loss: 0.1705 - acc: 0.9402 - val_loss: 0.2144 - val_acc: 0.9390\n",
      "Epoch 242/500\n",
      " - 9s - loss: 0.1623 - acc: 0.9431 - val_loss: 0.2467 - val_acc: 0.9273\n",
      "Epoch 243/500\n",
      " - 10s - loss: 0.1742 - acc: 0.9373 - val_loss: 0.2032 - val_acc: 0.9394\n",
      "Epoch 244/500\n",
      " - 9s - loss: 0.1580 - acc: 0.9435 - val_loss: 0.2421 - val_acc: 0.9277\n",
      "Epoch 245/500\n",
      " - 9s - loss: 0.1678 - acc: 0.9400 - val_loss: 0.2348 - val_acc: 0.9298\n",
      "Epoch 246/500\n",
      " - 9s - loss: 0.1641 - acc: 0.9410 - val_loss: 0.2370 - val_acc: 0.9319\n",
      "Epoch 247/500\n",
      " - 10s - loss: 0.1661 - acc: 0.9414 - val_loss: 0.2701 - val_acc: 0.9193\n",
      "Epoch 248/500\n",
      " - 9s - loss: 0.1654 - acc: 0.9420 - val_loss: 0.2709 - val_acc: 0.9231\n",
      "Epoch 249/500\n",
      " - 9s - loss: 0.1560 - acc: 0.9446 - val_loss: 0.2485 - val_acc: 0.9264\n",
      "Epoch 250/500\n",
      " - 9s - loss: 0.1789 - acc: 0.9391 - val_loss: 0.2265 - val_acc: 0.9293\n",
      "\n",
      "Epoch 00250: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_250-0.23.hdf5\n",
      "Epoch 251/500\n",
      " - 9s - loss: 0.1572 - acc: 0.9457 - val_loss: 0.2154 - val_acc: 0.9360\n",
      "Epoch 252/500\n",
      " - 9s - loss: 0.1611 - acc: 0.9398 - val_loss: 0.1979 - val_acc: 0.9444\n",
      "Epoch 253/500\n",
      " - 9s - loss: 0.1630 - acc: 0.9432 - val_loss: 0.2609 - val_acc: 0.9260\n",
      "Epoch 254/500\n",
      " - 9s - loss: 0.1628 - acc: 0.9442 - val_loss: 0.2067 - val_acc: 0.9348\n",
      "Epoch 255/500\n",
      " - 9s - loss: 0.1666 - acc: 0.9430 - val_loss: 0.1975 - val_acc: 0.9365\n",
      "Epoch 256/500\n",
      " - 9s - loss: 0.1679 - acc: 0.9402 - val_loss: 0.2327 - val_acc: 0.9298\n",
      "Epoch 257/500\n",
      " - 9s - loss: 0.1666 - acc: 0.9415 - val_loss: 0.1935 - val_acc: 0.9440\n",
      "Epoch 258/500\n",
      " - 9s - loss: 0.1690 - acc: 0.9409 - val_loss: 0.2505 - val_acc: 0.9264\n",
      "Epoch 259/500\n",
      " - 9s - loss: 0.1544 - acc: 0.9459 - val_loss: 0.2280 - val_acc: 0.9323\n",
      "Epoch 260/500\n",
      " - 9s - loss: 0.1535 - acc: 0.9481 - val_loss: 0.2139 - val_acc: 0.9369\n",
      "Epoch 261/500\n",
      " - 9s - loss: 0.1642 - acc: 0.9457 - val_loss: 0.1920 - val_acc: 0.9431\n",
      "Epoch 262/500\n",
      " - 9s - loss: 0.1649 - acc: 0.9412 - val_loss: 0.2764 - val_acc: 0.9189\n",
      "Epoch 263/500\n",
      " - 9s - loss: 0.1597 - acc: 0.9432 - val_loss: 0.2083 - val_acc: 0.9415\n",
      "Epoch 264/500\n",
      " - 10s - loss: 0.1575 - acc: 0.9433 - val_loss: 0.2264 - val_acc: 0.9331\n",
      "Epoch 265/500\n",
      " - 9s - loss: 0.1555 - acc: 0.9435 - val_loss: 0.2465 - val_acc: 0.9327\n",
      "Epoch 266/500\n",
      " - 9s - loss: 0.1749 - acc: 0.9390 - val_loss: 0.2215 - val_acc: 0.9323\n",
      "Epoch 267/500\n",
      " - 9s - loss: 0.1584 - acc: 0.9460 - val_loss: 0.2303 - val_acc: 0.9314\n",
      "Epoch 268/500\n",
      " - 9s - loss: 0.1653 - acc: 0.9411 - val_loss: 0.1969 - val_acc: 0.9398\n",
      "Epoch 269/500\n",
      " - 9s - loss: 0.1464 - acc: 0.9511 - val_loss: 0.2505 - val_acc: 0.9252\n",
      "Epoch 270/500\n",
      " - 9s - loss: 0.1585 - acc: 0.9462 - val_loss: 0.2107 - val_acc: 0.9360\n",
      "Epoch 271/500\n",
      " - 9s - loss: 0.1616 - acc: 0.9452 - val_loss: 0.2148 - val_acc: 0.9356\n",
      "Epoch 272/500\n",
      " - 9s - loss: 0.1602 - acc: 0.9452 - val_loss: 0.2124 - val_acc: 0.9335\n",
      "Epoch 273/500\n",
      " - 9s - loss: 0.1563 - acc: 0.9434 - val_loss: 0.2889 - val_acc: 0.9130\n",
      "Epoch 274/500\n",
      " - 9s - loss: 0.1674 - acc: 0.9418 - val_loss: 0.2504 - val_acc: 0.9319\n",
      "Epoch 275/500\n",
      " - 9s - loss: 0.1571 - acc: 0.9438 - val_loss: 0.2703 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00275: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_275-0.27.hdf5\n",
      "Epoch 276/500\n",
      " - 9s - loss: 0.1652 - acc: 0.9402 - val_loss: 0.2415 - val_acc: 0.9260\n",
      "Epoch 277/500\n",
      " - 9s - loss: 0.1633 - acc: 0.9419 - val_loss: 0.2266 - val_acc: 0.9302\n",
      "Epoch 278/500\n",
      " - 9s - loss: 0.1471 - acc: 0.9492 - val_loss: 0.2442 - val_acc: 0.9264\n",
      "Epoch 279/500\n",
      " - 9s - loss: 0.1420 - acc: 0.9508 - val_loss: 0.2292 - val_acc: 0.9335\n",
      "Epoch 280/500\n",
      " - 9s - loss: 0.1560 - acc: 0.9459 - val_loss: 0.2530 - val_acc: 0.9252\n",
      "Epoch 281/500\n",
      " - 9s - loss: 0.1549 - acc: 0.9436 - val_loss: 0.2563 - val_acc: 0.9227\n",
      "Epoch 282/500\n",
      " - 9s - loss: 0.1590 - acc: 0.9444 - val_loss: 0.2110 - val_acc: 0.9369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500\n",
      " - 9s - loss: 0.1645 - acc: 0.9437 - val_loss: 0.2127 - val_acc: 0.9373\n",
      "Epoch 284/500\n",
      " - 9s - loss: 0.1618 - acc: 0.9436 - val_loss: 0.2048 - val_acc: 0.9385\n",
      "Epoch 285/500\n",
      " - 9s - loss: 0.1631 - acc: 0.9417 - val_loss: 0.2151 - val_acc: 0.9365\n",
      "Epoch 286/500\n",
      " - 9s - loss: 0.1561 - acc: 0.9441 - val_loss: 0.1938 - val_acc: 0.9411\n",
      "Epoch 287/500\n",
      " - 10s - loss: 0.1436 - acc: 0.9495 - val_loss: 0.2472 - val_acc: 0.9289\n",
      "Epoch 288/500\n",
      " - 9s - loss: 0.1601 - acc: 0.9451 - val_loss: 0.2333 - val_acc: 0.9323\n",
      "Epoch 289/500\n",
      " - 9s - loss: 0.1506 - acc: 0.9474 - val_loss: 0.1975 - val_acc: 0.9423\n",
      "Epoch 290/500\n",
      " - 9s - loss: 0.1532 - acc: 0.9456 - val_loss: 0.2898 - val_acc: 0.9214\n",
      "Epoch 291/500\n",
      " - 9s - loss: 0.1540 - acc: 0.9459 - val_loss: 0.2083 - val_acc: 0.9394\n",
      "Epoch 292/500\n",
      " - 9s - loss: 0.1504 - acc: 0.9467 - val_loss: 0.1852 - val_acc: 0.9465\n",
      "Epoch 293/500\n",
      " - 9s - loss: 0.1705 - acc: 0.9417 - val_loss: 0.2120 - val_acc: 0.9348\n",
      "Epoch 294/500\n",
      " - 9s - loss: 0.1708 - acc: 0.9436 - val_loss: 0.2780 - val_acc: 0.9139\n",
      "Epoch 295/500\n",
      " - 9s - loss: 0.1573 - acc: 0.9465 - val_loss: 0.2309 - val_acc: 0.9310\n",
      "Epoch 296/500\n",
      " - 9s - loss: 0.1420 - acc: 0.9498 - val_loss: 0.2117 - val_acc: 0.9348\n",
      "Epoch 297/500\n",
      " - 10s - loss: 0.1536 - acc: 0.9462 - val_loss: 0.2574 - val_acc: 0.9214\n",
      "Epoch 298/500\n",
      " - 9s - loss: 0.1571 - acc: 0.9462 - val_loss: 0.2164 - val_acc: 0.9377\n",
      "Epoch 299/500\n",
      " - 9s - loss: 0.1413 - acc: 0.9503 - val_loss: 0.2428 - val_acc: 0.9277\n",
      "Epoch 300/500\n",
      " - 10s - loss: 0.1573 - acc: 0.9442 - val_loss: 0.2305 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00300: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_300-0.23.hdf5\n",
      "Epoch 301/500\n",
      " - 9s - loss: 0.1568 - acc: 0.9448 - val_loss: 0.2111 - val_acc: 0.9411\n",
      "Epoch 302/500\n",
      " - 10s - loss: 0.1468 - acc: 0.9484 - val_loss: 0.2218 - val_acc: 0.9356\n",
      "Epoch 303/500\n",
      " - 9s - loss: 0.1523 - acc: 0.9480 - val_loss: 0.2220 - val_acc: 0.9365\n",
      "Epoch 304/500\n",
      " - 9s - loss: 0.1501 - acc: 0.9479 - val_loss: 0.2095 - val_acc: 0.9335\n",
      "Epoch 305/500\n",
      " - 9s - loss: 0.1495 - acc: 0.9471 - val_loss: 0.2045 - val_acc: 0.9394\n",
      "Epoch 306/500\n",
      " - 9s - loss: 0.1483 - acc: 0.9476 - val_loss: 0.2264 - val_acc: 0.9344\n",
      "Epoch 307/500\n",
      " - 9s - loss: 0.1505 - acc: 0.9492 - val_loss: 0.2179 - val_acc: 0.9369\n",
      "Epoch 308/500\n",
      " - 9s - loss: 0.1443 - acc: 0.9501 - val_loss: 0.2010 - val_acc: 0.9394\n",
      "Epoch 309/500\n",
      " - 9s - loss: 0.1656 - acc: 0.9434 - val_loss: 0.1995 - val_acc: 0.9423\n",
      "Epoch 310/500\n",
      " - 9s - loss: 0.1569 - acc: 0.9465 - val_loss: 0.1855 - val_acc: 0.9406\n",
      "Epoch 311/500\n",
      " - 9s - loss: 0.1513 - acc: 0.9471 - val_loss: 0.2169 - val_acc: 0.9356\n",
      "Epoch 312/500\n",
      " - 9s - loss: 0.1563 - acc: 0.9451 - val_loss: 0.2264 - val_acc: 0.9331\n",
      "Epoch 313/500\n",
      " - 9s - loss: 0.1399 - acc: 0.9526 - val_loss: 0.1922 - val_acc: 0.9440\n",
      "Epoch 314/500\n",
      " - 9s - loss: 0.1726 - acc: 0.9416 - val_loss: 0.2303 - val_acc: 0.9331\n",
      "Epoch 315/500\n",
      " - 9s - loss: 0.1538 - acc: 0.9456 - val_loss: 0.2312 - val_acc: 0.9310\n",
      "Epoch 316/500\n",
      " - 9s - loss: 0.1402 - acc: 0.9506 - val_loss: 0.2284 - val_acc: 0.9281\n",
      "Epoch 317/500\n",
      " - 9s - loss: 0.1447 - acc: 0.9491 - val_loss: 0.1887 - val_acc: 0.9457\n",
      "Epoch 318/500\n",
      " - 9s - loss: 0.1467 - acc: 0.9482 - val_loss: 0.2551 - val_acc: 0.9314\n",
      "Epoch 319/500\n",
      " - 10s - loss: 0.1518 - acc: 0.9474 - val_loss: 0.2423 - val_acc: 0.9298\n",
      "Epoch 320/500\n",
      " - 9s - loss: 0.1486 - acc: 0.9484 - val_loss: 0.2039 - val_acc: 0.9385\n",
      "Epoch 321/500\n",
      " - 9s - loss: 0.1562 - acc: 0.9463 - val_loss: 0.2296 - val_acc: 0.9339\n",
      "Epoch 322/500\n",
      " - 9s - loss: 0.1526 - acc: 0.9464 - val_loss: 0.2062 - val_acc: 0.9394\n",
      "Epoch 323/500\n",
      " - 9s - loss: 0.1541 - acc: 0.9471 - val_loss: 0.2405 - val_acc: 0.9285\n",
      "Epoch 324/500\n",
      " - 9s - loss: 0.1453 - acc: 0.9498 - val_loss: 0.2112 - val_acc: 0.9348\n",
      "Epoch 325/500\n",
      " - 9s - loss: 0.1399 - acc: 0.9486 - val_loss: 0.2046 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00325: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_325-0.20.hdf5\n",
      "Epoch 326/500\n",
      " - 9s - loss: 0.1489 - acc: 0.9499 - val_loss: 0.2101 - val_acc: 0.9390\n",
      "Epoch 327/500\n",
      " - 9s - loss: 0.1402 - acc: 0.9528 - val_loss: 0.2099 - val_acc: 0.9415\n",
      "Epoch 328/500\n",
      " - 9s - loss: 0.1495 - acc: 0.9477 - val_loss: 0.1930 - val_acc: 0.9444\n",
      "Epoch 329/500\n",
      " - 9s - loss: 0.1412 - acc: 0.9515 - val_loss: 0.2236 - val_acc: 0.9365\n",
      "Epoch 330/500\n",
      " - 9s - loss: 0.1466 - acc: 0.9475 - val_loss: 0.2239 - val_acc: 0.9335\n",
      "Epoch 331/500\n",
      " - 9s - loss: 0.1480 - acc: 0.9494 - val_loss: 0.1946 - val_acc: 0.9436\n",
      "Epoch 332/500\n",
      " - 10s - loss: 0.1505 - acc: 0.9469 - val_loss: 0.2013 - val_acc: 0.9385\n",
      "Epoch 333/500\n",
      " - 9s - loss: 0.1496 - acc: 0.9469 - val_loss: 0.2228 - val_acc: 0.9327\n",
      "Epoch 334/500\n",
      " - 9s - loss: 0.1409 - acc: 0.9501 - val_loss: 0.2468 - val_acc: 0.9277\n",
      "Epoch 335/500\n",
      " - 9s - loss: 0.1519 - acc: 0.9476 - val_loss: 0.2135 - val_acc: 0.9385\n",
      "Epoch 336/500\n",
      " - 10s - loss: 0.1520 - acc: 0.9477 - val_loss: 0.2274 - val_acc: 0.9377\n",
      "Epoch 337/500\n",
      " - 9s - loss: 0.1556 - acc: 0.9457 - val_loss: 0.2575 - val_acc: 0.9210\n",
      "Epoch 338/500\n",
      " - 9s - loss: 0.1494 - acc: 0.9466 - val_loss: 0.2201 - val_acc: 0.9339\n",
      "Epoch 339/500\n",
      " - 9s - loss: 0.1482 - acc: 0.9435 - val_loss: 0.1962 - val_acc: 0.9440\n",
      "Epoch 340/500\n",
      " - 9s - loss: 0.1379 - acc: 0.9535 - val_loss: 0.1912 - val_acc: 0.9436\n",
      "Epoch 341/500\n",
      " - 9s - loss: 0.1436 - acc: 0.9513 - val_loss: 0.2302 - val_acc: 0.9335\n",
      "Epoch 342/500\n",
      " - 10s - loss: 0.1420 - acc: 0.9516 - val_loss: 0.2645 - val_acc: 0.9252\n",
      "Epoch 343/500\n",
      " - 10s - loss: 0.1435 - acc: 0.9506 - val_loss: 0.2379 - val_acc: 0.9293\n",
      "Epoch 344/500\n",
      " - 9s - loss: 0.1511 - acc: 0.9460 - val_loss: 0.2381 - val_acc: 0.9264\n",
      "Epoch 345/500\n",
      " - 9s - loss: 0.1413 - acc: 0.9525 - val_loss: 0.2783 - val_acc: 0.9239\n",
      "Epoch 346/500\n",
      " - 9s - loss: 0.1319 - acc: 0.9518 - val_loss: 0.2481 - val_acc: 0.9314\n",
      "Epoch 347/500\n",
      " - 9s - loss: 0.1453 - acc: 0.9513 - val_loss: 0.2901 - val_acc: 0.9193\n",
      "Epoch 348/500\n",
      " - 9s - loss: 0.1546 - acc: 0.9439 - val_loss: 0.2163 - val_acc: 0.9394\n",
      "Epoch 349/500\n",
      " - 9s - loss: 0.1383 - acc: 0.9510 - val_loss: 0.2297 - val_acc: 0.9369\n",
      "Epoch 350/500\n",
      " - 10s - loss: 0.1433 - acc: 0.9498 - val_loss: 0.2272 - val_acc: 0.9310\n",
      "\n",
      "Epoch 00350: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_350-0.23.hdf5\n",
      "Epoch 351/500\n",
      " - 10s - loss: 0.1461 - acc: 0.9481 - val_loss: 0.2320 - val_acc: 0.9352\n",
      "Epoch 352/500\n",
      " - 10s - loss: 0.1433 - acc: 0.9518 - val_loss: 0.2838 - val_acc: 0.9181\n",
      "Epoch 353/500\n",
      " - 9s - loss: 0.1499 - acc: 0.9462 - val_loss: 0.1972 - val_acc: 0.9415\n",
      "Epoch 354/500\n",
      " - 9s - loss: 0.1500 - acc: 0.9511 - val_loss: 0.2125 - val_acc: 0.9356\n",
      "Epoch 355/500\n",
      " - 10s - loss: 0.1496 - acc: 0.9485 - val_loss: 0.1917 - val_acc: 0.9419\n",
      "Epoch 356/500\n",
      " - 9s - loss: 0.1435 - acc: 0.9475 - val_loss: 0.2077 - val_acc: 0.9394\n",
      "Epoch 357/500\n",
      " - 10s - loss: 0.1358 - acc: 0.9517 - val_loss: 0.2418 - val_acc: 0.9277\n",
      "Epoch 358/500\n",
      " - 9s - loss: 0.1323 - acc: 0.9524 - val_loss: 0.1848 - val_acc: 0.9411\n",
      "Epoch 359/500\n",
      " - 9s - loss: 0.1433 - acc: 0.9497 - val_loss: 0.2241 - val_acc: 0.9310\n",
      "Epoch 360/500\n",
      " - 9s - loss: 0.1380 - acc: 0.9545 - val_loss: 0.2287 - val_acc: 0.9277\n",
      "Epoch 361/500\n",
      " - 9s - loss: 0.1381 - acc: 0.9491 - val_loss: 0.2545 - val_acc: 0.9243\n",
      "Epoch 362/500\n",
      " - 9s - loss: 0.1402 - acc: 0.9514 - val_loss: 0.2208 - val_acc: 0.9369\n",
      "Epoch 363/500\n",
      " - 10s - loss: 0.1460 - acc: 0.9493 - val_loss: 0.1973 - val_acc: 0.9440\n",
      "Epoch 364/500\n",
      " - 10s - loss: 0.1385 - acc: 0.9502 - val_loss: 0.2083 - val_acc: 0.9394\n",
      "Epoch 365/500\n",
      " - 9s - loss: 0.1412 - acc: 0.9488 - val_loss: 0.2633 - val_acc: 0.9202\n",
      "Epoch 366/500\n",
      " - 10s - loss: 0.1422 - acc: 0.9498 - val_loss: 0.2002 - val_acc: 0.9423\n",
      "Epoch 367/500\n",
      " - 10s - loss: 0.1344 - acc: 0.9504 - val_loss: 0.2707 - val_acc: 0.9231\n",
      "Epoch 368/500\n",
      " - 9s - loss: 0.1502 - acc: 0.9493 - val_loss: 0.2737 - val_acc: 0.9268\n",
      "Epoch 369/500\n",
      " - 10s - loss: 0.1375 - acc: 0.9519 - val_loss: 0.2298 - val_acc: 0.9356\n",
      "Epoch 370/500\n",
      " - 9s - loss: 0.1377 - acc: 0.9515 - val_loss: 0.2427 - val_acc: 0.9298\n",
      "Epoch 371/500\n",
      " - 9s - loss: 0.1309 - acc: 0.9538 - val_loss: 0.2300 - val_acc: 0.9356\n",
      "Epoch 372/500\n",
      " - 9s - loss: 0.1344 - acc: 0.9521 - val_loss: 0.1968 - val_acc: 0.9431\n",
      "Epoch 373/500\n",
      " - 9s - loss: 0.1334 - acc: 0.9543 - val_loss: 0.2040 - val_acc: 0.9415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/500\n",
      " - 10s - loss: 0.1329 - acc: 0.9533 - val_loss: 0.2431 - val_acc: 0.9293\n",
      "Epoch 375/500\n",
      " - 9s - loss: 0.1393 - acc: 0.9500 - val_loss: 0.2020 - val_acc: 0.9394\n",
      "\n",
      "Epoch 00375: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_375-0.20.hdf5\n",
      "Epoch 376/500\n",
      " - 10s - loss: 0.1339 - acc: 0.9538 - val_loss: 0.2408 - val_acc: 0.9256\n",
      "Epoch 377/500\n",
      " - 9s - loss: 0.1370 - acc: 0.9518 - val_loss: 0.2069 - val_acc: 0.9406\n",
      "Epoch 378/500\n",
      " - 9s - loss: 0.1347 - acc: 0.9529 - val_loss: 0.2151 - val_acc: 0.9440\n",
      "Epoch 379/500\n",
      " - 9s - loss: 0.1392 - acc: 0.9497 - val_loss: 0.1903 - val_acc: 0.9452\n",
      "Epoch 380/500\n",
      " - 9s - loss: 0.1396 - acc: 0.9495 - val_loss: 0.2087 - val_acc: 0.9381\n",
      "Epoch 381/500\n",
      " - 10s - loss: 0.1270 - acc: 0.9547 - val_loss: 0.2231 - val_acc: 0.9335\n",
      "Epoch 382/500\n",
      " - 10s - loss: 0.1462 - acc: 0.9482 - val_loss: 0.2310 - val_acc: 0.9310\n",
      "Epoch 383/500\n",
      " - 9s - loss: 0.1288 - acc: 0.9554 - val_loss: 0.2336 - val_acc: 0.9335\n",
      "Epoch 384/500\n",
      " - 9s - loss: 0.1388 - acc: 0.9517 - val_loss: 0.2296 - val_acc: 0.9319\n",
      "Epoch 385/500\n",
      " - 10s - loss: 0.1270 - acc: 0.9550 - val_loss: 0.2484 - val_acc: 0.9289\n",
      "Epoch 386/500\n",
      " - 10s - loss: 0.1425 - acc: 0.9498 - val_loss: 0.2496 - val_acc: 0.9256\n",
      "Epoch 387/500\n",
      " - 9s - loss: 0.1381 - acc: 0.9512 - val_loss: 0.2495 - val_acc: 0.9302\n",
      "Epoch 388/500\n",
      " - 10s - loss: 0.1464 - acc: 0.9500 - val_loss: 0.2037 - val_acc: 0.9411\n",
      "Epoch 389/500\n",
      " - 10s - loss: 0.1299 - acc: 0.9552 - val_loss: 0.2164 - val_acc: 0.9339\n",
      "Epoch 390/500\n",
      " - 9s - loss: 0.1411 - acc: 0.9517 - val_loss: 0.2399 - val_acc: 0.9369\n",
      "Epoch 391/500\n",
      " - 10s - loss: 0.1425 - acc: 0.9516 - val_loss: 0.1829 - val_acc: 0.9469\n",
      "Epoch 392/500\n",
      " - 9s - loss: 0.1329 - acc: 0.9525 - val_loss: 0.1991 - val_acc: 0.9406\n",
      "Epoch 393/500\n",
      " - 9s - loss: 0.1349 - acc: 0.9529 - val_loss: 0.2850 - val_acc: 0.9185\n",
      "Epoch 394/500\n",
      " - 9s - loss: 0.1309 - acc: 0.9544 - val_loss: 0.2226 - val_acc: 0.9394\n",
      "Epoch 395/500\n",
      " - 10s - loss: 0.1355 - acc: 0.9540 - val_loss: 0.2247 - val_acc: 0.9411\n",
      "Epoch 396/500\n",
      " - 10s - loss: 0.1270 - acc: 0.9520 - val_loss: 0.2251 - val_acc: 0.9427\n",
      "Epoch 397/500\n",
      " - 9s - loss: 0.1375 - acc: 0.9514 - val_loss: 0.2346 - val_acc: 0.9314\n",
      "Epoch 398/500\n",
      " - 10s - loss: 0.1279 - acc: 0.9546 - val_loss: 0.2785 - val_acc: 0.9252\n",
      "Epoch 399/500\n",
      " - 9s - loss: 0.1368 - acc: 0.9525 - val_loss: 0.2755 - val_acc: 0.9256\n",
      "Epoch 400/500\n",
      " - 10s - loss: 0.1432 - acc: 0.9495 - val_loss: 0.2064 - val_acc: 0.9415\n",
      "\n",
      "Epoch 00400: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_400-0.21.hdf5\n",
      "Epoch 401/500\n",
      " - 9s - loss: 0.1456 - acc: 0.9466 - val_loss: 0.2507 - val_acc: 0.9268\n",
      "Epoch 402/500\n",
      " - 9s - loss: 0.1437 - acc: 0.9488 - val_loss: 0.2115 - val_acc: 0.9348\n",
      "Epoch 403/500\n",
      " - 10s - loss: 0.1383 - acc: 0.9514 - val_loss: 0.2295 - val_acc: 0.9339\n",
      "Epoch 404/500\n",
      " - 9s - loss: 0.1361 - acc: 0.9532 - val_loss: 0.2487 - val_acc: 0.9314\n",
      "Epoch 405/500\n",
      " - 10s - loss: 0.1276 - acc: 0.9562 - val_loss: 0.2285 - val_acc: 0.9352\n",
      "Epoch 406/500\n",
      " - 9s - loss: 0.1326 - acc: 0.9538 - val_loss: 0.2329 - val_acc: 0.9289\n",
      "Epoch 407/500\n",
      " - 9s - loss: 0.1305 - acc: 0.9527 - val_loss: 0.2321 - val_acc: 0.9356\n",
      "Epoch 408/500\n",
      " - 10s - loss: 0.1390 - acc: 0.9499 - val_loss: 0.2087 - val_acc: 0.9398\n",
      "Epoch 409/500\n",
      " - 10s - loss: 0.1469 - acc: 0.9479 - val_loss: 0.2615 - val_acc: 0.9256\n",
      "Epoch 410/500\n",
      " - 9s - loss: 0.1335 - acc: 0.9529 - val_loss: 0.2457 - val_acc: 0.9306\n",
      "Epoch 411/500\n",
      " - 9s - loss: 0.1353 - acc: 0.9518 - val_loss: 0.1953 - val_acc: 0.9436\n",
      "Epoch 412/500\n",
      " - 10s - loss: 0.1333 - acc: 0.9523 - val_loss: 0.2374 - val_acc: 0.9306\n",
      "Epoch 413/500\n",
      " - 9s - loss: 0.1287 - acc: 0.9559 - val_loss: 0.2741 - val_acc: 0.9252\n",
      "Epoch 414/500\n",
      " - 10s - loss: 0.1274 - acc: 0.9563 - val_loss: 0.2706 - val_acc: 0.9227\n",
      "Epoch 415/500\n",
      " - 9s - loss: 0.1425 - acc: 0.9510 - val_loss: 0.1826 - val_acc: 0.9452\n",
      "Epoch 416/500\n",
      " - 9s - loss: 0.1301 - acc: 0.9535 - val_loss: 0.2484 - val_acc: 0.9310\n",
      "Epoch 417/500\n",
      " - 9s - loss: 0.1304 - acc: 0.9531 - val_loss: 0.2179 - val_acc: 0.9394\n",
      "Epoch 418/500\n",
      " - 10s - loss: 0.1336 - acc: 0.9528 - val_loss: 0.2320 - val_acc: 0.9335\n",
      "Epoch 419/500\n",
      " - 9s - loss: 0.1389 - acc: 0.9521 - val_loss: 0.2552 - val_acc: 0.9310\n",
      "Epoch 420/500\n",
      " - 9s - loss: 0.1250 - acc: 0.9555 - val_loss: 0.2229 - val_acc: 0.9411\n",
      "Epoch 421/500\n",
      " - 10s - loss: 0.1306 - acc: 0.9535 - val_loss: 0.2291 - val_acc: 0.9394\n",
      "Epoch 422/500\n",
      " - 9s - loss: 0.1187 - acc: 0.9563 - val_loss: 0.2670 - val_acc: 0.9277\n",
      "Epoch 423/500\n",
      " - 9s - loss: 0.1315 - acc: 0.9536 - val_loss: 0.2322 - val_acc: 0.9394\n",
      "Epoch 424/500\n",
      " - 10s - loss: 0.1390 - acc: 0.9524 - val_loss: 0.2352 - val_acc: 0.9356\n",
      "Epoch 425/500\n",
      " - 9s - loss: 0.1413 - acc: 0.9510 - val_loss: 0.2411 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00425: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_425-0.24.hdf5\n",
      "Epoch 426/500\n",
      " - 9s - loss: 0.1309 - acc: 0.9561 - val_loss: 0.2228 - val_acc: 0.9390\n",
      "Epoch 427/500\n",
      " - 9s - loss: 0.1230 - acc: 0.9554 - val_loss: 0.1984 - val_acc: 0.9461\n",
      "Epoch 428/500\n",
      " - 9s - loss: 0.1287 - acc: 0.9563 - val_loss: 0.2279 - val_acc: 0.9381\n",
      "Epoch 429/500\n",
      " - 10s - loss: 0.1324 - acc: 0.9532 - val_loss: 0.2355 - val_acc: 0.9398\n",
      "Epoch 430/500\n",
      " - 9s - loss: 0.1233 - acc: 0.9559 - val_loss: 0.2068 - val_acc: 0.9419\n",
      "Epoch 431/500\n",
      " - 9s - loss: 0.1269 - acc: 0.9549 - val_loss: 0.2352 - val_acc: 0.9381\n",
      "Epoch 432/500\n",
      " - 9s - loss: 0.1262 - acc: 0.9557 - val_loss: 0.2088 - val_acc: 0.9419\n",
      "Epoch 433/500\n",
      " - 9s - loss: 0.1314 - acc: 0.9545 - val_loss: 0.2147 - val_acc: 0.9381\n",
      "Epoch 434/500\n",
      " - 9s - loss: 0.1402 - acc: 0.9511 - val_loss: 0.2153 - val_acc: 0.9398\n",
      "Epoch 435/500\n",
      " - 9s - loss: 0.1378 - acc: 0.9531 - val_loss: 0.2191 - val_acc: 0.9390\n",
      "Epoch 436/500\n",
      " - 10s - loss: 0.1517 - acc: 0.9476 - val_loss: 0.2081 - val_acc: 0.9431\n",
      "Epoch 437/500\n",
      " - 9s - loss: 0.1307 - acc: 0.9534 - val_loss: 0.2361 - val_acc: 0.9335\n",
      "Epoch 438/500\n",
      " - 9s - loss: 0.1464 - acc: 0.9493 - val_loss: 0.2438 - val_acc: 0.9314\n",
      "Epoch 439/500\n",
      " - 9s - loss: 0.1204 - acc: 0.9585 - val_loss: 0.2177 - val_acc: 0.9406\n",
      "Epoch 440/500\n",
      " - 9s - loss: 0.1260 - acc: 0.9570 - val_loss: 0.2309 - val_acc: 0.9373\n",
      "Epoch 441/500\n",
      " - 9s - loss: 0.1313 - acc: 0.9528 - val_loss: 0.2054 - val_acc: 0.9436\n",
      "Epoch 442/500\n",
      " - 9s - loss: 0.1184 - acc: 0.9587 - val_loss: 0.2177 - val_acc: 0.9377\n",
      "Epoch 443/500\n",
      " - 9s - loss: 0.1328 - acc: 0.9531 - val_loss: 0.2419 - val_acc: 0.9335\n",
      "Epoch 444/500\n",
      " - 9s - loss: 0.1348 - acc: 0.9542 - val_loss: 0.2337 - val_acc: 0.9335\n",
      "Epoch 445/500\n",
      " - 9s - loss: 0.1300 - acc: 0.9563 - val_loss: 0.2302 - val_acc: 0.9377\n",
      "Epoch 446/500\n",
      " - 9s - loss: 0.1237 - acc: 0.9569 - val_loss: 0.2453 - val_acc: 0.9373\n",
      "Epoch 447/500\n",
      " - 9s - loss: 0.1267 - acc: 0.9552 - val_loss: 0.2846 - val_acc: 0.9235\n",
      "Epoch 448/500\n",
      " - 9s - loss: 0.1271 - acc: 0.9549 - val_loss: 0.2318 - val_acc: 0.9385\n",
      "Epoch 449/500\n",
      " - 9s - loss: 0.1325 - acc: 0.9559 - val_loss: 0.2635 - val_acc: 0.9281\n",
      "Epoch 450/500\n",
      " - 9s - loss: 0.1192 - acc: 0.9584 - val_loss: 0.2412 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00450: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_450-0.24.hdf5\n",
      "Epoch 451/500\n",
      " - 9s - loss: 0.1439 - acc: 0.9495 - val_loss: 0.2780 - val_acc: 0.9273\n",
      "Epoch 452/500\n",
      " - 9s - loss: 0.1301 - acc: 0.9563 - val_loss: 0.2372 - val_acc: 0.9327\n",
      "Epoch 453/500\n",
      " - 9s - loss: 0.1329 - acc: 0.9538 - val_loss: 0.2695 - val_acc: 0.9247\n",
      "Epoch 454/500\n",
      " - 9s - loss: 0.1274 - acc: 0.9555 - val_loss: 0.2690 - val_acc: 0.9293\n",
      "Epoch 455/500\n",
      " - 9s - loss: 0.1417 - acc: 0.9508 - val_loss: 0.2299 - val_acc: 0.9394\n",
      "Epoch 456/500\n",
      " - 9s - loss: 0.1305 - acc: 0.9550 - val_loss: 0.2525 - val_acc: 0.9323\n",
      "Epoch 457/500\n",
      " - 9s - loss: 0.1407 - acc: 0.9506 - val_loss: 0.2275 - val_acc: 0.9385\n",
      "Epoch 458/500\n",
      " - 9s - loss: 0.1446 - acc: 0.9498 - val_loss: 0.2413 - val_acc: 0.9335\n",
      "Epoch 459/500\n",
      " - 9s - loss: 0.1299 - acc: 0.9547 - val_loss: 0.2559 - val_acc: 0.9331\n",
      "Epoch 460/500\n",
      " - 9s - loss: 0.1330 - acc: 0.9534 - val_loss: 0.2117 - val_acc: 0.9394\n",
      "Epoch 461/500\n",
      " - 9s - loss: 0.1291 - acc: 0.9570 - val_loss: 0.2269 - val_acc: 0.9369\n",
      "Epoch 462/500\n",
      " - 9s - loss: 0.1226 - acc: 0.9552 - val_loss: 0.2536 - val_acc: 0.9310\n",
      "Epoch 463/500\n",
      " - 9s - loss: 0.1349 - acc: 0.9550 - val_loss: 0.2429 - val_acc: 0.9339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/500\n",
      " - 9s - loss: 0.1267 - acc: 0.9562 - val_loss: 0.2389 - val_acc: 0.9352\n",
      "Epoch 465/500\n",
      " - 9s - loss: 0.1241 - acc: 0.9580 - val_loss: 0.2397 - val_acc: 0.9323\n",
      "Epoch 466/500\n",
      " - 9s - loss: 0.1191 - acc: 0.9592 - val_loss: 0.2653 - val_acc: 0.9293\n",
      "Epoch 467/500\n",
      " - 9s - loss: 0.1277 - acc: 0.9561 - val_loss: 0.2260 - val_acc: 0.9356\n",
      "Epoch 468/500\n",
      " - 9s - loss: 0.1370 - acc: 0.9509 - val_loss: 0.2388 - val_acc: 0.9360\n",
      "Epoch 469/500\n",
      " - 9s - loss: 0.1270 - acc: 0.9558 - val_loss: 0.2443 - val_acc: 0.9348\n",
      "Epoch 470/500\n",
      " - 9s - loss: 0.1314 - acc: 0.9546 - val_loss: 0.2126 - val_acc: 0.9373\n",
      "Epoch 471/500\n",
      " - 9s - loss: 0.1292 - acc: 0.9552 - val_loss: 0.2475 - val_acc: 0.9314\n",
      "Epoch 472/500\n",
      " - 9s - loss: 0.1251 - acc: 0.9555 - val_loss: 0.3070 - val_acc: 0.9227\n",
      "Epoch 473/500\n",
      " - 9s - loss: 0.1259 - acc: 0.9585 - val_loss: 0.2288 - val_acc: 0.9352\n",
      "Epoch 474/500\n",
      " - 9s - loss: 0.1255 - acc: 0.9569 - val_loss: 0.2714 - val_acc: 0.9273\n",
      "Epoch 475/500\n",
      " - 9s - loss: 0.1231 - acc: 0.9575 - val_loss: 0.2351 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00475: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_475-0.24.hdf5\n",
      "Epoch 476/500\n",
      " - 9s - loss: 0.1383 - acc: 0.9543 - val_loss: 0.2153 - val_acc: 0.9385\n",
      "Epoch 477/500\n",
      " - 10s - loss: 0.1257 - acc: 0.9559 - val_loss: 0.2158 - val_acc: 0.9415\n",
      "Epoch 478/500\n",
      " - 9s - loss: 0.1298 - acc: 0.9544 - val_loss: 0.2089 - val_acc: 0.9411\n",
      "Epoch 479/500\n",
      " - 9s - loss: 0.1318 - acc: 0.9535 - val_loss: 0.2483 - val_acc: 0.9298\n",
      "Epoch 480/500\n",
      " - 9s - loss: 0.1240 - acc: 0.9564 - val_loss: 0.2151 - val_acc: 0.9369\n",
      "Epoch 481/500\n",
      " - 9s - loss: 0.1295 - acc: 0.9545 - val_loss: 0.2769 - val_acc: 0.9273\n",
      "Epoch 482/500\n",
      " - 9s - loss: 0.1219 - acc: 0.9562 - val_loss: 0.2294 - val_acc: 0.9348\n",
      "Epoch 483/500\n",
      " - 10s - loss: 0.1237 - acc: 0.9566 - val_loss: 0.2454 - val_acc: 0.9348\n",
      "Epoch 484/500\n",
      " - 9s - loss: 0.1418 - acc: 0.9509 - val_loss: 0.2946 - val_acc: 0.9185\n",
      "Epoch 485/500\n",
      " - 9s - loss: 0.1267 - acc: 0.9553 - val_loss: 0.2256 - val_acc: 0.9377\n",
      "Epoch 486/500\n",
      " - 9s - loss: 0.1202 - acc: 0.9610 - val_loss: 0.1906 - val_acc: 0.9477\n",
      "Epoch 487/500\n",
      " - 9s - loss: 0.1353 - acc: 0.9550 - val_loss: 0.2647 - val_acc: 0.9247\n",
      "Epoch 488/500\n",
      " - 10s - loss: 0.1307 - acc: 0.9524 - val_loss: 0.2191 - val_acc: 0.9339\n",
      "Epoch 489/500\n",
      " - 10s - loss: 0.1312 - acc: 0.9549 - val_loss: 0.2481 - val_acc: 0.9339\n",
      "Epoch 490/500\n",
      " - 10s - loss: 0.1257 - acc: 0.9561 - val_loss: 0.2119 - val_acc: 0.9465\n",
      "Epoch 491/500\n",
      " - 9s - loss: 0.1241 - acc: 0.9573 - val_loss: 0.2318 - val_acc: 0.9360\n",
      "Epoch 492/500\n",
      " - 10s - loss: 0.1339 - acc: 0.9519 - val_loss: 0.3063 - val_acc: 0.9193\n",
      "Epoch 493/500\n",
      " - 10s - loss: 0.1275 - acc: 0.9561 - val_loss: 0.2190 - val_acc: 0.9423\n",
      "Epoch 494/500\n",
      " - 9s - loss: 0.1250 - acc: 0.9574 - val_loss: 0.2425 - val_acc: 0.9310\n",
      "Epoch 495/500\n",
      " - 9s - loss: 0.1222 - acc: 0.9564 - val_loss: 0.2316 - val_acc: 0.9377\n",
      "Epoch 496/500\n",
      " - 9s - loss: 0.1276 - acc: 0.9554 - val_loss: 0.2260 - val_acc: 0.9385\n",
      "Epoch 497/500\n",
      " - 9s - loss: 0.1203 - acc: 0.9559 - val_loss: 0.2278 - val_acc: 0.9377\n",
      "Epoch 498/500\n",
      " - 9s - loss: 0.1318 - acc: 0.9546 - val_loss: 0.2123 - val_acc: 0.9356\n",
      "Epoch 499/500\n",
      " - 10s - loss: 0.1166 - acc: 0.9588 - val_loss: 0.2359 - val_acc: 0.9365\n",
      "Epoch 500/500\n",
      " - 10s - loss: 0.1202 - acc: 0.9576 - val_loss: 0.1987 - val_acc: 0.9436\n",
      "\n",
      "Epoch 00500: saving model to results_bayes/015-chong_no_batch_only_EndoErMito/weights_Chong_data_epoch_500-0.20.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = X_train_keep.shape[0]/batch_size,\n",
    "                    epochs = 500,                    \n",
    "                    validation_data = (X_valid_keep, one_hot(y_valid_keep, num_classes)),\n",
    "                    verbose = 2,\n",
    "                    callbacks=[checkpointer, tb_cb]\n",
    ")\n",
    "model.save(resdir+\"/final.keras.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from hyperdash import monitor_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%monitor_cell \"No Myto\"\n",
    "#print(\"Finished \" + resdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -rtl results_bayes/013-kraus1_full_no_batch_no_myto/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
