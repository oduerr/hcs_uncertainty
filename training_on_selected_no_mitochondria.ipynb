{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Using this notebook, we train on a subset of classes (phenotypes). For example, we leave out the mitochondrial phenotype.\n",
    "\n",
    "**Naming the experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_desc = 'chong_no_batch_no_mitochondria'#change here for exp id with directories\n",
    "del_id=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data\n",
    "\n",
    "Downloading the data if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3.2G\r\n",
      "-rw-r--r-- 1 root root 153M Jan  7  2017 Chong_test_set.hdf5\r\n",
      "-rw-r--r-- 1 root root  800 Jul 10 07:49 Chong_test_set.hdf5.hdf5\r\n",
      "-rw-r--r-- 1 root root 738M Jan  7  2017 Chong_train_set.hdf5\r\n",
      "-rw-r--r-- 1 root root 152M Jan  7  2017 Chong_valid_set.hdf5\r\n",
      "-rw-r--r-- 1 root root  740 Jan  8  2017 README.TXT\r\n",
      "-rw-r--r-- 1 root root  46M Jan  8  2017 Schuldiner_test_set.hdf5\r\n",
      "-rw-r--r-- 1 root root 405M Jan  8  2017 Schuldiner_train_set.hdf5\r\n",
      "-rw-r--r-- 1 root root 172M Jan  8  2017 wt2017_test_set.hdf5\r\n",
      "-rw-r--r-- 1 root root 1.5G Jan  8  2017 wt2017_train_set.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "#Taken from https://github.com/okraus/DeepLoc/blob/master/download_datasets.sh\n",
    "import os\n",
    "if not (os.path.exists('datasets/Chong_train_set.hdf5')):\n",
    "    !curl http://spidey.ccbr.utoronto.ca/~okraus/DeepLoc_full_datasets.zip --output DeepLoc_full_datasets.zip\n",
    "    !unzip DeepLoc_full_datasets.zip\n",
    "    !rm DeepLoc_full_datasets.zip\n",
    "!ls -lh datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 17 12:51:44 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P40           Off  | 00000000:89:00.0 Off |                    0 |\r\n",
      "| N/A   28C    P0    47W / 250W |      0MiB / 22919MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1.6.0', '2.1.5', '1.14.1', '2.7.1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Flatten, Activation\n",
    "from keras.layers import Lambda, Dropout, BatchNormalization, Convolution2D, MaxPooling2D\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time\n",
    "%matplotlib inline\n",
    "tf.__version__,keras.__version__, np.__version__, h5py.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Index1', 'Info1', 'data1', 'label_names']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({(0, b'ACTIN'): 738,\n",
       "         (1, b'BUDNECK'): 535,\n",
       "         (2, b'BUDTIP'): 336,\n",
       "         (3, b'CELLPERIPHERY'): 423,\n",
       "         (4, b'CYTOPLASM'): 1500,\n",
       "         (5, b'ENDOSOME'): 1500,\n",
       "         (6, b'ER'): 1500,\n",
       "         (7, b'GOLGI'): 1500,\n",
       "         (8, b'MITOCHONDRIA'): 1500,\n",
       "         (9, b'NUCLEARPERIPHERY'): 1500,\n",
       "         (10, b'NUCLEI'): 1500,\n",
       "         (11, b'NUCLEOLUS'): 1500,\n",
       "         (12, b'PEROXISOME'): 988,\n",
       "         (13, b'SPINDLE'): 185,\n",
       "         (14, b'SPINDLEPOLE'): 1500,\n",
       "         (15, b'VACUOLARMEMBRANE'): 1500,\n",
       "         (16, b'VACUOLE'): 1500,\n",
       "         (17, b'DEAD'): 749,\n",
       "         (18, b'GHOST'): 1428})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn1 = 'datasets/Chong_train_set.hdf5'\n",
    "d1 = h5py.File(fn1)\n",
    "print(list(d1.keys()))\n",
    "l = [d for d in zip(np.argmax(d1['Index1'],axis=1), d1['label_names'])]\n",
    "from collections import Counter\n",
    "Counter(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatBatch2Tensor(batchData,imSize,channels):\n",
    "    splitByChannel = [batchData[:,(chan*imSize**2):((chan+1)*imSize**2)].reshape((-1,imSize,imSize,1)) \\\n",
    "                      for chan in range(channels)]\n",
    "    tensorBatchData = np.concatenate(splitByChannel,3)\n",
    "    return tensorBatchData\n",
    "\n",
    "def load_kraus():\n",
    "       \n",
    "    #fn1 = 'datasets/wt2017_train_set.hdf5'\n",
    "    #fn2 = 'datasets/wt2017_test_set.hdf5'\n",
    "    \n",
    "    fn1 = 'datasets/Chong_train_set.hdf5'\n",
    "    fn2 = 'datasets/Chong_test_set.hdf5'\n",
    "    fn3 = 'datasets/Chong_valid_set.hdf5'\n",
    "    d1 = h5py.File(fn1)\n",
    "    d2 = h5py.File(fn2)\n",
    "    d3 = h5py.File(fn3)\n",
    "    \n",
    "    X_train = flatBatch2Tensor(d1['data1'][:], 64, 2)\n",
    "    X_test = flatBatch2Tensor(d2['data1'][:], 64, 2)\n",
    "    X_valid = flatBatch2Tensor(d3['data1'][:], 64, 2)\n",
    "    y_train = d1['Index1'][:]\n",
    "    y_test = d2['Index1'][:]\n",
    "    y_valid = d3['Index1'][:]\n",
    "    \n",
    "    # We bring the data into the range [0,1] and clamp it due to heavy outliers\n",
    "    X_train = np.clip(X_train,0,100)/100\n",
    "    X_test = np.clip(X_test,0,100)/100\n",
    "    X_valid = np.clip(X_valid,0,100)/100\n",
    "    \n",
    "    # For sparse labels\n",
    "    #y_train = np.ndarray.astype(np.argmax(d1['Index1'],axis=1),'int32')\n",
    "    #y_test = np.ndarray.astype(np.argmax(d2['Index1'],axis=1),'int32')\n",
    "        \n",
    "    print(\"X_train type {} dtype {} shape {}\".format(type(X_train), X_train.dtype,np.shape(X_train)))\n",
    "    print(\"X_train min {}, max {} mean {}\".format(np.min(X_train), np.max(X_train), np.mean(X_train)))\n",
    "    print(\"Y_train shape {} Y_test shape{} Y_validation shape{} \".format(np.shape(y_train), np.shape(y_test), np.shape(y_valid)))\n",
    "    return X_train, y_train, X_test, y_test, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type <class 'numpy.ndarray'> dtype float32 shape (21882, 64, 64, 2)\n",
      "X_train min 0.0, max 1.0 mean 0.17277522385120392\n",
      "Y_train shape (21882, 19) Y_test shape(4516, 19) Y_validation shape(4491, 19) \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "X_train, Y_train, X_test, Y_test, X_valid, Y_valid = load_kraus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, (4491, 19))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.argmax(Y_train, axis=1)) + 1, Y_valid.shape #19 number of classes - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing cells in the training and validation set\n",
    "\n",
    "We remove the e.g. mitochondrial cells from the training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes (original) 19    from 0 to 18\n"
     ]
    }
   ],
   "source": [
    "y_train = np.argmax(Y_train,axis=1)\n",
    "y_valid = np.argmax(Y_valid,axis=1)\n",
    "y_test = np.argmax(Y_test,axis=1)\n",
    "\n",
    "y_max = np.max(y_train) #0,...\n",
    "num_class_org = y_max + 1\n",
    "print('Number of classes (original)', num_class_org, '   from', 0, 'to', y_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a list of classes which shall be used in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For myto\n",
    "if True:\n",
    "    idx = del_id# here class index to delete\n",
    "    keep_idx = list(np.linspace(start=0,stop=y_max,num=y_max+1, dtype='int32'))\n",
    "    keep_idx.remove(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes (after cutting) 18 to keep from org [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(keep_idx)\n",
    "print(\"Number of classes (after cutting)\" , num_classes, \"to keep from org\", keep_idx)\n",
    "\n",
    "all_to_limited = dict()\n",
    "limited_to_all = dict()\n",
    "c = 0\n",
    "for i in range(num_class_org):\n",
    "    all_to_limited[i] = c\n",
    "    limited_to_all[c] = i\n",
    "    if (keep_idx.count(i) > 0):\n",
    "        c += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20382, 64, 64, 2), (3849, 64, 64, 2), 18, 18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_training = [keep_idx.count(y) > 0 for y in y_train]\n",
    "X_train_keep = X_train[keep_training]\n",
    "y_train_keep = [all_to_limited[y] for y in y_train if keep_idx.count(y) > 0] \n",
    "\n",
    "keep_valid = [keep_idx.count(y) > 0 for y in y_valid]\n",
    "X_valid_keep = X_valid[keep_valid]\n",
    "y_valid_keep = [all_to_limited[y] for y in y_valid if keep_idx.count(y) > 0] \n",
    "\n",
    "X_train_keep.shape, X_valid_keep.shape, len(np.unique(y_train_keep)), len(np.unique(y_valid_keep))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20382\n",
      "3849\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train) - np.sum(np.argmax(Y_train,axis=1)==del_id))\n",
    "print(len(Y_valid) - np.sum(np.argmax(Y_valid,axis=1)==del_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7150d076d8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7150db9080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X_train_keep[len(X_train_keep)-1,:,:,0])\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(X_train_keep[len(X_train_keep)-1,:,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building of Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    #zoom_range=[0.1,0.1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper functions\n",
    "def one_hot(Y, num_cl):\n",
    "    d = np.zeros((len(Y),num_cl), dtype='int8')\n",
    "    for row,col in enumerate(Y):\n",
    "        d[row, col] = 1\n",
    "    return d\n",
    "one_hot(np.array((1,0,1,1,2)), 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py:935: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (20382, 64, 64, 2) (2 channels).\n",
      "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_generator = datagen.flow(\n",
    "        x = X_train_keep,\n",
    "        y = one_hot(y_train_keep, num_classes),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (3,3),kernel_initializer='he_normal',padding='same',input_shape=(64,64,2)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Convolution2D(32, (3,3),kernel_initializer='he_normal',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Convolution2D(64, (3,3),kernel_initializer='he_normal',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Convolution2D(64, (3,3),kernel_initializer='he_normal',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())#macht einen vektor aus dem output\n",
    "model.add(Dropout(0.3))            \n",
    "model.add(Dense(200,kernel_initializer='he_normal'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        608       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               3277000   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 18)                3618      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 18)                0         \n",
      "=================================================================\n",
      "Total params: 3,345,898\n",
      "Trainable params: 3,345,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((None, 64, 64, 2), (None, 18))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.summary())\n",
    "model.input_shape, model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "def create_result_subdir(result_dir, run_desc):\n",
    "    ordinal = 0\n",
    "    for fname in glob.glob(os.path.join(result_dir, '*')):\n",
    "        try:\n",
    "            fbase = os.path.basename(fname)\n",
    "            ford = int(fbase[:fbase.find('-')])\n",
    "            ordinal = max(ordinal, ford + 1)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    result_subdir = os.path.join(result_dir, '%03d-%s' % (ordinal, run_desc))\n",
    "    if os.path.isdir(result_subdir):\n",
    "        return create_result_subdir(result_dir, run_desc) # Retry.\n",
    "    if not os.path.isdir(result_subdir):\n",
    "        os.makedirs(result_subdir)\n",
    "    return result_subdir, ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdir, ordinal = create_result_subdir('results_bayes', run_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results_bayes/021-chong_no_batch_no_mitochondria'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_cb = keras.callbacks.TensorBoard(log_dir=resdir, histogram_freq=0, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint( \n",
    "    filepath =  resdir+\"/weights_Chong_data_epoch_{epoch:03d}-{val_loss:.2f}.hdf5\",\n",
    "    verbose = 1, \n",
    "    save_best_only = False,\n",
    "    period = 25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3849, 18), 18, 19, (20382, 18))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(y_valid_keep, num_classes).shape, num_classes, num_class_org,one_hot(y_train_keep, num_classes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "160/159 [==============================] - 21s 129ms/step - loss: 2.5049 - acc: 0.1981 - val_loss: 2.0788 - val_acc: 0.3554\n",
      "Epoch 2/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 1.9500 - acc: 0.3434 - val_loss: 1.9021 - val_acc: 0.3676\n",
      "Epoch 3/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 1.7117 - acc: 0.4182 - val_loss: 1.5903 - val_acc: 0.5032\n",
      "Epoch 4/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 1.5555 - acc: 0.4688 - val_loss: 1.4596 - val_acc: 0.5225\n",
      "Epoch 5/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 1.4175 - acc: 0.5163 - val_loss: 1.3295 - val_acc: 0.5783\n",
      "Epoch 6/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 1.3424 - acc: 0.5356 - val_loss: 1.2470 - val_acc: 0.5916\n",
      "Epoch 7/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 1.2781 - acc: 0.5592 - val_loss: 1.1214 - val_acc: 0.6345\n",
      "Epoch 8/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 1.1996 - acc: 0.5839 - val_loss: 0.9945 - val_acc: 0.6841\n",
      "Epoch 9/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 1.1319 - acc: 0.6040 - val_loss: 0.8982 - val_acc: 0.7054\n",
      "Epoch 10/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 1.0687 - acc: 0.6280 - val_loss: 0.9042 - val_acc: 0.7119\n",
      "Epoch 11/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 1.0202 - acc: 0.6440 - val_loss: 0.9787 - val_acc: 0.6737\n",
      "Epoch 12/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.9889 - acc: 0.6604 - val_loss: 0.7861 - val_acc: 0.7508\n",
      "Epoch 13/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.9352 - acc: 0.6746 - val_loss: 0.7202 - val_acc: 0.7773\n",
      "Epoch 14/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.9091 - acc: 0.6844 - val_loss: 0.6877 - val_acc: 0.7706\n",
      "Epoch 15/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.8615 - acc: 0.6987 - val_loss: 0.7007 - val_acc: 0.7724\n",
      "Epoch 16/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.8500 - acc: 0.7071 - val_loss: 0.6126 - val_acc: 0.8038\n",
      "Epoch 17/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.8167 - acc: 0.7181 - val_loss: 0.5645 - val_acc: 0.8132\n",
      "Epoch 18/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.7811 - acc: 0.7289 - val_loss: 0.5719 - val_acc: 0.8124\n",
      "Epoch 19/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.7491 - acc: 0.7405 - val_loss: 0.5707 - val_acc: 0.8142\n",
      "Epoch 20/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.7245 - acc: 0.7492 - val_loss: 0.5109 - val_acc: 0.8405\n",
      "Epoch 21/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.7240 - acc: 0.7510 - val_loss: 0.5468 - val_acc: 0.8223\n",
      "Epoch 22/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.7004 - acc: 0.7560 - val_loss: 0.5255 - val_acc: 0.8246\n",
      "Epoch 23/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.6726 - acc: 0.7671 - val_loss: 0.4987 - val_acc: 0.8392\n",
      "Epoch 24/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.6656 - acc: 0.7722 - val_loss: 0.4971 - val_acc: 0.8355\n",
      "Epoch 25/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.6503 - acc: 0.7748 - val_loss: 0.4778 - val_acc: 0.8415\n",
      "\n",
      "Epoch 00025: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_025-0.48.hdf5\n",
      "Epoch 26/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.6361 - acc: 0.7817 - val_loss: 0.4954 - val_acc: 0.8316\n",
      "Epoch 27/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.6120 - acc: 0.7906 - val_loss: 0.4521 - val_acc: 0.8446\n",
      "Epoch 28/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.6016 - acc: 0.7926 - val_loss: 0.4658 - val_acc: 0.8405\n",
      "Epoch 29/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.6026 - acc: 0.7942 - val_loss: 0.4156 - val_acc: 0.8618\n",
      "Epoch 30/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.5874 - acc: 0.7973 - val_loss: 0.4676 - val_acc: 0.8397\n",
      "Epoch 31/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.5942 - acc: 0.7960 - val_loss: 0.4250 - val_acc: 0.8587\n",
      "Epoch 32/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.5740 - acc: 0.8017 - val_loss: 0.4321 - val_acc: 0.8535\n",
      "Epoch 33/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.5569 - acc: 0.8074 - val_loss: 0.4216 - val_acc: 0.8506\n",
      "Epoch 34/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.5613 - acc: 0.8073 - val_loss: 0.3878 - val_acc: 0.8675\n",
      "Epoch 35/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.5385 - acc: 0.8131 - val_loss: 0.3925 - val_acc: 0.8774\n",
      "Epoch 36/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.5383 - acc: 0.8162 - val_loss: 0.3895 - val_acc: 0.8732\n",
      "Epoch 37/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.5340 - acc: 0.8208 - val_loss: 0.4048 - val_acc: 0.8685\n",
      "Epoch 38/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.5205 - acc: 0.8204 - val_loss: 0.3835 - val_acc: 0.8779\n",
      "Epoch 39/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.5171 - acc: 0.8218 - val_loss: 0.3782 - val_acc: 0.8774\n",
      "Epoch 40/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.5188 - acc: 0.8198 - val_loss: 0.3667 - val_acc: 0.8779\n",
      "Epoch 41/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.5074 - acc: 0.8254 - val_loss: 0.3651 - val_acc: 0.8704\n",
      "Epoch 42/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.5080 - acc: 0.8286 - val_loss: 0.3713 - val_acc: 0.8815\n",
      "Epoch 43/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.5064 - acc: 0.8286 - val_loss: 0.3585 - val_acc: 0.8774\n",
      "Epoch 44/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4932 - acc: 0.8311 - val_loss: 0.3406 - val_acc: 0.8862\n",
      "Epoch 45/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.4894 - acc: 0.8334 - val_loss: 0.3434 - val_acc: 0.8841\n",
      "Epoch 46/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.4771 - acc: 0.8362 - val_loss: 0.3632 - val_acc: 0.8826\n",
      "Epoch 47/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.4804 - acc: 0.8356 - val_loss: 0.3372 - val_acc: 0.8844\n",
      "Epoch 48/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.4747 - acc: 0.8399 - val_loss: 0.3698 - val_acc: 0.8750\n",
      "Epoch 49/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.4712 - acc: 0.8367 - val_loss: 0.3391 - val_acc: 0.8805\n",
      "Epoch 50/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.4640 - acc: 0.8420 - val_loss: 0.3441 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00050: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_050-0.34.hdf5\n",
      "Epoch 51/500\n",
      "160/159 [==============================] - 18s 111ms/step - loss: 0.4702 - acc: 0.8436 - val_loss: 0.3094 - val_acc: 0.9008\n",
      "Epoch 52/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4468 - acc: 0.8466 - val_loss: 0.3492 - val_acc: 0.8805\n",
      "Epoch 53/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4440 - acc: 0.8459 - val_loss: 0.2984 - val_acc: 0.9002\n",
      "Epoch 54/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4471 - acc: 0.8494 - val_loss: 0.3848 - val_acc: 0.8652\n",
      "Epoch 55/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.4639 - acc: 0.8422 - val_loss: 0.3475 - val_acc: 0.8859\n",
      "Epoch 56/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.4463 - acc: 0.8494 - val_loss: 0.3233 - val_acc: 0.8922\n",
      "Epoch 57/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.4320 - acc: 0.8506 - val_loss: 0.3361 - val_acc: 0.8865\n",
      "Epoch 58/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4363 - acc: 0.8538 - val_loss: 0.3300 - val_acc: 0.8906\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/159 [==============================] - 19s 117ms/step - loss: 0.4391 - acc: 0.8517 - val_loss: 0.3287 - val_acc: 0.8891\n",
      "Epoch 60/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4287 - acc: 0.8521 - val_loss: 0.3167 - val_acc: 0.8950\n",
      "Epoch 61/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4265 - acc: 0.8557 - val_loss: 0.3297 - val_acc: 0.8854\n",
      "Epoch 62/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.4194 - acc: 0.8548 - val_loss: 0.3082 - val_acc: 0.9008\n",
      "Epoch 63/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.4202 - acc: 0.8592 - val_loss: 0.3006 - val_acc: 0.8995\n",
      "Epoch 64/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.4115 - acc: 0.8609 - val_loss: 0.3026 - val_acc: 0.9049\n",
      "Epoch 65/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.4210 - acc: 0.8587 - val_loss: 0.3353 - val_acc: 0.8917\n",
      "Epoch 66/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.4138 - acc: 0.8596 - val_loss: 0.3350 - val_acc: 0.8906\n",
      "Epoch 67/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4095 - acc: 0.8598 - val_loss: 0.3069 - val_acc: 0.8969\n",
      "Epoch 68/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.4065 - acc: 0.8609 - val_loss: 0.2972 - val_acc: 0.9026\n",
      "Epoch 69/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.4052 - acc: 0.8616 - val_loss: 0.3183 - val_acc: 0.8961\n",
      "Epoch 70/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4082 - acc: 0.8601 - val_loss: 0.2894 - val_acc: 0.9080\n",
      "Epoch 71/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.4083 - acc: 0.8587 - val_loss: 0.3064 - val_acc: 0.8943\n",
      "Epoch 72/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.4052 - acc: 0.8622 - val_loss: 0.2980 - val_acc: 0.9049\n",
      "Epoch 73/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.3896 - acc: 0.8673 - val_loss: 0.3587 - val_acc: 0.8807\n",
      "Epoch 74/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3952 - acc: 0.8650 - val_loss: 0.2727 - val_acc: 0.9140\n",
      "Epoch 75/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3944 - acc: 0.8658 - val_loss: 0.2903 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00075: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_075-0.29.hdf5\n",
      "Epoch 76/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.3789 - acc: 0.8695 - val_loss: 0.2934 - val_acc: 0.9036\n",
      "Epoch 77/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3836 - acc: 0.8711 - val_loss: 0.2635 - val_acc: 0.9182\n",
      "Epoch 78/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.3754 - acc: 0.8714 - val_loss: 0.2838 - val_acc: 0.9034\n",
      "Epoch 79/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3914 - acc: 0.8664 - val_loss: 0.3077 - val_acc: 0.8984\n",
      "Epoch 80/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3777 - acc: 0.8702 - val_loss: 0.3085 - val_acc: 0.8971\n",
      "Epoch 81/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3832 - acc: 0.8709 - val_loss: 0.3131 - val_acc: 0.8982\n",
      "Epoch 82/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3734 - acc: 0.8727 - val_loss: 0.2646 - val_acc: 0.9153\n",
      "Epoch 83/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3730 - acc: 0.8726 - val_loss: 0.2952 - val_acc: 0.9049\n",
      "Epoch 84/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3712 - acc: 0.8731 - val_loss: 0.2827 - val_acc: 0.9096\n",
      "Epoch 85/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3656 - acc: 0.8743 - val_loss: 0.3060 - val_acc: 0.9023\n",
      "Epoch 86/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3620 - acc: 0.8750 - val_loss: 0.2935 - val_acc: 0.9072\n",
      "Epoch 87/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3610 - acc: 0.8770 - val_loss: 0.2642 - val_acc: 0.9096\n",
      "Epoch 88/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.3682 - acc: 0.8750 - val_loss: 0.3461 - val_acc: 0.8828\n",
      "Epoch 89/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.3634 - acc: 0.8782 - val_loss: 0.2820 - val_acc: 0.9083\n",
      "Epoch 90/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3652 - acc: 0.8742 - val_loss: 0.3032 - val_acc: 0.8997\n",
      "Epoch 91/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3597 - acc: 0.8799 - val_loss: 0.2798 - val_acc: 0.9088\n",
      "Epoch 92/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.3549 - acc: 0.8798 - val_loss: 0.2634 - val_acc: 0.9179\n",
      "Epoch 93/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.3526 - acc: 0.8812 - val_loss: 0.3142 - val_acc: 0.8958\n",
      "Epoch 94/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.3562 - acc: 0.8802 - val_loss: 0.2819 - val_acc: 0.9041\n",
      "Epoch 95/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.3525 - acc: 0.8816 - val_loss: 0.2896 - val_acc: 0.9067\n",
      "Epoch 96/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3560 - acc: 0.8795 - val_loss: 0.3134 - val_acc: 0.8982\n",
      "Epoch 97/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.3485 - acc: 0.8828 - val_loss: 0.2785 - val_acc: 0.9062\n",
      "Epoch 98/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.3385 - acc: 0.8860 - val_loss: 0.2692 - val_acc: 0.9106\n",
      "Epoch 99/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.3402 - acc: 0.8836 - val_loss: 0.3099 - val_acc: 0.9036\n",
      "Epoch 100/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3425 - acc: 0.8826 - val_loss: 0.2944 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00100: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_100-0.29.hdf5\n",
      "Epoch 101/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.3505 - acc: 0.8816 - val_loss: 0.3084 - val_acc: 0.8997\n",
      "Epoch 102/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3462 - acc: 0.8830 - val_loss: 0.2797 - val_acc: 0.9114\n",
      "Epoch 103/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3376 - acc: 0.8844 - val_loss: 0.2769 - val_acc: 0.9114\n",
      "Epoch 104/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.3371 - acc: 0.8837 - val_loss: 0.2689 - val_acc: 0.9119\n",
      "Epoch 105/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3503 - acc: 0.8811 - val_loss: 0.2905 - val_acc: 0.9039\n",
      "Epoch 106/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3429 - acc: 0.8819 - val_loss: 0.2891 - val_acc: 0.9062\n",
      "Epoch 107/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.3337 - acc: 0.8849 - val_loss: 0.3019 - val_acc: 0.9028\n",
      "Epoch 108/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.3356 - acc: 0.8857 - val_loss: 0.3235 - val_acc: 0.8943\n",
      "Epoch 109/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3421 - acc: 0.8836 - val_loss: 0.2575 - val_acc: 0.9182\n",
      "Epoch 110/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.3291 - acc: 0.8845 - val_loss: 0.2908 - val_acc: 0.9091\n",
      "Epoch 111/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3295 - acc: 0.8887 - val_loss: 0.2936 - val_acc: 0.9028\n",
      "Epoch 112/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.3386 - acc: 0.8855 - val_loss: 0.2850 - val_acc: 0.9062\n",
      "Epoch 113/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3276 - acc: 0.8899 - val_loss: 0.2700 - val_acc: 0.9119\n",
      "Epoch 114/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3258 - acc: 0.8913 - val_loss: 0.2656 - val_acc: 0.9158\n",
      "Epoch 115/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3258 - acc: 0.8887 - val_loss: 0.2781 - val_acc: 0.9176\n",
      "Epoch 116/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3306 - acc: 0.8881 - val_loss: 0.2679 - val_acc: 0.9104\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/159 [==============================] - 19s 116ms/step - loss: 0.3330 - acc: 0.8866 - val_loss: 0.2713 - val_acc: 0.9104\n",
      "Epoch 118/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3217 - acc: 0.8885 - val_loss: 0.2787 - val_acc: 0.9078\n",
      "Epoch 119/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3255 - acc: 0.8893 - val_loss: 0.2931 - val_acc: 0.9078\n",
      "Epoch 120/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.3259 - acc: 0.8877 - val_loss: 0.2782 - val_acc: 0.9098\n",
      "Epoch 121/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.3173 - acc: 0.8906 - val_loss: 0.2536 - val_acc: 0.9148\n",
      "Epoch 122/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3195 - acc: 0.8916 - val_loss: 0.2644 - val_acc: 0.9122\n",
      "Epoch 123/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.3178 - acc: 0.8915 - val_loss: 0.2792 - val_acc: 0.9065\n",
      "Epoch 124/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3148 - acc: 0.8922 - val_loss: 0.2652 - val_acc: 0.9145\n",
      "Epoch 125/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3191 - acc: 0.8905 - val_loss: 0.2607 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00125: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_125-0.26.hdf5\n",
      "Epoch 126/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.3209 - acc: 0.8920 - val_loss: 0.2575 - val_acc: 0.9145\n",
      "Epoch 127/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3118 - acc: 0.8947 - val_loss: 0.2691 - val_acc: 0.9093\n",
      "Epoch 128/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3155 - acc: 0.8943 - val_loss: 0.2657 - val_acc: 0.9098\n",
      "Epoch 129/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.3040 - acc: 0.8956 - val_loss: 0.2605 - val_acc: 0.9150\n",
      "Epoch 130/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3139 - acc: 0.8920 - val_loss: 0.2559 - val_acc: 0.9189\n",
      "Epoch 131/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.3190 - acc: 0.8923 - val_loss: 0.2410 - val_acc: 0.9247\n",
      "Epoch 132/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3215 - acc: 0.8922 - val_loss: 0.2699 - val_acc: 0.9124\n",
      "Epoch 133/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3115 - acc: 0.8942 - val_loss: 0.2586 - val_acc: 0.9130\n",
      "Epoch 134/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3082 - acc: 0.8949 - val_loss: 0.2542 - val_acc: 0.9169\n",
      "Epoch 135/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3101 - acc: 0.8955 - val_loss: 0.2664 - val_acc: 0.9145\n",
      "Epoch 136/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.3153 - acc: 0.8932 - val_loss: 0.2520 - val_acc: 0.9197\n",
      "Epoch 137/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3067 - acc: 0.8934 - val_loss: 0.2483 - val_acc: 0.9192\n",
      "Epoch 138/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3021 - acc: 0.8952 - val_loss: 0.2845 - val_acc: 0.9065\n",
      "Epoch 139/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.3066 - acc: 0.8980 - val_loss: 0.2582 - val_acc: 0.9161\n",
      "Epoch 140/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3033 - acc: 0.8968 - val_loss: 0.2622 - val_acc: 0.9117\n",
      "Epoch 141/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.3020 - acc: 0.8959 - val_loss: 0.2530 - val_acc: 0.9143\n",
      "Epoch 142/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3005 - acc: 0.8969 - val_loss: 0.2714 - val_acc: 0.9148\n",
      "Epoch 143/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.3014 - acc: 0.8969 - val_loss: 0.2756 - val_acc: 0.9127\n",
      "Epoch 144/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.3003 - acc: 0.8992 - val_loss: 0.2580 - val_acc: 0.9215\n",
      "Epoch 145/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.3014 - acc: 0.8961 - val_loss: 0.2699 - val_acc: 0.9143\n",
      "Epoch 146/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2911 - acc: 0.9017 - val_loss: 0.2662 - val_acc: 0.9158\n",
      "Epoch 147/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2978 - acc: 0.8983 - val_loss: 0.2621 - val_acc: 0.9189\n",
      "Epoch 148/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2935 - acc: 0.8985 - val_loss: 0.3051 - val_acc: 0.9106\n",
      "Epoch 149/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2962 - acc: 0.8994 - val_loss: 0.2610 - val_acc: 0.9148\n",
      "Epoch 150/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.3014 - acc: 0.8967 - val_loss: 0.2689 - val_acc: 0.9195\n",
      "\n",
      "Epoch 00150: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_150-0.27.hdf5\n",
      "Epoch 151/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2945 - acc: 0.9009 - val_loss: 0.2641 - val_acc: 0.9166\n",
      "Epoch 152/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2933 - acc: 0.9004 - val_loss: 0.2575 - val_acc: 0.9179\n",
      "Epoch 153/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2839 - acc: 0.9044 - val_loss: 0.2439 - val_acc: 0.9273\n",
      "Epoch 154/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2908 - acc: 0.9030 - val_loss: 0.2617 - val_acc: 0.9205\n",
      "Epoch 155/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2973 - acc: 0.8967 - val_loss: 0.2940 - val_acc: 0.9072\n",
      "Epoch 156/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2908 - acc: 0.8997 - val_loss: 0.2911 - val_acc: 0.9091\n",
      "Epoch 157/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2886 - acc: 0.9004 - val_loss: 0.2658 - val_acc: 0.9156\n",
      "Epoch 158/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2971 - acc: 0.8986 - val_loss: 0.2893 - val_acc: 0.9127\n",
      "Epoch 159/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2959 - acc: 0.8998 - val_loss: 0.2742 - val_acc: 0.9117\n",
      "Epoch 160/500\n",
      "160/159 [==============================] - 18s 111ms/step - loss: 0.2993 - acc: 0.8973 - val_loss: 0.2522 - val_acc: 0.9184\n",
      "Epoch 161/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2871 - acc: 0.9025 - val_loss: 0.2545 - val_acc: 0.9156\n",
      "Epoch 162/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2858 - acc: 0.9009 - val_loss: 0.2460 - val_acc: 0.9179\n",
      "Epoch 163/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2946 - acc: 0.8980 - val_loss: 0.2664 - val_acc: 0.9122\n",
      "Epoch 164/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2884 - acc: 0.9035 - val_loss: 0.2640 - val_acc: 0.9161\n",
      "Epoch 165/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2811 - acc: 0.9032 - val_loss: 0.2779 - val_acc: 0.9192\n",
      "Epoch 166/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2851 - acc: 0.9035 - val_loss: 0.2372 - val_acc: 0.9249\n",
      "Epoch 167/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2836 - acc: 0.9033 - val_loss: 0.2513 - val_acc: 0.9213\n",
      "Epoch 168/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2928 - acc: 0.9017 - val_loss: 0.2426 - val_acc: 0.9249\n",
      "Epoch 169/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2820 - acc: 0.9006 - val_loss: 0.2611 - val_acc: 0.9226\n",
      "Epoch 170/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2789 - acc: 0.9047 - val_loss: 0.2513 - val_acc: 0.9210\n",
      "Epoch 171/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2992 - acc: 0.8999 - val_loss: 0.2876 - val_acc: 0.9122\n",
      "Epoch 172/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2862 - acc: 0.9026 - val_loss: 0.2515 - val_acc: 0.9226\n",
      "Epoch 173/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2789 - acc: 0.9057 - val_loss: 0.2628 - val_acc: 0.9202\n",
      "Epoch 174/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2879 - acc: 0.9011 - val_loss: 0.2457 - val_acc: 0.9223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2786 - acc: 0.9050 - val_loss: 0.2970 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00175: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_175-0.30.hdf5\n",
      "Epoch 176/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2864 - acc: 0.9012 - val_loss: 0.2677 - val_acc: 0.9195\n",
      "Epoch 177/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2770 - acc: 0.9070 - val_loss: 0.2877 - val_acc: 0.9101\n",
      "Epoch 178/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2847 - acc: 0.9018 - val_loss: 0.2841 - val_acc: 0.9171\n",
      "Epoch 179/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2699 - acc: 0.9075 - val_loss: 0.2513 - val_acc: 0.9252\n",
      "Epoch 180/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2682 - acc: 0.9071 - val_loss: 0.2593 - val_acc: 0.9241\n",
      "Epoch 181/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2768 - acc: 0.9068 - val_loss: 0.2655 - val_acc: 0.9174\n",
      "Epoch 182/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2755 - acc: 0.9052 - val_loss: 0.2735 - val_acc: 0.9145\n",
      "Epoch 183/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2782 - acc: 0.9034 - val_loss: 0.2547 - val_acc: 0.9234\n",
      "Epoch 184/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2878 - acc: 0.9029 - val_loss: 0.2502 - val_acc: 0.9244\n",
      "Epoch 185/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2821 - acc: 0.9039 - val_loss: 0.2801 - val_acc: 0.9169\n",
      "Epoch 186/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2752 - acc: 0.9048 - val_loss: 0.2624 - val_acc: 0.9195\n",
      "Epoch 187/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2765 - acc: 0.9070 - val_loss: 0.2811 - val_acc: 0.9122\n",
      "Epoch 188/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2782 - acc: 0.9046 - val_loss: 0.2631 - val_acc: 0.9174\n",
      "Epoch 189/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2745 - acc: 0.9068 - val_loss: 0.2565 - val_acc: 0.9223\n",
      "Epoch 190/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2702 - acc: 0.9062 - val_loss: 0.2595 - val_acc: 0.9226\n",
      "Epoch 191/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2707 - acc: 0.9092 - val_loss: 0.2482 - val_acc: 0.9200\n",
      "Epoch 192/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2739 - acc: 0.9075 - val_loss: 0.2733 - val_acc: 0.9182\n",
      "Epoch 193/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2653 - acc: 0.9099 - val_loss: 0.2981 - val_acc: 0.9109\n",
      "Epoch 194/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2721 - acc: 0.9046 - val_loss: 0.2537 - val_acc: 0.9208\n",
      "Epoch 195/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2672 - acc: 0.9085 - val_loss: 0.2369 - val_acc: 0.9262\n",
      "Epoch 196/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2712 - acc: 0.9081 - val_loss: 0.2964 - val_acc: 0.9054\n",
      "Epoch 197/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2720 - acc: 0.9061 - val_loss: 0.2616 - val_acc: 0.9174\n",
      "Epoch 198/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2694 - acc: 0.9060 - val_loss: 0.2828 - val_acc: 0.9156\n",
      "Epoch 199/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2685 - acc: 0.9079 - val_loss: 0.2447 - val_acc: 0.9223\n",
      "Epoch 200/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2771 - acc: 0.9055 - val_loss: 0.2715 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00200: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_200-0.27.hdf5\n",
      "Epoch 201/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2713 - acc: 0.9050 - val_loss: 0.2699 - val_acc: 0.9161\n",
      "Epoch 202/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2663 - acc: 0.9080 - val_loss: 0.2697 - val_acc: 0.9192\n",
      "Epoch 203/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2682 - acc: 0.9069 - val_loss: 0.2682 - val_acc: 0.9187\n",
      "Epoch 204/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2680 - acc: 0.9092 - val_loss: 0.2317 - val_acc: 0.9260\n",
      "Epoch 205/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2623 - acc: 0.9098 - val_loss: 0.2554 - val_acc: 0.9210\n",
      "Epoch 206/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2702 - acc: 0.9092 - val_loss: 0.2762 - val_acc: 0.9122\n",
      "Epoch 207/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2595 - acc: 0.9102 - val_loss: 0.2477 - val_acc: 0.9247\n",
      "Epoch 208/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2638 - acc: 0.9077 - val_loss: 0.3080 - val_acc: 0.9080\n",
      "Epoch 209/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2694 - acc: 0.9077 - val_loss: 0.2451 - val_acc: 0.9218\n",
      "Epoch 210/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2536 - acc: 0.9119 - val_loss: 0.2598 - val_acc: 0.9218\n",
      "Epoch 211/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2645 - acc: 0.9080 - val_loss: 0.2454 - val_acc: 0.9267\n",
      "Epoch 212/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2744 - acc: 0.9090 - val_loss: 0.2369 - val_acc: 0.9288\n",
      "Epoch 213/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2747 - acc: 0.9061 - val_loss: 0.2521 - val_acc: 0.9184\n",
      "Epoch 214/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2652 - acc: 0.9080 - val_loss: 0.2626 - val_acc: 0.9234\n",
      "Epoch 215/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2637 - acc: 0.9109 - val_loss: 0.2300 - val_acc: 0.9332\n",
      "Epoch 216/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2587 - acc: 0.9123 - val_loss: 0.2939 - val_acc: 0.9104\n",
      "Epoch 217/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2624 - acc: 0.9081 - val_loss: 0.2533 - val_acc: 0.9184\n",
      "Epoch 218/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2586 - acc: 0.9111 - val_loss: 0.2374 - val_acc: 0.9257\n",
      "Epoch 219/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2720 - acc: 0.9077 - val_loss: 0.2661 - val_acc: 0.9179\n",
      "Epoch 220/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2646 - acc: 0.9075 - val_loss: 0.2717 - val_acc: 0.9210\n",
      "Epoch 221/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2614 - acc: 0.9108 - val_loss: 0.2740 - val_acc: 0.9195\n",
      "Epoch 222/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2688 - acc: 0.9099 - val_loss: 0.2936 - val_acc: 0.9145\n",
      "Epoch 223/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2658 - acc: 0.9071 - val_loss: 0.2323 - val_acc: 0.9262\n",
      "Epoch 224/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2708 - acc: 0.9079 - val_loss: 0.2556 - val_acc: 0.9184\n",
      "Epoch 225/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2574 - acc: 0.9109 - val_loss: 0.2306 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00225: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_225-0.23.hdf5\n",
      "Epoch 226/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2630 - acc: 0.9103 - val_loss: 0.2385 - val_acc: 0.9270\n",
      "Epoch 227/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2713 - acc: 0.9090 - val_loss: 0.2654 - val_acc: 0.9171\n",
      "Epoch 228/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2604 - acc: 0.9117 - val_loss: 0.2491 - val_acc: 0.9254\n",
      "Epoch 229/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2605 - acc: 0.9117 - val_loss: 0.2770 - val_acc: 0.9111\n",
      "Epoch 230/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2601 - acc: 0.9099 - val_loss: 0.2389 - val_acc: 0.9252\n",
      "Epoch 231/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2595 - acc: 0.9112 - val_loss: 0.2485 - val_acc: 0.9215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2675 - acc: 0.9095 - val_loss: 0.2541 - val_acc: 0.9288\n",
      "Epoch 233/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2566 - acc: 0.9145 - val_loss: 0.2484 - val_acc: 0.9254\n",
      "Epoch 234/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2662 - acc: 0.9110 - val_loss: 0.2689 - val_acc: 0.9171\n",
      "Epoch 235/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2613 - acc: 0.9109 - val_loss: 0.2325 - val_acc: 0.9288\n",
      "Epoch 236/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2569 - acc: 0.9132 - val_loss: 0.2686 - val_acc: 0.9156\n",
      "Epoch 237/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2497 - acc: 0.9134 - val_loss: 0.2388 - val_acc: 0.9267\n",
      "Epoch 238/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2562 - acc: 0.9119 - val_loss: 0.2702 - val_acc: 0.9197\n",
      "Epoch 239/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2576 - acc: 0.9092 - val_loss: 0.2692 - val_acc: 0.9208\n",
      "Epoch 240/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2617 - acc: 0.9103 - val_loss: 0.2629 - val_acc: 0.9215\n",
      "Epoch 241/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2589 - acc: 0.9099 - val_loss: 0.2593 - val_acc: 0.9187\n",
      "Epoch 242/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2597 - acc: 0.9102 - val_loss: 0.2771 - val_acc: 0.9161\n",
      "Epoch 243/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2494 - acc: 0.9128 - val_loss: 0.2513 - val_acc: 0.9218\n",
      "Epoch 244/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2647 - acc: 0.9096 - val_loss: 0.2663 - val_acc: 0.9145\n",
      "Epoch 245/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2517 - acc: 0.9122 - val_loss: 0.3190 - val_acc: 0.9028\n",
      "Epoch 246/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2551 - acc: 0.9108 - val_loss: 0.2616 - val_acc: 0.9150\n",
      "Epoch 247/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2450 - acc: 0.9168 - val_loss: 0.2342 - val_acc: 0.9239\n",
      "Epoch 248/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2604 - acc: 0.9086 - val_loss: 0.2306 - val_acc: 0.9270\n",
      "Epoch 249/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2485 - acc: 0.9149 - val_loss: 0.2224 - val_acc: 0.9330\n",
      "Epoch 250/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2518 - acc: 0.9117 - val_loss: 0.2413 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00250: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_250-0.24.hdf5\n",
      "Epoch 251/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2550 - acc: 0.9121 - val_loss: 0.2614 - val_acc: 0.9174\n",
      "Epoch 252/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2632 - acc: 0.9125 - val_loss: 0.2810 - val_acc: 0.9150\n",
      "Epoch 253/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2514 - acc: 0.9136 - val_loss: 0.2434 - val_acc: 0.9231\n",
      "Epoch 254/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2567 - acc: 0.9136 - val_loss: 0.2345 - val_acc: 0.9262\n",
      "Epoch 255/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2571 - acc: 0.9136 - val_loss: 0.2425 - val_acc: 0.9241\n",
      "Epoch 256/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2457 - acc: 0.9163 - val_loss: 0.2537 - val_acc: 0.9197\n",
      "Epoch 257/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2497 - acc: 0.9137 - val_loss: 0.2408 - val_acc: 0.9247\n",
      "Epoch 258/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2514 - acc: 0.9145 - val_loss: 0.2692 - val_acc: 0.9156\n",
      "Epoch 259/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2456 - acc: 0.9177 - val_loss: 0.2443 - val_acc: 0.9275\n",
      "Epoch 260/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2594 - acc: 0.9116 - val_loss: 0.2123 - val_acc: 0.9306\n",
      "Epoch 261/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2488 - acc: 0.9164 - val_loss: 0.2346 - val_acc: 0.9280\n",
      "Epoch 262/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2481 - acc: 0.9154 - val_loss: 0.2634 - val_acc: 0.9231\n",
      "Epoch 263/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2492 - acc: 0.9156 - val_loss: 0.2399 - val_acc: 0.9236\n",
      "Epoch 264/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2448 - acc: 0.9176 - val_loss: 0.2237 - val_acc: 0.9327\n",
      "Epoch 265/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2397 - acc: 0.9161 - val_loss: 0.2366 - val_acc: 0.9283\n",
      "Epoch 266/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2437 - acc: 0.9139 - val_loss: 0.2545 - val_acc: 0.9231\n",
      "Epoch 267/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2408 - acc: 0.9163 - val_loss: 0.2332 - val_acc: 0.9265\n",
      "Epoch 268/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2532 - acc: 0.9120 - val_loss: 0.2211 - val_acc: 0.9319\n",
      "Epoch 269/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2535 - acc: 0.9131 - val_loss: 0.2626 - val_acc: 0.9239\n",
      "Epoch 270/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2482 - acc: 0.9147 - val_loss: 0.2531 - val_acc: 0.9208\n",
      "Epoch 271/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2399 - acc: 0.9185 - val_loss: 0.2320 - val_acc: 0.9270\n",
      "Epoch 272/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2461 - acc: 0.9150 - val_loss: 0.2594 - val_acc: 0.9192\n",
      "Epoch 273/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2404 - acc: 0.9166 - val_loss: 0.2233 - val_acc: 0.9306\n",
      "Epoch 274/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2386 - acc: 0.9172 - val_loss: 0.2802 - val_acc: 0.9226\n",
      "Epoch 275/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2424 - acc: 0.9174 - val_loss: 0.2283 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00275: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_275-0.23.hdf5\n",
      "Epoch 276/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2482 - acc: 0.9137 - val_loss: 0.2343 - val_acc: 0.9260\n",
      "Epoch 277/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2457 - acc: 0.9146 - val_loss: 0.2627 - val_acc: 0.9221\n",
      "Epoch 278/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2475 - acc: 0.9148 - val_loss: 0.2157 - val_acc: 0.9304\n",
      "Epoch 279/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2390 - acc: 0.9179 - val_loss: 0.2669 - val_acc: 0.9192\n",
      "Epoch 280/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2623 - acc: 0.9122 - val_loss: 0.2434 - val_acc: 0.9252\n",
      "Epoch 281/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2381 - acc: 0.9151 - val_loss: 0.2373 - val_acc: 0.9309\n",
      "Epoch 282/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2366 - acc: 0.9173 - val_loss: 0.2497 - val_acc: 0.9280\n",
      "Epoch 283/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2427 - acc: 0.9148 - val_loss: 0.2329 - val_acc: 0.9288\n",
      "Epoch 284/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2405 - acc: 0.9168 - val_loss: 0.2639 - val_acc: 0.9215\n",
      "Epoch 285/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2435 - acc: 0.9149 - val_loss: 0.2805 - val_acc: 0.9200\n",
      "Epoch 286/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2440 - acc: 0.9184 - val_loss: 0.2290 - val_acc: 0.9319\n",
      "Epoch 287/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2385 - acc: 0.9198 - val_loss: 0.2494 - val_acc: 0.9226\n",
      "Epoch 288/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2475 - acc: 0.9156 - val_loss: 0.2489 - val_acc: 0.9213\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2448 - acc: 0.9171 - val_loss: 0.2476 - val_acc: 0.9234\n",
      "Epoch 290/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2421 - acc: 0.9160 - val_loss: 0.2180 - val_acc: 0.9304\n",
      "Epoch 291/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2447 - acc: 0.9144 - val_loss: 0.2357 - val_acc: 0.9267\n",
      "Epoch 292/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2368 - acc: 0.9186 - val_loss: 0.2624 - val_acc: 0.9200\n",
      "Epoch 293/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2418 - acc: 0.9144 - val_loss: 0.2403 - val_acc: 0.9286\n",
      "Epoch 294/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2431 - acc: 0.9177 - val_loss: 0.2452 - val_acc: 0.9241\n",
      "Epoch 295/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2387 - acc: 0.9172 - val_loss: 0.2809 - val_acc: 0.9195\n",
      "Epoch 296/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2386 - acc: 0.9183 - val_loss: 0.2632 - val_acc: 0.9176\n",
      "Epoch 297/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2354 - acc: 0.9204 - val_loss: 0.2421 - val_acc: 0.9249\n",
      "Epoch 298/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2373 - acc: 0.9190 - val_loss: 0.2465 - val_acc: 0.9221\n",
      "Epoch 299/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2354 - acc: 0.9188 - val_loss: 0.2513 - val_acc: 0.9265\n",
      "Epoch 300/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2377 - acc: 0.9190 - val_loss: 0.2560 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00300: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_300-0.26.hdf5\n",
      "Epoch 301/500\n",
      "160/159 [==============================] - 18s 111ms/step - loss: 0.2414 - acc: 0.9149 - val_loss: 0.2465 - val_acc: 0.9221\n",
      "Epoch 302/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2247 - acc: 0.9205 - val_loss: 0.2389 - val_acc: 0.9280\n",
      "Epoch 303/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2342 - acc: 0.9198 - val_loss: 0.2471 - val_acc: 0.9226\n",
      "Epoch 304/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2346 - acc: 0.9191 - val_loss: 0.2625 - val_acc: 0.9215\n",
      "Epoch 305/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2401 - acc: 0.9183 - val_loss: 0.2508 - val_acc: 0.9215\n",
      "Epoch 306/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2343 - acc: 0.9184 - val_loss: 0.2389 - val_acc: 0.9252\n",
      "Epoch 307/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2449 - acc: 0.9167 - val_loss: 0.2266 - val_acc: 0.9275\n",
      "Epoch 308/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.2364 - acc: 0.9175 - val_loss: 0.2368 - val_acc: 0.9262\n",
      "Epoch 309/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2323 - acc: 0.9188 - val_loss: 0.2352 - val_acc: 0.9278\n",
      "Epoch 310/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2347 - acc: 0.9189 - val_loss: 0.2741 - val_acc: 0.9182\n",
      "Epoch 311/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2356 - acc: 0.9197 - val_loss: 0.2293 - val_acc: 0.9304\n",
      "Epoch 312/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2377 - acc: 0.9184 - val_loss: 0.2456 - val_acc: 0.9223\n",
      "Epoch 313/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2377 - acc: 0.9200 - val_loss: 0.2730 - val_acc: 0.9145\n",
      "Epoch 314/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2327 - acc: 0.9194 - val_loss: 0.2653 - val_acc: 0.9156\n",
      "Epoch 315/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2300 - acc: 0.9215 - val_loss: 0.2367 - val_acc: 0.9288\n",
      "Epoch 316/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2363 - acc: 0.9184 - val_loss: 0.2445 - val_acc: 0.9223\n",
      "Epoch 317/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2345 - acc: 0.9182 - val_loss: 0.2210 - val_acc: 0.9335\n",
      "Epoch 318/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2359 - acc: 0.9179 - val_loss: 0.2571 - val_acc: 0.9270\n",
      "Epoch 319/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2395 - acc: 0.9183 - val_loss: 0.2640 - val_acc: 0.9176\n",
      "Epoch 320/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2427 - acc: 0.9162 - val_loss: 0.2455 - val_acc: 0.9236\n",
      "Epoch 321/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2371 - acc: 0.9191 - val_loss: 0.2833 - val_acc: 0.9163\n",
      "Epoch 322/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.2235 - acc: 0.9229 - val_loss: 0.2490 - val_acc: 0.9218\n",
      "Epoch 323/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2478 - acc: 0.9151 - val_loss: 0.2433 - val_acc: 0.9257\n",
      "Epoch 324/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2335 - acc: 0.9213 - val_loss: 0.2270 - val_acc: 0.9291\n",
      "Epoch 325/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2248 - acc: 0.9225 - val_loss: 0.2643 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00325: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_325-0.26.hdf5\n",
      "Epoch 326/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2350 - acc: 0.9192 - val_loss: 0.2341 - val_acc: 0.9275\n",
      "Epoch 327/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2408 - acc: 0.9182 - val_loss: 0.2510 - val_acc: 0.9231\n",
      "Epoch 328/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2234 - acc: 0.9225 - val_loss: 0.2798 - val_acc: 0.9132\n",
      "Epoch 329/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2230 - acc: 0.9220 - val_loss: 0.2311 - val_acc: 0.9280\n",
      "Epoch 330/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2260 - acc: 0.9243 - val_loss: 0.2500 - val_acc: 0.9252\n",
      "Epoch 331/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2243 - acc: 0.9214 - val_loss: 0.2607 - val_acc: 0.9202\n",
      "Epoch 332/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2325 - acc: 0.9223 - val_loss: 0.2882 - val_acc: 0.9122\n",
      "Epoch 333/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2293 - acc: 0.9224 - val_loss: 0.2412 - val_acc: 0.9286\n",
      "Epoch 334/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2365 - acc: 0.9179 - val_loss: 0.2498 - val_acc: 0.9231\n",
      "Epoch 335/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2300 - acc: 0.9185 - val_loss: 0.2366 - val_acc: 0.9244\n",
      "Epoch 336/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2319 - acc: 0.9213 - val_loss: 0.2249 - val_acc: 0.9366\n",
      "Epoch 337/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2301 - acc: 0.9185 - val_loss: 0.2676 - val_acc: 0.9200\n",
      "Epoch 338/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2331 - acc: 0.9211 - val_loss: 0.2474 - val_acc: 0.9273\n",
      "Epoch 339/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2251 - acc: 0.9207 - val_loss: 0.2465 - val_acc: 0.9286\n",
      "Epoch 340/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2371 - acc: 0.9210 - val_loss: 0.2170 - val_acc: 0.9319\n",
      "Epoch 341/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2207 - acc: 0.9216 - val_loss: 0.2673 - val_acc: 0.9150\n",
      "Epoch 342/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2284 - acc: 0.9201 - val_loss: 0.2898 - val_acc: 0.9135\n",
      "Epoch 343/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2347 - acc: 0.9207 - val_loss: 0.2711 - val_acc: 0.9200\n",
      "Epoch 344/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2287 - acc: 0.9206 - val_loss: 0.2504 - val_acc: 0.9218\n",
      "Epoch 345/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2329 - acc: 0.9211 - val_loss: 0.2482 - val_acc: 0.9293\n",
      "Epoch 346/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2318 - acc: 0.9204 - val_loss: 0.2276 - val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2228 - acc: 0.9242 - val_loss: 0.2296 - val_acc: 0.9286\n",
      "Epoch 348/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2272 - acc: 0.9205 - val_loss: 0.2339 - val_acc: 0.9288\n",
      "Epoch 349/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2334 - acc: 0.9197 - val_loss: 0.2206 - val_acc: 0.9309\n",
      "Epoch 350/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2233 - acc: 0.9231 - val_loss: 0.2391 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00350: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_350-0.24.hdf5\n",
      "Epoch 351/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2223 - acc: 0.9239 - val_loss: 0.2615 - val_acc: 0.9210\n",
      "Epoch 352/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2282 - acc: 0.9213 - val_loss: 0.2311 - val_acc: 0.9283\n",
      "Epoch 353/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2271 - acc: 0.9211 - val_loss: 0.2229 - val_acc: 0.9275\n",
      "Epoch 354/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2310 - acc: 0.9220 - val_loss: 0.2574 - val_acc: 0.9210\n",
      "Epoch 355/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2332 - acc: 0.9205 - val_loss: 0.2315 - val_acc: 0.9314\n",
      "Epoch 356/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2190 - acc: 0.9239 - val_loss: 0.2273 - val_acc: 0.9309\n",
      "Epoch 357/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2265 - acc: 0.9224 - val_loss: 0.2257 - val_acc: 0.9278\n",
      "Epoch 358/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2301 - acc: 0.9199 - val_loss: 0.2418 - val_acc: 0.9296\n",
      "Epoch 359/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2313 - acc: 0.9195 - val_loss: 0.2725 - val_acc: 0.9166\n",
      "Epoch 360/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2189 - acc: 0.9237 - val_loss: 0.2612 - val_acc: 0.9189\n",
      "Epoch 361/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2311 - acc: 0.9207 - val_loss: 0.2304 - val_acc: 0.9262\n",
      "Epoch 362/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2280 - acc: 0.9218 - val_loss: 0.2466 - val_acc: 0.9228\n",
      "Epoch 363/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2347 - acc: 0.9215 - val_loss: 0.2551 - val_acc: 0.9234\n",
      "Epoch 364/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2238 - acc: 0.9238 - val_loss: 0.2486 - val_acc: 0.9234\n",
      "Epoch 365/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2256 - acc: 0.9236 - val_loss: 0.2141 - val_acc: 0.9361\n",
      "Epoch 366/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2227 - acc: 0.9222 - val_loss: 0.2364 - val_acc: 0.9270\n",
      "Epoch 367/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2218 - acc: 0.9235 - val_loss: 0.2595 - val_acc: 0.9221\n",
      "Epoch 368/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2215 - acc: 0.9225 - val_loss: 0.2385 - val_acc: 0.9249\n",
      "Epoch 369/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2216 - acc: 0.9246 - val_loss: 0.2160 - val_acc: 0.9319\n",
      "Epoch 370/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2326 - acc: 0.9176 - val_loss: 0.2496 - val_acc: 0.9221\n",
      "Epoch 371/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2308 - acc: 0.9213 - val_loss: 0.2482 - val_acc: 0.9252\n",
      "Epoch 372/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2253 - acc: 0.9250 - val_loss: 0.2238 - val_acc: 0.9299\n",
      "Epoch 373/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2224 - acc: 0.9231 - val_loss: 0.2254 - val_acc: 0.9299\n",
      "Epoch 374/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2277 - acc: 0.9202 - val_loss: 0.2335 - val_acc: 0.9293\n",
      "Epoch 375/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2171 - acc: 0.9273 - val_loss: 0.2228 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00375: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_375-0.22.hdf5\n",
      "Epoch 376/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2184 - acc: 0.9236 - val_loss: 0.2381 - val_acc: 0.9260\n",
      "Epoch 377/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2216 - acc: 0.9240 - val_loss: 0.2538 - val_acc: 0.9184\n",
      "Epoch 378/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2342 - acc: 0.9200 - val_loss: 0.2161 - val_acc: 0.9322\n",
      "Epoch 379/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2236 - acc: 0.9231 - val_loss: 0.2381 - val_acc: 0.9291\n",
      "Epoch 380/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2192 - acc: 0.9244 - val_loss: 0.2421 - val_acc: 0.9270\n",
      "Epoch 381/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2226 - acc: 0.9245 - val_loss: 0.2658 - val_acc: 0.9192\n",
      "Epoch 382/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2269 - acc: 0.9210 - val_loss: 0.2401 - val_acc: 0.9257\n",
      "Epoch 383/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2231 - acc: 0.9230 - val_loss: 0.2458 - val_acc: 0.9241\n",
      "Epoch 384/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2209 - acc: 0.9252 - val_loss: 0.2327 - val_acc: 0.9275\n",
      "Epoch 385/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2197 - acc: 0.9246 - val_loss: 0.2447 - val_acc: 0.9312\n",
      "Epoch 386/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2223 - acc: 0.9228 - val_loss: 0.2668 - val_acc: 0.9267\n",
      "Epoch 387/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2157 - acc: 0.9262 - val_loss: 0.2147 - val_acc: 0.9376\n",
      "Epoch 388/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2092 - acc: 0.9271 - val_loss: 0.2336 - val_acc: 0.9293\n",
      "Epoch 389/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2176 - acc: 0.9248 - val_loss: 0.2206 - val_acc: 0.9304\n",
      "Epoch 390/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2223 - acc: 0.9234 - val_loss: 0.2573 - val_acc: 0.9257\n",
      "Epoch 391/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2186 - acc: 0.9248 - val_loss: 0.2794 - val_acc: 0.9169\n",
      "Epoch 392/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2163 - acc: 0.9242 - val_loss: 0.2275 - val_acc: 0.9327\n",
      "Epoch 393/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2241 - acc: 0.9233 - val_loss: 0.2518 - val_acc: 0.9247\n",
      "Epoch 394/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2213 - acc: 0.9253 - val_loss: 0.2397 - val_acc: 0.9228\n",
      "Epoch 395/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2204 - acc: 0.9269 - val_loss: 0.2263 - val_acc: 0.9314\n",
      "Epoch 396/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2245 - acc: 0.9237 - val_loss: 0.2149 - val_acc: 0.9361\n",
      "Epoch 397/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2237 - acc: 0.9237 - val_loss: 0.2165 - val_acc: 0.9330\n",
      "Epoch 398/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2301 - acc: 0.9227 - val_loss: 0.2696 - val_acc: 0.9195\n",
      "Epoch 399/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2224 - acc: 0.9218 - val_loss: 0.2330 - val_acc: 0.9286\n",
      "Epoch 400/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2147 - acc: 0.9255 - val_loss: 0.2204 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00400: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_400-0.22.hdf5\n",
      "Epoch 401/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2160 - acc: 0.9253 - val_loss: 0.2203 - val_acc: 0.9273\n",
      "Epoch 402/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2220 - acc: 0.9222 - val_loss: 0.2177 - val_acc: 0.9332\n",
      "Epoch 403/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2190 - acc: 0.9243 - val_loss: 0.2695 - val_acc: 0.9148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2159 - acc: 0.9260 - val_loss: 0.2447 - val_acc: 0.9291\n",
      "Epoch 405/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2125 - acc: 0.9274 - val_loss: 0.3108 - val_acc: 0.9083\n",
      "Epoch 406/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2197 - acc: 0.9254 - val_loss: 0.2213 - val_acc: 0.9299\n",
      "Epoch 407/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2190 - acc: 0.9246 - val_loss: 0.2396 - val_acc: 0.9252\n",
      "Epoch 408/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2126 - acc: 0.9287 - val_loss: 0.2394 - val_acc: 0.9265\n",
      "Epoch 409/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.2237 - acc: 0.9236 - val_loss: 0.2503 - val_acc: 0.9244\n",
      "Epoch 410/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2156 - acc: 0.9261 - val_loss: 0.2447 - val_acc: 0.9288\n",
      "Epoch 411/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2174 - acc: 0.9261 - val_loss: 0.2404 - val_acc: 0.9278\n",
      "Epoch 412/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2125 - acc: 0.9253 - val_loss: 0.2455 - val_acc: 0.9228\n",
      "Epoch 413/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2311 - acc: 0.9200 - val_loss: 0.2415 - val_acc: 0.9280\n",
      "Epoch 414/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2182 - acc: 0.9243 - val_loss: 0.2563 - val_acc: 0.9215\n",
      "Epoch 415/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2230 - acc: 0.9244 - val_loss: 0.2277 - val_acc: 0.9322\n",
      "Epoch 416/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2224 - acc: 0.9231 - val_loss: 0.2609 - val_acc: 0.9174\n",
      "Epoch 417/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2154 - acc: 0.9241 - val_loss: 0.2424 - val_acc: 0.9273\n",
      "Epoch 418/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2186 - acc: 0.9239 - val_loss: 0.2473 - val_acc: 0.9280\n",
      "Epoch 419/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2176 - acc: 0.9255 - val_loss: 0.2432 - val_acc: 0.9278\n",
      "Epoch 420/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2115 - acc: 0.9275 - val_loss: 0.2180 - val_acc: 0.9356\n",
      "Epoch 421/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2144 - acc: 0.9259 - val_loss: 0.2324 - val_acc: 0.9335\n",
      "Epoch 422/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2133 - acc: 0.9283 - val_loss: 0.2314 - val_acc: 0.9327\n",
      "Epoch 423/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2192 - acc: 0.9238 - val_loss: 0.2428 - val_acc: 0.9286\n",
      "Epoch 424/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2194 - acc: 0.9254 - val_loss: 0.2187 - val_acc: 0.9345\n",
      "Epoch 425/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2088 - acc: 0.9293 - val_loss: 0.2167 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00425: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_425-0.22.hdf5\n",
      "Epoch 426/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2118 - acc: 0.9260 - val_loss: 0.2360 - val_acc: 0.9257\n",
      "Epoch 427/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2120 - acc: 0.9264 - val_loss: 0.2361 - val_acc: 0.9267\n",
      "Epoch 428/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2142 - acc: 0.9281 - val_loss: 0.2342 - val_acc: 0.9309\n",
      "Epoch 429/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2178 - acc: 0.9278 - val_loss: 0.2412 - val_acc: 0.9301\n",
      "Epoch 430/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2166 - acc: 0.9245 - val_loss: 0.2167 - val_acc: 0.9350\n",
      "Epoch 431/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2236 - acc: 0.9222 - val_loss: 0.2248 - val_acc: 0.9327\n",
      "Epoch 432/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2063 - acc: 0.9292 - val_loss: 0.2407 - val_acc: 0.9309\n",
      "Epoch 433/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2212 - acc: 0.9237 - val_loss: 0.2774 - val_acc: 0.9221\n",
      "Epoch 434/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2107 - acc: 0.9262 - val_loss: 0.2580 - val_acc: 0.9265\n",
      "Epoch 435/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2148 - acc: 0.9263 - val_loss: 0.2536 - val_acc: 0.9262\n",
      "Epoch 436/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2216 - acc: 0.9251 - val_loss: 0.2515 - val_acc: 0.9247\n",
      "Epoch 437/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2137 - acc: 0.9273 - val_loss: 0.2050 - val_acc: 0.9382\n",
      "Epoch 438/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2160 - acc: 0.9254 - val_loss: 0.2583 - val_acc: 0.9260\n",
      "Epoch 439/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2138 - acc: 0.9267 - val_loss: 0.2145 - val_acc: 0.9353\n",
      "Epoch 440/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2112 - acc: 0.9283 - val_loss: 0.2265 - val_acc: 0.9337\n",
      "Epoch 441/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2080 - acc: 0.9301 - val_loss: 0.2250 - val_acc: 0.9332\n",
      "Epoch 442/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2060 - acc: 0.9291 - val_loss: 0.2401 - val_acc: 0.9283\n",
      "Epoch 443/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2031 - acc: 0.9297 - val_loss: 0.2178 - val_acc: 0.9345\n",
      "Epoch 444/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2214 - acc: 0.9233 - val_loss: 0.2261 - val_acc: 0.9280\n",
      "Epoch 445/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2150 - acc: 0.9270 - val_loss: 0.2061 - val_acc: 0.9400\n",
      "Epoch 446/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2194 - acc: 0.9248 - val_loss: 0.2529 - val_acc: 0.9241\n",
      "Epoch 447/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2173 - acc: 0.9244 - val_loss: 0.2386 - val_acc: 0.9262\n",
      "Epoch 448/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2004 - acc: 0.9311 - val_loss: 0.2590 - val_acc: 0.9223\n",
      "Epoch 449/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2139 - acc: 0.9269 - val_loss: 0.2333 - val_acc: 0.9330\n",
      "Epoch 450/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.1980 - acc: 0.9317 - val_loss: 0.2216 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00450: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_450-0.22.hdf5\n",
      "Epoch 451/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2045 - acc: 0.9289 - val_loss: 0.2496 - val_acc: 0.9270\n",
      "Epoch 452/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2159 - acc: 0.9263 - val_loss: 0.2354 - val_acc: 0.9345\n",
      "Epoch 453/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2072 - acc: 0.9279 - val_loss: 0.2485 - val_acc: 0.9288\n",
      "Epoch 454/500\n",
      "160/159 [==============================] - 18s 112ms/step - loss: 0.2085 - acc: 0.9294 - val_loss: 0.2457 - val_acc: 0.9283\n",
      "Epoch 455/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2113 - acc: 0.9238 - val_loss: 0.2307 - val_acc: 0.9327\n",
      "Epoch 456/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2103 - acc: 0.9288 - val_loss: 0.2550 - val_acc: 0.9241\n",
      "Epoch 457/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.2046 - acc: 0.9302 - val_loss: 0.2345 - val_acc: 0.9324\n",
      "Epoch 458/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2082 - acc: 0.9294 - val_loss: 0.2531 - val_acc: 0.9236\n",
      "Epoch 459/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2130 - acc: 0.9260 - val_loss: 0.2281 - val_acc: 0.9304\n",
      "Epoch 460/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2089 - acc: 0.9293 - val_loss: 0.2274 - val_acc: 0.9309\n",
      "Epoch 461/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2012 - acc: 0.9318 - val_loss: 0.2562 - val_acc: 0.9275\n",
      "Epoch 462/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2127 - acc: 0.9284 - val_loss: 0.2312 - val_acc: 0.9314\n",
      "Epoch 463/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2033 - acc: 0.9307 - val_loss: 0.2029 - val_acc: 0.9358\n",
      "Epoch 464/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2067 - acc: 0.9290 - val_loss: 0.2275 - val_acc: 0.9337\n",
      "Epoch 465/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2124 - acc: 0.9275 - val_loss: 0.2585 - val_acc: 0.9260\n",
      "Epoch 466/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.2220 - acc: 0.9247 - val_loss: 0.2269 - val_acc: 0.9343\n",
      "Epoch 467/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.2163 - acc: 0.9267 - val_loss: 0.2776 - val_acc: 0.9179\n",
      "Epoch 468/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2061 - acc: 0.9302 - val_loss: 0.2364 - val_acc: 0.9314\n",
      "Epoch 469/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2161 - acc: 0.9249 - val_loss: 0.2700 - val_acc: 0.9221\n",
      "Epoch 470/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2050 - acc: 0.9303 - val_loss: 0.2468 - val_acc: 0.9252\n",
      "Epoch 471/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2093 - acc: 0.9274 - val_loss: 0.2140 - val_acc: 0.9327\n",
      "Epoch 472/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2124 - acc: 0.9286 - val_loss: 0.2664 - val_acc: 0.9202\n",
      "Epoch 473/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2093 - acc: 0.9286 - val_loss: 0.2452 - val_acc: 0.9247\n",
      "Epoch 474/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2121 - acc: 0.9276 - val_loss: 0.2481 - val_acc: 0.9267\n",
      "Epoch 475/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2036 - acc: 0.9298 - val_loss: 0.2289 - val_acc: 0.9283\n",
      "\n",
      "Epoch 00475: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_475-0.23.hdf5\n",
      "Epoch 476/500\n",
      "160/159 [==============================] - 18s 114ms/step - loss: 0.2070 - acc: 0.9278 - val_loss: 0.2322 - val_acc: 0.9335\n",
      "Epoch 477/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2021 - acc: 0.9312 - val_loss: 0.2501 - val_acc: 0.9288\n",
      "Epoch 478/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2153 - acc: 0.9272 - val_loss: 0.2548 - val_acc: 0.9301\n",
      "Epoch 479/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.2084 - acc: 0.9285 - val_loss: 0.2481 - val_acc: 0.9278\n",
      "Epoch 480/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.1948 - acc: 0.9353 - val_loss: 0.2501 - val_acc: 0.9304\n",
      "Epoch 481/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2057 - acc: 0.9273 - val_loss: 0.2154 - val_acc: 0.9350\n",
      "Epoch 482/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2040 - acc: 0.9293 - val_loss: 0.2419 - val_acc: 0.9296\n",
      "Epoch 483/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2146 - acc: 0.9255 - val_loss: 0.2278 - val_acc: 0.9324\n",
      "Epoch 484/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2027 - acc: 0.9297 - val_loss: 0.2117 - val_acc: 0.9361\n",
      "Epoch 485/500\n",
      "160/159 [==============================] - 18s 113ms/step - loss: 0.2123 - acc: 0.9273 - val_loss: 0.2395 - val_acc: 0.9273\n",
      "Epoch 486/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.1978 - acc: 0.9311 - val_loss: 0.2690 - val_acc: 0.9208\n",
      "Epoch 487/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.1958 - acc: 0.9333 - val_loss: 0.2472 - val_acc: 0.9358\n",
      "Epoch 488/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2012 - acc: 0.9310 - val_loss: 0.2472 - val_acc: 0.9262\n",
      "Epoch 489/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2056 - acc: 0.9321 - val_loss: 0.2411 - val_acc: 0.9280\n",
      "Epoch 490/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2017 - acc: 0.9285 - val_loss: 0.2218 - val_acc: 0.9358\n",
      "Epoch 491/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2051 - acc: 0.9301 - val_loss: 0.2269 - val_acc: 0.9314\n",
      "Epoch 492/500\n",
      "160/159 [==============================] - 18s 116ms/step - loss: 0.2059 - acc: 0.9271 - val_loss: 0.2177 - val_acc: 0.9358\n",
      "Epoch 493/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2087 - acc: 0.9300 - val_loss: 0.2440 - val_acc: 0.9278\n",
      "Epoch 494/500\n",
      "160/159 [==============================] - 19s 116ms/step - loss: 0.2121 - acc: 0.9278 - val_loss: 0.2340 - val_acc: 0.9324\n",
      "Epoch 495/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2098 - acc: 0.9275 - val_loss: 0.2400 - val_acc: 0.9291\n",
      "Epoch 496/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.1964 - acc: 0.9303 - val_loss: 0.2269 - val_acc: 0.9348\n",
      "Epoch 497/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2007 - acc: 0.9307 - val_loss: 0.2267 - val_acc: 0.9312\n",
      "Epoch 498/500\n",
      "160/159 [==============================] - 19s 118ms/step - loss: 0.2029 - acc: 0.9313 - val_loss: 0.2354 - val_acc: 0.9324\n",
      "Epoch 499/500\n",
      "160/159 [==============================] - 18s 115ms/step - loss: 0.2050 - acc: 0.9289 - val_loss: 0.2582 - val_acc: 0.9270\n",
      "Epoch 500/500\n",
      "160/159 [==============================] - 19s 117ms/step - loss: 0.2040 - acc: 0.9298 - val_loss: 0.2010 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00500: saving model to results_bayes/021-chong_no_batch_no_mitochondria/weights_Chong_data_epoch_500-0.20.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = X_train_keep.shape[0]/batch_size,\n",
    "                    epochs = 500,                    \n",
    "                    validation_data = (X_valid_keep, one_hot(y_valid_keep, num_classes)),\n",
    "                    verbose = 1,\n",
    "                    callbacks=[checkpointer, tb_cb]\n",
    ")\n",
    "model.save(resdir+\"/final.keras.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7064067048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f70650d88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
